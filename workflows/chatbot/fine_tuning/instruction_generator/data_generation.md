Instruction Data Generation
======
1. [Introduction](#introduction)
2. [Get Started](#get-started)
3. [Examples](#examples)

## Introduction

Large language models, such as ChatGPT, LLaMA, and Bard, have demonstrated superior performance across a wide range of natural language processing tasks compared to previous pretrained language models. One key distinction between pretrained language models and large language models is the introduction of a new paradigm called self-instruct learning, as outlined in the [self-instruct learning](https://github.com/yizhongw/self-instruct). This fine-tuning paradigm, coupled with manually crafted instruction following data, enables the model to generalize to various tasks and achieve promising progress.

Currently, the most powerful large language model available is ChatGPT. As discussed in the source paper of [ChatGPT](https://arxiv.org/abs/2203.02155), the quality of the instruction following data plays a crucial role in influencing the final results of the model. OpenAI, the creator of ChatGPT, invested significant time and effort by employing a large group of human volunteers to annotate and review the instruction following data. This meticulous approach, combined with an advanced training pipeline, has made ChatGPT the most powerful language model, surpassing the performance of other open-source models. However, due to commercial reasons, OpenAI has not released the model weights of ChatGPT and only offers access to its capabilities through their API.

Despite the restricted access to ChatGPT, developers and researchers have shown great interest in emulating the pipeline of ChatGPT to create customized models conditioned on specific domain documents. As demonstrated in the [in-context learning distillation paper](https://arxiv.org/abs/2212.10670), it is possible to transfer knowledge from a teacher model (such as ChatGPT) to a student model. One straightforward method involves using the teacher model to annotate and augment data, followed by fine-tuning the student model using the augmented data. This paradigm enables the student model to mimic the behavior of the teacher model and achieve better performance. A similar idea is proposed in [Alpaca](https://github.com/tatsu-lab/stanford_alpaca), which formulates an effective pipeline for using ChatGPT to generate high-quality instruction following data. It has been shown that even a small dataset of 52K generated instruction following examples can significantly enhance the performance of the vanilla LLaMA model.

However, existing data generation methods still focus on generating Alpaca-formatted data, which is suitable for generic application scenarios. Developers often rely on casual language modeling to fine-tune their models using domain-specific documents, while the data generated by ChatGPT is typically used to enhance the conversational abilities of their systems. We believe that this training paradigm does not fully leverage the annotation capabilities of ChatGPT. Thus, it remains a challenge to generate instruction following data that is closely related to domain-specific documents, thereby enabling the student model to better leverage the knowledge from a more powerful large language model like ChatGPT.

In addition to the demand for generating instruction following data for self-instruct learning conditioned on user-specific documents, we have also explored the potential of using ChatGPT to generate pairwise instruction data for [reinforcement learning from human feedback](https://openai.com/research/learning-from-human-preferences), a crucial training procedure for aligning user intent in state-of-the-art large language models. This training procedure requires paired positive and negative answers, where the positive answer is more likely to be selected by humans and vice versa, in response to a specific instruction query. The goal is to train a critic model using [adversarial learning techniques](https://arxiv.org/abs/1707.06347), forcing the generator to output human-like responses.

Traditionally, this method relies on human volunteers to determine which answer is more suitable for a given instruction query. However, in content-based data generation, it is not feasible to assume that participants possess comprehensive background knowledge to understand the provided context. This limitation can easily mislead the language model and result in poor performance.

In this repository, we aim to release a new method that leverages ChatGPT to generate content-based pairwise instruction data. We believe that this novel approach will significantly reduce the cost of data annotation and inspire the development of chatbot customization to improve its performance.


## Get Started
This data generation procedure can be roughly categorized into three steps: document preparation, prompt construction, and data generation.

### Documents preparation
Users have the option to upload their private documents in either PDF or Markdown format. To ensure effective context understanding by the model, it is advisable to split lengthy documents into smaller paragraphs. The documents are saved in the following format:

 ```python
{"doc":xxxx, "doc_id":xxxx}
 ```

### Prompt construction
For each generation round, a content instance is selected to construct the input prompt.

```python
def encode_prompt_content(content):
    prompt = open("./prompt.txt").read() + "\n"
    prompt_instructions = re.sub(r"\s+", " ", content).strip().rstrip(":")
    prompt += f"Content: {content}\n"
    prompt += f"###\n"
    prompt += f"List of instructions:\n"
```

Specifically, we design the prompt template as shown in `prompt.txt` to describe our requirements for the generation prrocess:

```bash
Task: Your role is to create a total of 8 varied instructions based on the provided content to evaluate the language model's performance. These instructions will be given to a language model and we will evaluate the language model for completing the instructions.

Requirements:
1. The instructions should cover a wide range of task types including, but not limited to, open-ended generation, QA, classification, decision-making, code generation, etc.
2. For each task, generate an appropriate correct response and a false answer. 
3. All instructions must be written in English. 
4. Each generated instruction should follow this format: {id "Instruction:[content] Correct Answer:[answer] Fake Answer:[answer]" ###}. 
5. Avoid vague references like "from the previous text" or "given the content" in the instruction. Clearly state the required content in each instruction. 
6. Begin each instruction instance with a numerical ID, starting from 1. 
```

### Data generation
Before using ChatGPT to generate the instruction samples, it is necessary to configure the parameters for decoding.
```python
class OpenAIDecodingArguments(object):
    max_tokens: int = 3584
    temperature: float = 1.0
    top_p: float = 1.0
    n: int = 1
    stream: bool = False
    stop: Optional[Sequence[str]] = None
    presence_penalty: float = 1.0
    frequency_penalty: float = 0.0
    suffix: Optional[str] = None
    logprobs: Optional[int] = None
    echo: bool = False
```

Next, the arguments and prompts will be sent to the OpenAI API to initiate the generation process:
```python
completion_batch = openai.Completion.create(prompt=prompt_batch, **shared_kwargs)
```
In this code snippet, `**shared_kwargs` includes the `model_name` and `OpenAIDecodingArguments`. Here, we set `model_name` as `text-davinci-003` to conduct the decoding process. However, users have the flexibility to select other models listed on the [OpenAI website](https://platform.openai.com/docs/models/overview) based on their specific needs.

To address the issue of downstream student models not being able to handle multimedia information, a data processing step is implemented to filter out inappropriate instructions using a blacklist. This blacklist can be manually designed by the user to meet their specific requirements. Here is an example of how the filtering process can be implemented:
```python
if any(find_word_in_string(word, instruct) for word in blacklist):
    continue
# filter those starting with punctuation
if inst[0] in string.punctuation:
    continue
# filter those starting with non-english character
if not inst[0].isascii():
    continue
instructions.append({"instruction": instruct, "correct": correct, "fake": fake})
```
After the instructions have been filtered, they are then reviewed by a human expert to ensure that the generated instruction samples do not contain harmful or inappropriate content. The filtered data is stored locally for further model fine-tuning.


## Examples
Below are some examples that are generated by our method,
```python
{
    "instruction": "Generate the main advantages of Xeon CPUs.",
    "correct": "Xeon CPUs offer a single hardware and software platform from the data center to the factory floor and provide acceleration beyond expectations to meet service level agreements (SLAs).",
    "fake": "Xeon CPUs are designed for AI code, which reduces hardware cost."
},
{
    "instruction": "Generate a code snippet for the optimization technique of low precision inference.",
    "correct": "function optimizeLowPrecisionInference(){\n const x = accuracy + complexity;\n const y = model_updates * speed;\n return x/y; \n}",
    "fake": "function optimizeLowPrecisionInference(){\n var a = tensorflow + pytorch;\n return a}}"
},
{
    "instruction": "Describe how performance speeds up when moving from 3rd-gen to 4th-gen Intel Xeon processors using Intel AMX.",
    "correct": "Popular AI models can achieve up to 19x faster performance speeds when moving from 3rd Gen to 4th Gen Intel Xeon processors using Intel AMX.",
    "fake": "Popular AI models experience a dramatic decrease of up to 80% in performance speeds when moving from 3rd Gen to 4th Gen Intel Xeon processors using Intel AMX."
},
```
