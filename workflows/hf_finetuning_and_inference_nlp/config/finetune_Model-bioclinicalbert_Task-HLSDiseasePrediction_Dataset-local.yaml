# Copyright (c) 2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

args:
  model_name_or_path: "emilyalsentzer/Bio_ClinicalBERT"
  tokenizer_name: "emilyalsentzer/Bio_ClinicalBERT"
  dataset: "local" # local or huggingface datasets name

  # Add local dataset configurations below. Skip for HF datasets.
  # Make sure to specify your local dataset . The code will fail otherwise.
  local_dataset:
    finetune_input : '/workspace/dataset/annotation.csv'
    inference_input : '/workspace/dataset/annotation.csv'
    delimiter: ","
    features:
      class_label: "label"
      data_column: "symptoms"
      id: "Patient_ID"
    label_list: ["Malignant", "Normal", "Benign"]

  # Add the fine tuning configurations below
  pipeline: "finetune"
  finetune_impl: "itrex"
  dtype_ft: "fp32"
  max_seq_len: 64
  smoke_test: false
  max_train_samples: null
  max_test_samples: null
  preprocessing_num_workers: 8
  overwrite_cache: true
  finetune_output: "finetune_predictions_report.yaml"
  save_detailed_performance_metrics: true

training_args:
  num_train_epochs: 1
  do_train: true
  do_predict: true
  per_device_train_batch_size: 100
  per_device_eval_batch_size: 100
  output_dir: "./output_dir"
