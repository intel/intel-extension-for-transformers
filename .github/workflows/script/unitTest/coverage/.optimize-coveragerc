[run]
branch = True

[report]
omit =
 */**/fake*yaml
 */**/fake.py
 */intel_extension_for_transformers/llm/amp/**
 */intel_extension_for_transformers/llm/finetuning/**
 */intel_extension_for_transformers/llm/inference/**
 */intel_extension_for_transformers/llm/library/**
 */intel_extension_for_transformers/llm/operator/**
 */intel_extension_for_transformers/llm/runtime/deprecated/**
 */intel_extension_for_transformers/llm/runtime/graph/**
 */intel_extension_for_transformers/neural_chat/**
 */intel_extension_for_transformers/transformers/modeling/**
 */intel_extension_for_transformers/transformers/utils/get_throughput.py
exclude_lines =
 pragma: no cover
 raise NotImplementedError
 raise TypeError
 if self.device == "gpu":
 if device == "gpu":
 except ImportError:
 except Exception as e:
 onnx_version < ONNX18_VERSION
 onnx_version >= ONNX18_VERSION
