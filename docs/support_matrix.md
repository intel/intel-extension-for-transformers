
- [Quantization](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/quantization.md#supported-feature-matrix) : Click the link

- [Weight Only Quantization](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/weightonlyquant.md#supported-framework-model-matrix) : Click the link

- [SmoothQuant](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/weightonlyquant.md#supported-framework-model-matrix) : Click the link

- [LLM Runtime](https://github.com/intel/intel-extension-for-transformers/tree/main/intel_extension_for_transformers/llm/runtime/graph) : Click the link

- Fine-tuning:
DPO, PPO, Instruction, TTS

- NeuralChat:
Intel CPU, Intel XPU, Habana Gaudi1/Gaudi2, NVidia GPU.
