
- [Quantization](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/quantization.md#supported-feature-matrix)

- [Weight Only Quantization](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/weightonlyquant.md#supported-framework-model-matrix)

- [SmoothQuant](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/weightonlyquant.md#supported-framework-model-matrix)

- [LLM Runtime](https://github.com/intel/intel-extension-for-transformers/tree/main/intel_extension_for_transformers/llm/runtime/graph)

- Fine-tuning:
DPO, PPO, Instruction, TTS

- NeuralChat:
Intel CPU, Intel XPU, Habana Gaudi1/Gaudi2, NVidia GPU.
