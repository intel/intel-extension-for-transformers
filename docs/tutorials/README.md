Tutorials
===========================
Feel free to delve into these tutorials and unlock the features in just a matter of minutes. 


| Feature |Task |Model| Notebook Link        |
| ------- | --------------------------------------------- | ----------------- | -------------------- |
|Static and dynamic post training quantization|language-modeling|Bert-Base|[Notebook](./pytorch/language-modeling/bert-base-uncased.ipynb)|
|Static and dynamic post training quantization|Multiple Choice|Bert-Base|[Notebook](./pytorch/multiple-choice/bert-base-uncased_SWAG.ipynb)|
|Static and dynamic post training quantization|Question Answering|MiniLM (Distilled from RoBERTa Large)|[Notebook](./pytorch/question-answering/Dynamic_MiniLM_SQuAD.ipynb)|
|Static and dynamic post training quantization|Question Answering|Bert Large|[Notebook](./pytorch/question-answering/bert-large-uncased-whole-word-masking-finetuned-squad.ipynb)|
|Dynamic post training quantization|Summarization|Bert Base|[Notebook](./pytorch/summarization/pegasus-samsum.ipynb)|
|Static and dynamic post training quantization|Token Classification|Distilbert Base|[Notebook](./pytorch/token-classification/distilbert_base_ner.ipynb)|
|Dynamic post training quantization|Translation|T5 small|[Notebook](./pytorch/translation/t5-small.ipynb)|
|Static and dynamic post training quantization|Text Classification|Bert Base|[Notebook](./pytorch/text-classification/bert-base-uncased-MRPC.ipynb)|
|Pruning|Text Classification|Bert base|[Notebook](./pytorch/text-classification/pruning.ipynb)|
|Distillation|Question Answering|Specified by user|[Notebook](./pytorch/question-answering/distillation.ipynb)|
|Distillation|Text Classification|Specified by user|[Notebook](./pytorch/text-classification/distillation.ipynb)|
|Prune Once for All|Text Classification|Bert base|[Notebook](./pytorch/text-classification/orchestrate_optimizations.ipynb)|
|Prune Once for All|Text Classification|Bert Mini|[Notebook](./pytorch/text-classification/orchestrate_optimizations_bert_mini.ipynb)|
|Prune Once for ALL|Question Answering|Specified by user|[Notebook](./pytorch/question-answering/orchestrate_optimizations.ipynb)|
|Prune Once for ALL|Question Answering|Bert Mini|[Notebook](./pytorch/question-answering/orchestrate_optimizations_bert_mini.ipynb)|
|Length-Adaptive Training and post training quantization|Question Answering|MiniLM|[Notebook](./pytorch/question-answering/Dynamic_MiniLM_SQuAD.ipynb)|
|Early Exit (SWEET)|Text Classification|Bert Base|[Notebook](./pytorch/text-classification/SWEET.ipynb)|
|Early Exit (TangoBERT)|Text Classification|Roberta Base + Bert Tiny|[Notebook](./pytorch/text-classification/SWEET.ipynb)|
|SetFit|Text Classification|MiniLM|[Notebook](./pytorch/text-classification/SetFit_model_compression_AGNews.ipynb)|
