Tutorials
===========================

Welcome to use these tutorials to explore the features within minutes. 



| Feature |task |Model| Notebook Link        |
| ------- | --------------------------------------------- | ----------------- | -------------------- |
|Static and dynamic post training quantization|language-modeling|Bert-Base|[Notebook](./language-modeling/bert-base-uncased.ipynb)|
|Static and dynamic post training quantization|Multiple Choice|Bert-Base|[Notebook](./multiple-choice/bert-base-uncased_SWAG.ipynb)|
|Static and dynamic post training quantization|Question Answering|MiniLM (Distilled from RoBERTa Large)|[Notebook](./question-answering/Dynamic_MiniLM_SQuAD.ipynb)|
|Length-Adaptive Training and post training quantization|Question Answering|MiniLM|[Notebook](./question-answering/Dynamic_MiniLM_SQuAD.ipynb)|
|Static and dynamic post training quantization|Question Answering|Bert Large|[Notebook](./question-answering/bert-large-uncased-whole-word-masking-finetuned-squad.ipynb)|
|Distillation|Question Answering|n/a|[Notebook](./question-answering/distillation.ipynb)|
|Prune Once for ALL|Question Answering|n/a|[Notebook](./question-answering/orchestrate_optimizations.ipynb)|
|Prune Once for ALL|Question Answering|Bert Mini|[Notebook](./question-answering/orchestrate_optimizations_bert_mini.ipynb)|
