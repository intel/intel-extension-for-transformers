:py:mod:`intel_extension_for_transformers.llm.runtime.deprecated.compile.sub_graph.attention_mask_length_adaptive_keep_indices`
===============================================================================================================================

.. py:module:: intel_extension_for_transformers.llm.runtime.deprecated.compile.sub_graph.attention_mask_length_adaptive_keep_indices

.. autoapi-nested-parse::

   The AttentionMaskLengthAdaptiveExpandIndices Pattern.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   intel_extension_for_transformers.llm.runtime.deprecated.compile.sub_graph.attention_mask_length_adaptive_keep_indices.AttentionMaskLengthAdaptiveExpandIndices




.. py:class:: AttentionMaskLengthAdaptiveExpandIndices




   The AttentionMaskLengthAdaptiveExpandIndices pattern.

   Fuse the original sub-graph into the custom acceleration 'AttentionMaskLengthAdaptiveExpandIndices' graph.
   The fusion strategy is based on 'AddClsToken' pattern map configurations and different kinds of models.


