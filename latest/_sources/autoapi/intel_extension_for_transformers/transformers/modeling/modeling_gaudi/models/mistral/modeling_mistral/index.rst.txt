intel_extension_for_transformers.transformers.modeling.modeling_gaudi.models.mistral.modeling_mistral
=====================================================================================================

.. py:module:: intel_extension_for_transformers.transformers.modeling.modeling_gaudi.models.mistral.modeling_mistral

.. autoapi-nested-parse::

   PyTorch Mistral model.



Functions
---------

.. autoapisummary::

   intel_extension_for_transformers.transformers.modeling.modeling_gaudi.models.mistral.modeling_mistral.gaudi_mistral_rmsnorm_forward
   intel_extension_for_transformers.transformers.modeling.modeling_gaudi.models.mistral.modeling_mistral.gaudi_mistral_repeat_kv


Module Contents
---------------

.. py:function:: gaudi_mistral_rmsnorm_forward(self, hidden_states)

   The only differences are:
       - override RMSNorm with Habana fused RMSNorm


.. py:function:: gaudi_mistral_repeat_kv(query_states: torch.Tensor, key_states: torch.Tensor, value_states: torch.Tensor, attention_mask: torch.Tensor, n_rep: int)

   The only differences are:
       - Append num_key_value_heads == 1 check as kv states can be broadcasted during
         matmuls so need to expand and reshape them.
       - Add new args query_states, key_states, value_states and attention_mask and update the logic for expansion.
   The query states go from (batch, num_heads, seqlen, head_dim) to
   (batch, num_key_value_heads, n_rep, seqlen, head_dim)
   The key/value states go from (batch, num_key_value_heads, seqlen, head_dim) to
   (batch, num_key_value_heads, 1, seqlen, head_dim)


