<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Distillation &mdash; Intel® Extension for Transformers 0.1.dev1+g5b64759 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=68dfede1" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "intel-extension-for-transformers"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pruning" href="pruning.html" />
    <link rel="prev" title="Quantization" href="quantization.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Intel® Extension for Transformers
          </a>
            <div class="version">
              <a href="../../versions.html">latest▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../user_guide.html">User Guide</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../feature.html">Features</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#usage">usage</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pruning.html">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="autodistillation.html">AutoDistillation Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_augmentation.html">Data Augmentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="benchmark.html">Benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="export.html">Export to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="objectives.html">Objective</a></li>
<li class="toctree-l3"><a class="reference internal" href="pipeline.html">Pipeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../neural_engine.html">Neural Engine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../kernel.html">Kernels</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../example.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_doc/api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="release.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/intel-extension-for-transformers">Repo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Extension for Transformers</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../user_guide.html">User Guide</a></li>
          <li class="breadcrumb-item"><a href="../feature.html">Features</a></li>
      <li class="breadcrumb-item active">Distillation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/docs/distillation.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="distillation">
<h1>Distillation<a class="headerlink" href="#distillation" title="Link to this heading"></a></h1>
<ol>
<li><p><a class="reference external" href="#introduction">Introduction</a></p>
<p>1.1 <a class="reference external" href="#distillation">Distillation</a></p>
<p>1.2 <a class="reference external" href="#knowledge-distillation">Knowledge Distillation</a></p>
<p>1.3 <a class="reference external" href="#intermediate-layer-knowledge-distillation">Intermediate Layer Knowledge Distillation</a></p>
</li>
<li><p><a class="reference external" href="#usage">usage</a></p>
<p>2.1 <a class="reference external" href="#pytorch-script">Pytorch Script</a></p>
<p>2.2 <a class="reference external" href="#tensorflow-script">Tensorflow Script</a></p>
<p>2.3 <a class="reference external" href="#create-an-instance-of-metric">Create an Instance of Metric</a></p>
<p>2.4 <a class="reference external" href="#create-an-instance-of-criterionoptional">Create an Instance of Criterion(Optional)</a></p>
<p>2.5 <a class="reference external" href="#create-an-instance-of-distillationconfig">Create an Instance of DistillationConfig</a></p>
<p>2.6 <a class="reference external" href="#distill-with-trainer">Distill with Trainer</a></p>
</li>
</ol>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<section id="id1">
<h3>Distillation<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<p>Distillation is a widely-used approach to perform network compression, which transfers knowledge from a large model to a smaller one without significant loss of validity. As smaller models are less expensive to evaluate, they can be deployed on less powerful hardware (such as a mobile device). Graph shown below is the workflow of the distillation, the teacher model will take the same input that feed into the student model to produce the output that contains knowledge of the teacher model to instruct the student model.
<br></p>
<img src="./imgs/Distillation_workflow.png" alt="Architecture" width=700 height=300>
<br></section>
<section id="knowledge-distillation">
<h3>Knowledge Distillation<a class="headerlink" href="#knowledge-distillation" title="Link to this heading"></a></h3>
<p>Knowledge distillation is proposed in <a class="reference external" href="https://arxiv.org/abs/1503.02531">Distilling the Knowledge in a Neural Network</a>. It leverages the logits (the input of softmax in the classification tasks) of teacher and student model to minimize the the difference between their predicted class distributions, this can be done by minimizing the below loss function.</p>
<p>$$L_{KD} = D(z_t, z_s)$$</p>
<p>Where $D$ is a distance measurement, e.g. Euclidean distance and Kullback–Leibler divergence, $z_t$ and $z_s$ are the logits of teacher and student model, or predicted distributions from softmax of the logits in case the distance is measured in terms of distribution.</p>
</section>
<section id="intermediate-layer-knowledge-distillation">
<h3>Intermediate Layer Knowledge Distillation<a class="headerlink" href="#intermediate-layer-knowledge-distillation" title="Link to this heading"></a></h3>
<p>There are more information contained in the teacher model beside its logits, for example, the output features of the teacher model’s intermediate layers often been used to guide the student model, as in <a class="reference external" href="https://arxiv.org/pdf/1908.09355">Patient Knowledge Distillation for BERT Model Compression</a> and <a class="reference external" href="https://arxiv.org/abs/2004.02984">MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices</a>. The general loss function for this approach can be summarized as follow.</p>
<p>$$L_{KD} = \sum\limits_i D(T_t^{n_i}(F_t^{n_i}), T_s^{m_i}(F_s^{m_i}))$$</p>
<p>Where $D$ is a distance measurement as before, $F_t^{n_i}$ the output feature of the $n_i$’s layer of the teacher model, $F_s^{m_i}$ the output feature of the $m_i$’s layer of the student model. Since the dimensions of $F_t^{n_i}$ and $F_s^{m_i}$ are usually different, the transformations $T_t^{n_i}$ and $T_s^{m_i}$ are needed to match dimensions of the two features. Specifically, the transformation can take the forms like identity, linear transformation, 1X1 convolution etc.</p>
</section>
</section>
<section id="usage">
<h2>usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h2>
<section id="pytorch-script">
<h3>Pytorch Script:<a class="headerlink" href="#pytorch-script" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">intel_extension_for_transformers.transformers</span> <span class="kn">import</span> <span class="n">metric</span><span class="p">,</span> <span class="n">objectives</span><span class="p">,</span> <span class="n">DistillationConfig</span><span class="p">,</span> <span class="n">Criterion</span>
<span class="kn">from</span> <span class="nn">intel_extension_for_transformers.transformers.trainer</span> <span class="kn">import</span> <span class="n">NLPTrainer</span>
<span class="c1"># Replace transformers.Trainer with NLPTrainer</span>
<span class="c1"># trainer = transformers.Trainer(......)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">NLPTrainer</span><span class="p">(</span><span class="o">......</span><span class="p">)</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;eval_accuracy&quot;</span><span class="p">)</span>
<span class="n">d_conf</span> <span class="o">=</span> <span class="n">DistillationConfig</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">tune_metric</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distill</span><span class="p">(</span>
    <span class="n">distillation_config</span><span class="o">=</span><span class="n">d_conf</span><span class="p">,</span> <span class="n">teacher_model</span><span class="o">=</span><span class="n">teacher_model</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="../examples/huggingface/pytorch/text-classification/distillation/run_glue.py">example</a> for the details.</p>
</section>
<section id="tensorflow-script">
<h3>Tensorflow Script:<a class="headerlink" href="#tensorflow-script" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">intel_extension_for_transformers.transformers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">DistillationConfig</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">intel_extension_for_transformers.transformers.distillation</span> <span class="kn">import</span> <span class="n">Criterion</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">TFOptimization</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">metric_</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;eval_accuracy&quot;</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">Criterion</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;KnowledgeLoss&#39;</span><span class="p">,</span>
                    <span class="n">layer_mappings</span><span class="o">=</span><span class="p">[[</span><span class="s1">&#39;classifier&#39;</span><span class="p">,</span> <span class="s1">&#39;classifier&#39;</span><span class="p">]],</span>
                    <span class="n">loss_types</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CE&#39;</span><span class="p">,</span> <span class="s1">&#39;CE&#39;</span><span class="p">],</span>
                    <span class="n">loss_weight_ratio</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
                    <span class="n">add_origin_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">distillation_conf</span> <span class="o">=</span> <span class="n">DistillationConfig</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">metric_</span><span class="p">,</span>
                                        <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">)</span>
<span class="n">distilled_model</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">distill</span><span class="p">(</span>
            <span class="n">distillation_config</span><span class="o">=</span><span class="n">distillation_conf</span><span class="p">,</span>
            <span class="n">teacher_model</span><span class="o">=</span><span class="n">teacher_model</span><span class="p">)</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="../examples/huggingface/tensorflow/text-classification/distillation/run_glue.py">example</a> for the details.</p>
</section>
<section id="create-an-instance-of-metric">
<h3>Create an Instance of Metric<a class="headerlink" href="#create-an-instance-of-metric" title="Link to this heading"></a></h3>
<p>The Metric defines which metric will be used to measure the performance of tuned models.</p>
<ul>
<li><p>example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metric</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;eval_accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="metrics.html">metrics document</a> for the details.</p>
</li>
</ul>
</section>
<section id="create-an-instance-of-criterion-optional">
<h3>Create an Instance of Criterion(Optional)<a class="headerlink" href="#create-an-instance-of-criterion-optional" title="Link to this heading"></a></h3>
<p>The criterion used in training phase.</p>
<ul>
<li><p>arguments:
|Argument   |Type       |Description                                        |Default value    |
|:———-|:———-|:———————————————–|:—————-|
|name       |String|Name of criterion, like:”KnowledgeLoss”, “IntermediateLayersLoss”  |”KnowledgeLoss”|
|temperature|Float |parameter for KnowledgeDistillationLoss               |1.0             |
|loss_types|List of string|Type of loss                               |[’CE’, ‘CE’]        |
|loss_weight_ratio|List of float|weight ratio of loss                 |[0.5, 0.5]     |
|layer_mappings|List|parameter for IntermediateLayersLoss             |[] |
|add_origin_loss|bool|parameter for IntermediateLayersLoss            |False |</p></li>
<li><p>example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">Criterion</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;KnowledgeLoss&#39;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="create-an-instance-of-distillationconfig">
<h3>Create an Instance of DistillationConfig<a class="headerlink" href="#create-an-instance-of-distillationconfig" title="Link to this heading"></a></h3>
<p>The DistillationConfig contains all the information related to the model distillation behavior. If you created Metric and Criterion instance, then you can create an instance of DistillationConfig. Metric and pruner_config is optional.</p>
<ul>
<li><p>arguments:
|Argument   |Type       |Description                                        |Default value    |
|:———-|:———-|:———————————————–|:—————-|
|framework  |string     |which framework you used                        |”pytorch”        |
|criterion|Criterion |criterion of training                              |”KnowledgeLoss”|
|metrics    |Metric    |Used to evaluate accuracy of tuning model, no need for NoTrainerOptimizer|None    |</p></li>
<li><p>example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">d_conf</span> <span class="o">=</span> <span class="n">DistillationConfig</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="distill-with-trainer">
<h3>Distill with Trainer<a class="headerlink" href="#distill-with-trainer" title="Link to this heading"></a></h3>
<ul>
<li><p>Distill with Trainer
NLPTrainer inherits from transformers.Trainer, so you can create a trainer as in examples of Transformers. Then you can distill model with trainer.distill function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">distill</span><span class="p">(</span>
    <span class="n">distillation_config</span><span class="o">=</span><span class="n">d_conf</span><span class="p">,</span> <span class="n">teacher_model</span><span class="o">=</span><span class="n">teacher_model</span>
<span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quantization.html" class="btn btn-neutral float-left" title="Quantization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="pruning.html" class="btn btn-neutral float-right" title="Pruning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Extension for Transformers, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x7fd4007895d0> 
  <p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a> <a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a></div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>