<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Setup Conda &mdash; Intel® Extension for Transformers 0.1.dev1+g8722443 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/custom.css?v=68dfede1" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "intel-extension-for-transformers"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../../../index.html" class="icon icon-home">
            Intel® Extension for Transformers
          </a>
            <div class="version">
              <a href="../../../../../../../../../versions.html">latest▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../example.html">Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../api_doc/api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../release.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../legal.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/intel-extension-for-transformers">Repo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">Intel® Extension for Transformers</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Setup Conda</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../../_sources/docs/intel_extension_for_transformers/neural_chat/examples/deployment/talkingbot/server/backend/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>This README is intended to guide you through setting up the backend for a voice chatbot using the NeuralChat framework. You can deploy this text chatbot on various platforms, including Intel XEON Scalable Processors, Habana’s Gaudi processors (HPU), Intel Data Center GPU and Client GPU, Nvidia Data Center GPU and Client GPU.</p>
<section id="setup-conda">
<h1>Setup Conda<a class="headerlink" href="#setup-conda" title="Link to this heading"></a></h1>
<p>First, you need to install and configure the Conda environment:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and install Miniconda</span>
wget<span class="w"> </span>https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash<span class="w"> </span>Miniconda*.sh
<span class="nb">source</span><span class="w"> </span>~/.bashrc
</pre></div>
</div>
</section>
<section id="install-numactl">
<h1>Install numactl<a class="headerlink" href="#install-numactl" title="Link to this heading"></a></h1>
<p>Next, install the numactl library:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt<span class="w"> </span>install<span class="w"> </span>numactl
</pre></div>
</div>
</section>
<section id="install-python-dependencies">
<h1>Install Python dependencies<a class="headerlink" href="#install-python-dependencies" title="Link to this heading"></a></h1>
<p>Install the following Python dependencies using Conda:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>astunparse<span class="w"> </span>ninja<span class="w"> </span>pyyaml<span class="w"> </span>mkl<span class="w"> </span>mkl-include<span class="w"> </span>setuptools<span class="w"> </span>cmake<span class="w"> </span>cffi<span class="w"> </span>typing_extensions<span class="w"> </span>future<span class="w"> </span>six<span class="w"> </span>requests<span class="w"> </span>dataclasses<span class="w"> </span>-y
conda<span class="w"> </span>install<span class="w"> </span>jemalloc<span class="w"> </span>gperftools<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>-y
conda<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>-y<span class="w"> </span>pyg<span class="w"> </span>-c<span class="w"> </span>pyg
conda<span class="w"> </span>install<span class="w"> </span>-q<span class="w"> </span>-y<span class="w"> </span>pytorch<span class="w"> </span><span class="nv">cudatoolkit</span><span class="o">=</span><span class="m">11</span>.3<span class="w"> </span>-c<span class="w"> </span>pytorch
</pre></div>
</div>
<p>Install other dependencies using pip:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>../../../requirements.txt
pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>torch<span class="w"> </span>torchaudio<span class="w"> </span>--no-cache-dir
</pre></div>
</div>
</section>
<section id="configure-the-voicebot-yaml">
<h1>Configure the voicebot.yaml<a class="headerlink" href="#configure-the-voicebot-yaml" title="Link to this heading"></a></h1>
<p>You can customize the configuration file ‘textbot.yaml’ to match your environment setup. Here’s a table to help you understand the configurable options:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Item</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>host</td>
<td>127.0.0.1</td>
</tr>
<tr>
<td>port</td>
<td>8888</td>
</tr>
<tr>
<td>model_name_or_path</td>
<td>"Intel/neural-chat-7b-v3-1"</td>
</tr>
<tr>
<td>device</td>
<td>"cpu"</td>
</tr>
<tr>
<td>asr.enable</td>
<td>true</td>
</tr>
<tr>
<td>asr.args.device</td>
<td>"cpu"</td>
</tr>
<tr>
<td>asr.args.model_name_or_path</td>
<td>"openai/whisper-small"</td>
</tr>
<tr>
<td>asr.args.bf16</td>
<td>false</td>
</tr>
<tr>
<td>tts.enable</td>
<td>true</td>
</tr>
<tr>
<td>tts.args.device</td>
<td>"cpu"</td>
</tr>
<tr>
<td>tts.args.voice</td>
<td>"default"</td>
</tr>
<tr>
<td>tts.args.stream_mode</td>
<td>true</td>
</tr>
<tr>
<td>tts.args.output_audio_path</td>
<td>"./output_audio"</td>
</tr>
<tr>
<td>tts.args.speedup</td>
<td>1.0</td>
</tr>
<tr>
<td>tasks_list</td>
<td>['voicechat']</td>
</tr>
</tbody>
</table></section>
<section id="run-the-voicechat-server">
<h1>Run the VoiceChat server<a class="headerlink" href="#run-the-voicechat-server" title="Link to this heading"></a></h1>
<p>To start the VoiceChat server, use the following command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>nohup<span class="w"> </span>bash<span class="w"> </span>run.sh<span class="w"> </span><span class="p">&amp;</span>
</pre></div>
</div>
</section>
<section id="quick-test-with-openai-compatible-endpoints-audio">
<h1>Quick test with OpenAI compatible endpoints (audio)<a class="headerlink" href="#quick-test-with-openai-compatible-endpoints-audio" title="Link to this heading"></a></h1>
<p>To make our audio service compatible to OpenAI <a class="reference external" href="https://platform.openai.com/docs/api-reference/audio/">endpoints</a>, we offer the following three endpoints:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">v1</span><span class="o">/</span><span class="n">audio</span><span class="o">/</span><span class="n">speech</span>
<span class="o">/</span><span class="n">v1</span><span class="o">/</span><span class="n">audio</span><span class="o">/</span><span class="n">transcriptions</span>
<span class="o">/</span><span class="n">v1</span><span class="o">/</span><span class="n">audio</span><span class="o">/</span><span class="n">translations</span>
</pre></div>
</div>
<p>To test whether the talkingbot server can serve your requests correctly, you can use <code class="docutils literal notranslate"><span class="pre">curl</span></code> as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://localhost:8888/v1/audio/translations<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: multipart/form-data&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-F<span class="w"> </span><span class="nv">file</span><span class="o">=</span><span class="s2">&quot;@sample_1.wav&quot;</span>

curl<span class="w"> </span>http://localhost:8888/v1/audio/transcriptions<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: multipart/form-data&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-F<span class="w"> </span><span class="nv">file</span><span class="o">=</span><span class="s2">&quot;@sample_zh_cn.wav&quot;</span>

curl<span class="w"> </span>http://localhost:8888/v1/audio/speech<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;speecht5&quot;,</span>
<span class="s1">    &quot;input&quot;: &quot;The quick brown fox jumped over the lazy dog.&quot;,</span>
<span class="s1">    &quot;voice&quot;: &quot;default&quot;</span>
<span class="s1">  }&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--output<span class="w"> </span>speech.mp3

<span class="c1"># To use multi-language TTS, please</span>
<span class="c1"># 1) set `enable: false` under tts in talkingbot.yaml</span>
<span class="c1"># 2) set `enable: true` under tts_multilang in talkingbot.yaml</span>
curl<span class="w"> </span>http://localhost:8888/v1/audio/speech<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">    &quot;model&quot;: &quot;bert-vits2&quot;,</span>
<span class="s1">    &quot;input&quot;: &quot;欢迎来到英特尔。&quot;,</span>
<span class="s1">    &quot;voice&quot;: &quot;default&quot;</span>
<span class="s1">  }&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--output<span class="w"> </span>speech.mp3
</pre></div>
</div>
</section>
<section id="customized-endpoints-of-a-audio-input-audio-output-pipeline">
<h1>Customized endpoints of a audio-input-audio-output pipeline<a class="headerlink" href="#customized-endpoints-of-a-audio-input-audio-output-pipeline" title="Link to this heading"></a></h1>
<p>You can check <code class="docutils literal notranslate"><span class="pre">intel_extension_for_transformers/neural_chat/server/restful/voicechat_api.py</span></code> to see the other customized endpoints offered by us:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">v1</span><span class="o">/</span><span class="n">talkingbot</span><span class="o">/</span><span class="n">asr</span>
<span class="o">/</span><span class="n">v1</span><span class="o">/</span><span class="n">talkingbot</span><span class="o">/</span><span class="n">llm_tts</span>
<span class="o">/</span><span class="n">v1</span><span class="o">/</span><span class="n">talkingbot</span><span class="o">/</span><span class="n">create_embedding</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">/v1/talkingbot/asr</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">/v1/audio/transcriptions</span></code> and for backward compatibility we simply keep that for audio-to-speech conversion.
<code class="docutils literal notranslate"><span class="pre">/v1/talkingbot/llm_tts</span></code> merges two tasks: <code class="docutils literal notranslate"><span class="pre">LLM</span> <span class="pre">text</span> <span class="pre">generation</span></code> and the <code class="docutils literal notranslate"><span class="pre">text</span> <span class="pre">to</span> <span class="pre">speech</span></code> into one process, which is designed specifically for converting steadily the LLM streaming outputs to speech.
<code class="docutils literal notranslate"><span class="pre">/v1/talkingbot/create_embedding</span></code> is used to create a SpeechT5 speaker embedding for zero-shot voice cloning. Although voice-cloning is relatively weak for SpeechT5, we still keep this endpoint for quick start. If you want to clone your voice properly, please check the current best practices for SpeechT5 based on few-shot voice-cloning finetuning in this <a class="reference external" href="../../../../finetuning/tts/">repo</a>.</p>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Extension for Transformers, Intel.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x7f1689fc6fe0> 
  <p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a> <a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a></div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>