accelerate
datasets >= 2.0
diffusers
peft
protobuf
sentencepiece != 0.1.92
--extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
torch==2.1.0a0
transformers
optimum-intel
bitsandbytes  #baichuan
transformers_stream_generator
tiktoken  #qwen
einops  #qwen
git+https://github.com/intel/auto-round.git@ecca5349981044e1278773a251b3fc5c0a11fe7b
git+https://github.com/intel/neural-compressor.git
lm-eval==0.4.2
