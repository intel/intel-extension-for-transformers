accelerate
datasets >= 2.0
peft
protobuf
sentencepiece != 0.1.92
--extra-index-url https://download.pytorch.org/whl/cpu
torch==2.2.0+cpu
transformers
intel_extension_for_pytorch==2.2.0
optimum-intel
bitsandbytes  #baichuan
transformers_stream_generator
tiktoken  #qwen
einops  #qwen
git+https://github.com/intel/neural-compressor.git
git+https://github.com/EleutherAI/lm-evaluation-harness.git@cc9778fbe4fa1a709be2abed9deb6180fd40e7e2
git+https://github.com/intel/auto-round.git@6815f8b66be456ecbef2d0beb33dbc4efeefdc04
