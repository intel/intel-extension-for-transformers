{
    "llama2_7b_neural_speed": {
        "working_dir": "huggingface/neural_speed",
        "data_dir": "",
        "hf_model_name": "meta-llama/Llama-2-7b-hf",
        "benchmark": {
            "cmd": "python run_accuracy.py",
            "params": {
                "model_name": "/tf_dataset2/models/nlp_toolkit/llama-2-7b-chat/Llama-2-7b-chat-hf",
                "model_format": "runtime",
                "tasks": "lambada_openai"
            }
        },
        "launcher":{}
    },
    "neural_chat_v3-1_neural_speed": {
        "working_dir": "huggingface/neural_speed",
        "data_dir": "",
        "hf_model_name": "Intel/neural-chat-7b-v3-1",
        "benchmark": {
            "cmd": "python run_accuracy.py",
            "params": {
                "model_name": "/tf_dataset2/models/nlp_toolkit/neural-chat-7b-v3-1",
                "model_format": "runtime",
                "tasks": "piqa"
            }
        },
        "launcher":{}
    },
    "neural_chat_v3-3_autoround_neural_speed": {
        "working_dir": "huggingface/neural_speed",
        "data_dir": "",
        "hf_model_name": "Intel/neural-chat-7b-v3-3",
        "benchmark": {
            "cmd": "python run_accuracy.py",
            "params": {
                "model_name": "/tf_dataset2/models/auto_round/neuralchat_v3-3",
                "model_format": "runtime",
                "tasks": "lambada_openai"
            }
        },
        "launcher":{}
    },
    "mistral_7b_neural_speed": {
        "working_dir": "huggingface/neural_speed",
        "data_dir": "",
        "hf_model_name": "mistralai/Mistral-7B-v0.1",
        "benchmark": {
            "cmd": "python run_accuracy.py",
            "params": {
                "model_name": "/tf_dataset2/models/pytorch/Mistral-7B-v0.1",
                "model_format": "runtime",
                "tasks": "piqa"
            }
        },
        "launcher":{}
    },
    "qwen_neural_speed": {
        "working_dir": "huggingface/neural_speed",
        "data_dir": "",
        "hf_model_name": "Qwen/Qwen-7B-Chat",
        "benchmark": {
            "cmd": "python run_accuracy.py",
            "params": {
                "model_name": "/tf_dataset2/models/nlp_toolkit/Qwen-7B-Chat",
                "model_format": "runtime",
                "tasks": "lambada_openai"
            }
        },
        "launcher":{}
    }
}