model:
  name: model
  operator:
    input_data:
      type: Input
      output:
        sample:0:
          dtype: fp32
          shape: [-1, -1, -1, -1]
        timestep:0:
          dtype: fp32
          shape: [-1]
        encoder_hidden_states:0:
          dtype: fp32
          shape: [-1, -1, 768]
        /time_proj/Constant_1_output_0:0:
          dtype: fp32
          shape: [1, 160]
          location: [0, 640]
        time_embedding.linear_1.weight:0:
          dtype: bf16
          shape: [1280, 320]
          location: [640, 819200]
        time_embedding.linear_1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [819840, 2560]
        conv_in.weight:0:
          dtype: bf16
          shape: [320, 8, 3, 3]
          location: [822400, 46080]
        conv_in.bias:0:
          dtype: bf16
          shape: [320]
          location: [868480, 640]
        onnx::Mul_9050:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [869120, 1280]
        onnx::Add_9051:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [870400, 1280]
        down_blocks.0.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [871680, 1843200]
        down_blocks.0.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [320]
          location: [2714880, 640]
        time_embedding.linear_2.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [2715520, 3276800]
        time_embedding.linear_2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [5992320, 2560]
        down_blocks.0.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [320, 1280]
          location: [5994880, 819200]
        down_blocks.0.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [320]
          location: [6814080, 640]
        onnx::Mul_9052:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [6814720, 1280]
        onnx::Add_9053:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [6816000, 1280]
        down_blocks.0.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [6817280, 1843200]
        down_blocks.0.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [320]
          location: [8660480, 640]
        /down_blocks.0/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [8661120, 4]
        onnx::Mul_9054:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [8661124, 1280]
        onnx::Add_9055:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [8662404, 1280]
        down_blocks.0.attentions.0.proj_in.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [8663684, 204800]
        down_blocks.0.attentions.0.proj_in.bias:0:
          dtype: bf16
          shape: [320]
          location: [8868484, 640]
        down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [320]
          location: [8869124, 1280]
        down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [320]
          location: [8870404, 1280]
        onnx::MatMul_9056:0:
          dtype: bf16
          shape: [320, 320]
          location: [8871684, 204800]
        onnx::MatMul_9058:0:
          dtype: bf16
          shape: [320, 320]
          location: [9076484, 204800]
        onnx::MatMul_9059:0:
          dtype: bf16
          shape: [320, 320]
          location: [9281284, 204800]
        onnx::MatMul_9065:0:
          dtype: bf16
          shape: [320, 320]
          location: [9486084, 204800]
        down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [9690884, 640]
        down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [320]
          location: [9691524, 1280]
        down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [320]
          location: [9692804, 1280]
        onnx::MatMul_9066:0:
          dtype: bf16
          shape: [320, 320]
          location: [9694084, 204800]
        onnx::MatMul_9068:0:
          dtype: bf16
          shape: [768, 320]
          location: [9898884, 491520]
        onnx::MatMul_9069:0:
          dtype: bf16
          shape: [768, 320]
          location: [10390404, 491520]
        onnx::MatMul_9075:0:
          dtype: bf16
          shape: [320, 320]
          location: [10881924, 204800]
        down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [11086724, 640]
        down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [320]
          location: [11087364, 1280]
        down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [320]
          location: [11088644, 1280]
        onnx::MatMul_9076:0:
          dtype: bf16
          shape: [320, 2560]
          location: [11089924, 1638400]
        down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [2560]
          location: [12728324, 5120]
        onnx::MatMul_9077:0:
          dtype: bf16
          shape: [1280, 320]
          location: [12733444, 819200]
        down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [320]
          location: [13552644, 640]
        down_blocks.0.attentions.0.proj_out.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [13553284, 204800]
        down_blocks.0.attentions.0.proj_out.bias:0:
          dtype: bf16
          shape: [320]
          location: [13758084, 640]
        onnx::Mul_9078:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [13758724, 1280]
        onnx::Add_9079:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [13760004, 1280]
        down_blocks.0.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [13761284, 1843200]
        down_blocks.0.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [320]
          location: [15604484, 640]
        down_blocks.0.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [320, 1280]
          location: [15605124, 819200]
        down_blocks.0.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [320]
          location: [16424324, 640]
        onnx::Mul_9080:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [16424964, 1280]
        onnx::Add_9081:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [16426244, 1280]
        down_blocks.0.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [16427524, 1843200]
        down_blocks.0.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [320]
          location: [18270724, 640]
        /down_blocks.0/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [18271364, 4]
        onnx::Mul_9082:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [18271368, 1280]
        onnx::Add_9083:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [18272648, 1280]
        down_blocks.0.attentions.1.proj_in.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [18273928, 204800]
        down_blocks.0.attentions.1.proj_in.bias:0:
          dtype: bf16
          shape: [320]
          location: [18478728, 640]
        down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [320]
          location: [18479368, 1280]
        down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [320]
          location: [18480648, 1280]
        onnx::MatMul_9084:0:
          dtype: bf16
          shape: [320, 320]
          location: [18481928, 204800]
        onnx::MatMul_9086:0:
          dtype: bf16
          shape: [320, 320]
          location: [18686728, 204800]
        onnx::MatMul_9087:0:
          dtype: bf16
          shape: [320, 320]
          location: [18891528, 204800]
        onnx::MatMul_9093:0:
          dtype: bf16
          shape: [320, 320]
          location: [19096328, 204800]
        down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [19301128, 640]
        down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [320]
          location: [19301768, 1280]
        down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [320]
          location: [19303048, 1280]
        onnx::MatMul_9094:0:
          dtype: bf16
          shape: [320, 320]
          location: [19304328, 204800]
        onnx::MatMul_9096:0:
          dtype: bf16
          shape: [768, 320]
          location: [19509128, 491520]
        onnx::MatMul_9097:0:
          dtype: bf16
          shape: [768, 320]
          location: [20000648, 491520]
        onnx::MatMul_9103:0:
          dtype: bf16
          shape: [320, 320]
          location: [20492168, 204800]
        down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [20696968, 640]
        down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [320]
          location: [20697608, 1280]
        down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [320]
          location: [20698888, 1280]
        onnx::MatMul_9104:0:
          dtype: bf16
          shape: [320, 2560]
          location: [20700168, 1638400]
        down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [2560]
          location: [22338568, 5120]
        onnx::MatMul_9105:0:
          dtype: bf16
          shape: [1280, 320]
          location: [22343688, 819200]
        down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [320]
          location: [23162888, 640]
        down_blocks.0.attentions.1.proj_out.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [23163528, 204800]
        down_blocks.0.attentions.1.proj_out.bias:0:
          dtype: bf16
          shape: [320]
          location: [23368328, 640]
        down_blocks.0.downsamplers.0.conv.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [23368968, 1843200]
        down_blocks.0.downsamplers.0.conv.bias:0:
          dtype: bf16
          shape: [320]
          location: [25212168, 640]
        onnx::Mul_9106:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [25212808, 1280]
        onnx::Add_9107:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [25214088, 1280]
        down_blocks.1.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [640, 320, 3, 3]
          location: [25215368, 3686400]
        down_blocks.1.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [640]
          location: [28901768, 1280]
        down_blocks.1.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [640, 1280]
          location: [28903048, 1638400]
        down_blocks.1.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [640]
          location: [30541448, 1280]
        onnx::Mul_9108:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [30542728, 2560]
        onnx::Add_9109:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [30545288, 2560]
        down_blocks.1.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [30547848, 7372800]
        down_blocks.1.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [640]
          location: [37920648, 1280]
        down_blocks.1.resnets.0.conv_shortcut.weight:0:
          dtype: bf16
          shape: [640, 320, 1, 1]
          location: [37921928, 409600]
        down_blocks.1.resnets.0.conv_shortcut.bias:0:
          dtype: bf16
          shape: [640]
          location: [38331528, 1280]
        /down_blocks.1/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [38332808, 4]
        onnx::Mul_9110:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [38332812, 2560]
        onnx::Add_9111:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [38335372, 2560]
        down_blocks.1.attentions.0.proj_in.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [38337932, 819200]
        down_blocks.1.attentions.0.proj_in.bias:0:
          dtype: bf16
          shape: [640]
          location: [39157132, 1280]
        down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [640]
          location: [39158412, 2560]
        down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [640]
          location: [39160972, 2560]
        onnx::MatMul_9112:0:
          dtype: bf16
          shape: [640, 640]
          location: [39163532, 819200]
        onnx::MatMul_9114:0:
          dtype: bf16
          shape: [640, 640]
          location: [39982732, 819200]
        onnx::MatMul_9115:0:
          dtype: bf16
          shape: [640, 640]
          location: [40801932, 819200]
        onnx::MatMul_9121:0:
          dtype: bf16
          shape: [640, 640]
          location: [41621132, 819200]
        down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [42440332, 1280]
        down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [640]
          location: [42441612, 2560]
        down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [640]
          location: [42444172, 2560]
        onnx::MatMul_9122:0:
          dtype: bf16
          shape: [640, 640]
          location: [42446732, 819200]
        onnx::MatMul_9124:0:
          dtype: bf16
          shape: [768, 640]
          location: [43265932, 983040]
        onnx::MatMul_9125:0:
          dtype: bf16
          shape: [768, 640]
          location: [44248972, 983040]
        onnx::MatMul_9131:0:
          dtype: bf16
          shape: [640, 640]
          location: [45232012, 819200]
        down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [46051212, 1280]
        down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [640]
          location: [46052492, 2560]
        down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [640]
          location: [46055052, 2560]
        onnx::MatMul_9132:0:
          dtype: bf16
          shape: [640, 5120]
          location: [46057612, 6553600]
        down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [5120]
          location: [52611212, 10240]
        onnx::MatMul_9133:0:
          dtype: bf16
          shape: [2560, 640]
          location: [52621452, 3276800]
        down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [640]
          location: [55898252, 1280]
        down_blocks.1.attentions.0.proj_out.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [55899532, 819200]
        down_blocks.1.attentions.0.proj_out.bias:0:
          dtype: bf16
          shape: [640]
          location: [56718732, 1280]
        onnx::Mul_9134:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [56720012, 2560]
        onnx::Add_9135:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [56722572, 2560]
        down_blocks.1.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [56725132, 7372800]
        down_blocks.1.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [640]
          location: [64097932, 1280]
        down_blocks.1.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [640, 1280]
          location: [64099212, 1638400]
        down_blocks.1.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [640]
          location: [65737612, 1280]
        onnx::Mul_9136:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [65738892, 2560]
        onnx::Add_9137:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [65741452, 2560]
        down_blocks.1.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [65744012, 7372800]
        down_blocks.1.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [640]
          location: [73116812, 1280]
        /down_blocks.1/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [73118092, 4]
        onnx::Mul_9138:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [73118096, 2560]
        onnx::Add_9139:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [73120656, 2560]
        down_blocks.1.attentions.1.proj_in.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [73123216, 819200]
        down_blocks.1.attentions.1.proj_in.bias:0:
          dtype: bf16
          shape: [640]
          location: [73942416, 1280]
        down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [640]
          location: [73943696, 2560]
        down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [640]
          location: [73946256, 2560]
        onnx::MatMul_9140:0:
          dtype: bf16
          shape: [640, 640]
          location: [73948816, 819200]
        onnx::MatMul_9142:0:
          dtype: bf16
          shape: [640, 640]
          location: [74768016, 819200]
        onnx::MatMul_9143:0:
          dtype: bf16
          shape: [640, 640]
          location: [75587216, 819200]
        onnx::MatMul_9149:0:
          dtype: bf16
          shape: [640, 640]
          location: [76406416, 819200]
        down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [77225616, 1280]
        down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [640]
          location: [77226896, 2560]
        down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [640]
          location: [77229456, 2560]
        onnx::MatMul_9150:0:
          dtype: bf16
          shape: [640, 640]
          location: [77232016, 819200]
        onnx::MatMul_9152:0:
          dtype: bf16
          shape: [768, 640]
          location: [78051216, 983040]
        onnx::MatMul_9153:0:
          dtype: bf16
          shape: [768, 640]
          location: [79034256, 983040]
        onnx::MatMul_9159:0:
          dtype: bf16
          shape: [640, 640]
          location: [80017296, 819200]
        down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [80836496, 1280]
        down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [640]
          location: [80837776, 2560]
        down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [640]
          location: [80840336, 2560]
        onnx::MatMul_9160:0:
          dtype: bf16
          shape: [640, 5120]
          location: [80842896, 6553600]
        down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [5120]
          location: [87396496, 10240]
        onnx::MatMul_9161:0:
          dtype: bf16
          shape: [2560, 640]
          location: [87406736, 3276800]
        down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [640]
          location: [90683536, 1280]
        down_blocks.1.attentions.1.proj_out.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [90684816, 819200]
        down_blocks.1.attentions.1.proj_out.bias:0:
          dtype: bf16
          shape: [640]
          location: [91504016, 1280]
        down_blocks.1.downsamplers.0.conv.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [91505296, 7372800]
        down_blocks.1.downsamplers.0.conv.bias:0:
          dtype: bf16
          shape: [640]
          location: [98878096, 1280]
        onnx::Mul_9162:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [98879376, 2560]
        onnx::Add_9163:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [98881936, 2560]
        down_blocks.2.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [1280, 640, 3, 3]
          location: [98884496, 14745600]
        down_blocks.2.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [113630096, 2560]
        down_blocks.2.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [113632656, 3276800]
        down_blocks.2.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [116909456, 2560]
        onnx::Mul_9164:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [116912016, 5120]
        onnx::Add_9165:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [116917136, 5120]
        down_blocks.2.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [116922256, 29491200]
        down_blocks.2.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [146413456, 2560]
        down_blocks.2.resnets.0.conv_shortcut.weight:0:
          dtype: bf16
          shape: [1280, 640, 1, 1]
          location: [146416016, 1638400]
        down_blocks.2.resnets.0.conv_shortcut.bias:0:
          dtype: bf16
          shape: [1280]
          location: [148054416, 2560]
        /down_blocks.2/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [148056976, 4]
        onnx::Mul_9166:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [148056980, 5120]
        onnx::Add_9167:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [148062100, 5120]
        down_blocks.2.attentions.0.proj_in.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [148067220, 3276800]
        down_blocks.2.attentions.0.proj_in.bias:0:
          dtype: bf16
          shape: [1280]
          location: [151344020, 2560]
        down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [1280]
          location: [151346580, 5120]
        down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [1280]
          location: [151351700, 5120]
        onnx::MatMul_9168:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [151356820, 3276800]
        onnx::MatMul_9170:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [154633620, 3276800]
        onnx::MatMul_9171:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [157910420, 3276800]
        onnx::MatMul_9177:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [161187220, 3276800]
        down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [164464020, 2560]
        down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [1280]
          location: [164466580, 5120]
        down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [1280]
          location: [164471700, 5120]
        onnx::MatMul_9178:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [164476820, 3276800]
        onnx::MatMul_9180:0:
          dtype: bf16
          shape: [768, 1280]
          location: [167753620, 1966080]
        onnx::MatMul_9181:0:
          dtype: bf16
          shape: [768, 1280]
          location: [169719700, 1966080]
        onnx::MatMul_9187:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [171685780, 3276800]
        down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [174962580, 2560]
        down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [1280]
          location: [174965140, 5120]
        down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [1280]
          location: [174970260, 5120]
        onnx::MatMul_9188:0:
          dtype: bf16
          shape: [1280, 10240]
          location: [174975380, 26214400]
        down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [10240]
          location: [201189780, 20480]
        onnx::MatMul_9189:0:
          dtype: bf16
          shape: [5120, 1280]
          location: [201210260, 13107200]
        down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [214317460, 2560]
        down_blocks.2.attentions.0.proj_out.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [214320020, 3276800]
        down_blocks.2.attentions.0.proj_out.bias:0:
          dtype: bf16
          shape: [1280]
          location: [217596820, 2560]
        onnx::Mul_9190:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [217599380, 5120]
        onnx::Add_9191:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [217604500, 5120]
        down_blocks.2.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [217609620, 29491200]
        down_blocks.2.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [247100820, 2560]
        down_blocks.2.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [247103380, 3276800]
        down_blocks.2.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [250380180, 2560]
        onnx::Mul_9192:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [250382740, 5120]
        onnx::Add_9193:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [250387860, 5120]
        down_blocks.2.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [250392980, 29491200]
        down_blocks.2.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [279884180, 2560]
        /down_blocks.2/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [279886740, 4]
        onnx::Mul_9194:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [279886744, 5120]
        onnx::Add_9195:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [279891864, 5120]
        down_blocks.2.attentions.1.proj_in.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [279896984, 3276800]
        down_blocks.2.attentions.1.proj_in.bias:0:
          dtype: bf16
          shape: [1280]
          location: [283173784, 2560]
        down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [1280]
          location: [283176344, 5120]
        down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [1280]
          location: [283181464, 5120]
        onnx::MatMul_9196:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [283186584, 3276800]
        onnx::MatMul_9198:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [286463384, 3276800]
        onnx::MatMul_9199:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [289740184, 3276800]
        onnx::MatMul_9205:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [293016984, 3276800]
        down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [296293784, 2560]
        down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [1280]
          location: [296296344, 5120]
        down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [1280]
          location: [296301464, 5120]
        onnx::MatMul_9206:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [296306584, 3276800]
        onnx::MatMul_9208:0:
          dtype: bf16
          shape: [768, 1280]
          location: [299583384, 1966080]
        onnx::MatMul_9209:0:
          dtype: bf16
          shape: [768, 1280]
          location: [301549464, 1966080]
        onnx::MatMul_9215:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [303515544, 3276800]
        down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [306792344, 2560]
        down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [1280]
          location: [306794904, 5120]
        down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [1280]
          location: [306800024, 5120]
        onnx::MatMul_9216:0:
          dtype: bf16
          shape: [1280, 10240]
          location: [306805144, 26214400]
        down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [10240]
          location: [333019544, 20480]
        onnx::MatMul_9217:0:
          dtype: bf16
          shape: [5120, 1280]
          location: [333040024, 13107200]
        down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [346147224, 2560]
        down_blocks.2.attentions.1.proj_out.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [346149784, 3276800]
        down_blocks.2.attentions.1.proj_out.bias:0:
          dtype: bf16
          shape: [1280]
          location: [349426584, 2560]
        down_blocks.2.downsamplers.0.conv.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [349429144, 29491200]
        down_blocks.2.downsamplers.0.conv.bias:0:
          dtype: bf16
          shape: [1280]
          location: [378920344, 2560]
        onnx::Mul_9218:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [378922904, 5120]
        onnx::Add_9219:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [378928024, 5120]
        down_blocks.3.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [378933144, 29491200]
        down_blocks.3.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [408424344, 2560]
        down_blocks.3.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [408426904, 3276800]
        down_blocks.3.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [411703704, 2560]
        onnx::Mul_9220:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [411706264, 5120]
        onnx::Add_9221:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [411711384, 5120]
        down_blocks.3.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [411716504, 29491200]
        down_blocks.3.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [441207704, 2560]
        /down_blocks.3/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [441210264, 4]
        onnx::Mul_9222:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [441210268, 5120]
        onnx::Add_9223:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [441215388, 5120]
        down_blocks.3.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [441220508, 29491200]
        down_blocks.3.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [470711708, 2560]
        down_blocks.3.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [470714268, 3276800]
        down_blocks.3.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [473991068, 2560]
        onnx::Mul_9224:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [473993628, 5120]
        onnx::Add_9225:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [473998748, 5120]
        down_blocks.3.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [474003868, 29491200]
        down_blocks.3.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [503495068, 2560]
        /down_blocks.3/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [503497628, 4]
        onnx::Mul_9226:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [503497632, 5120]
        onnx::Add_9227:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [503502752, 5120]
        mid_block.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [503507872, 29491200]
        mid_block.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [532999072, 2560]
        mid_block.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [533001632, 3276800]
        mid_block.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [536278432, 2560]
        onnx::Mul_9228:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [536280992, 5120]
        onnx::Add_9229:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [536286112, 5120]
        mid_block.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [536291232, 29491200]
        mid_block.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [565782432, 2560]
        /mid_block/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [565784992, 4]
        onnx::Mul_9230:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [565784996, 5120]
        onnx::Add_9231:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [565790116, 5120]
        mid_block.attentions.0.proj_in.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [565795236, 3276800]
        mid_block.attentions.0.proj_in.bias:0:
          dtype: bf16
          shape: [1280]
          location: [569072036, 2560]
        mid_block.attentions.0.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [1280]
          location: [569074596, 5120]
        mid_block.attentions.0.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [1280]
          location: [569079716, 5120]
        onnx::MatMul_9232:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [569084836, 3276800]
        onnx::MatMul_9234:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [572361636, 3276800]
        onnx::MatMul_9235:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [575638436, 3276800]
        onnx::MatMul_9241:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [578915236, 3276800]
        mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [582192036, 2560]
        mid_block.attentions.0.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [1280]
          location: [582194596, 5120]
        mid_block.attentions.0.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [1280]
          location: [582199716, 5120]
        onnx::MatMul_9242:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [582204836, 3276800]
        onnx::MatMul_9244:0:
          dtype: bf16
          shape: [768, 1280]
          location: [585481636, 1966080]
        onnx::MatMul_9245:0:
          dtype: bf16
          shape: [768, 1280]
          location: [587447716, 1966080]
        onnx::MatMul_9251:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [589413796, 3276800]
        mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [592690596, 2560]
        mid_block.attentions.0.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [1280]
          location: [592693156, 5120]
        mid_block.attentions.0.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [1280]
          location: [592698276, 5120]
        onnx::MatMul_9252:0:
          dtype: bf16
          shape: [1280, 10240]
          location: [592703396, 26214400]
        mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [10240]
          location: [618917796, 20480]
        onnx::MatMul_9253:0:
          dtype: bf16
          shape: [5120, 1280]
          location: [618938276, 13107200]
        mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [632045476, 2560]
        mid_block.attentions.0.proj_out.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [632048036, 3276800]
        mid_block.attentions.0.proj_out.bias:0:
          dtype: bf16
          shape: [1280]
          location: [635324836, 2560]
        onnx::Mul_9254:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [635327396, 5120]
        onnx::Add_9255:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [635332516, 5120]
        mid_block.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [635337636, 29491200]
        mid_block.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [664828836, 2560]
        mid_block.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [664831396, 3276800]
        mid_block.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [668108196, 2560]
        onnx::Mul_9256:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [668110756, 5120]
        onnx::Add_9257:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [668115876, 5120]
        mid_block.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [668120996, 29491200]
        mid_block.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [697612196, 2560]
        /mid_block/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [697614756, 4]
        onnx::Mul_9258:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [697614760, 10240]
        onnx::Add_9259:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [697625000, 10240]
        up_blocks.0.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [1280, 2560, 3, 3]
          location: [697635240, 58982400]
        up_blocks.0.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [756617640, 2560]
        up_blocks.0.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [756620200, 3276800]
        up_blocks.0.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [759897000, 2560]
        onnx::Mul_9260:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [759899560, 5120]
        onnx::Add_9261:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [759904680, 5120]
        up_blocks.0.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [759909800, 29491200]
        up_blocks.0.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [789401000, 2560]
        up_blocks.0.resnets.0.conv_shortcut.weight:0:
          dtype: bf16
          shape: [1280, 2560, 1, 1]
          location: [789403560, 6553600]
        up_blocks.0.resnets.0.conv_shortcut.bias:0:
          dtype: bf16
          shape: [1280]
          location: [795957160, 2560]
        /up_blocks.0/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [795959720, 4]
        onnx::Mul_9262:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [795959724, 10240]
        onnx::Add_9263:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [795969964, 10240]
        up_blocks.0.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [1280, 2560, 3, 3]
          location: [795980204, 58982400]
        up_blocks.0.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [854962604, 2560]
        up_blocks.0.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [854965164, 3276800]
        up_blocks.0.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [858241964, 2560]
        onnx::Mul_9264:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [858244524, 5120]
        onnx::Add_9265:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [858249644, 5120]
        up_blocks.0.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [858254764, 29491200]
        up_blocks.0.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [887745964, 2560]
        up_blocks.0.resnets.1.conv_shortcut.weight:0:
          dtype: bf16
          shape: [1280, 2560, 1, 1]
          location: [887748524, 6553600]
        up_blocks.0.resnets.1.conv_shortcut.bias:0:
          dtype: bf16
          shape: [1280]
          location: [894302124, 2560]
        /up_blocks.0/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [894304684, 4]
        onnx::Mul_9266:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [894304688, 10240]
        onnx::Add_9267:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [894314928, 10240]
        up_blocks.0.resnets.2.conv1.weight:0:
          dtype: bf16
          shape: [1280, 2560, 3, 3]
          location: [894325168, 58982400]
        up_blocks.0.resnets.2.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [953307568, 2560]
        up_blocks.0.resnets.2.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [953310128, 3276800]
        up_blocks.0.resnets.2.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [956586928, 2560]
        onnx::Mul_9268:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [956589488, 5120]
        onnx::Add_9269:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [956594608, 5120]
        up_blocks.0.resnets.2.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [956599728, 29491200]
        up_blocks.0.resnets.2.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [986090928, 2560]
        up_blocks.0.resnets.2.conv_shortcut.weight:0:
          dtype: bf16
          shape: [1280, 2560, 1, 1]
          location: [986093488, 6553600]
        up_blocks.0.resnets.2.conv_shortcut.bias:0:
          dtype: bf16
          shape: [1280]
          location: [992647088, 2560]
        /up_blocks.0/resnets.2/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [992649648, 4]
        /up_blocks.0/upsamplers.0/Constant_output_0:0:
          dtype: fp32
          shape: [4]
          location: [992649652, 16]
        up_blocks.0.upsamplers.0.conv.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [992649668, 29491200]
        up_blocks.0.upsamplers.0.conv.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1022140868, 2560]
        onnx::Mul_9271:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [1022143428, 10240]
        onnx::Add_9272:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [1022153668, 10240]
        up_blocks.1.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [1280, 2560, 3, 3]
          location: [1022163908, 58982400]
        up_blocks.1.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1081146308, 2560]
        up_blocks.1.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1081148868, 3276800]
        up_blocks.1.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1084425668, 2560]
        onnx::Mul_9273:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1084428228, 5120]
        onnx::Add_9274:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1084433348, 5120]
        up_blocks.1.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [1084438468, 29491200]
        up_blocks.1.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1113929668, 2560]
        up_blocks.1.resnets.0.conv_shortcut.weight:0:
          dtype: bf16
          shape: [1280, 2560, 1, 1]
          location: [1113932228, 6553600]
        up_blocks.1.resnets.0.conv_shortcut.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1120485828, 2560]
        /up_blocks.1/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1120488388, 4]
        onnx::Mul_9275:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1120488392, 5120]
        onnx::Add_9276:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1120493512, 5120]
        up_blocks.1.attentions.0.proj_in.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [1120498632, 3276800]
        up_blocks.1.attentions.0.proj_in.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1123775432, 2560]
        up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1123777992, 5120]
        up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1123783112, 5120]
        onnx::MatMul_9277:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1123788232, 3276800]
        onnx::MatMul_9279:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1127065032, 3276800]
        onnx::MatMul_9280:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1130341832, 3276800]
        onnx::MatMul_9286:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1133618632, 3276800]
        up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1136895432, 2560]
        up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1136897992, 5120]
        up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1136903112, 5120]
        onnx::MatMul_9287:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1136908232, 3276800]
        onnx::MatMul_9289:0:
          dtype: bf16
          shape: [768, 1280]
          location: [1140185032, 1966080]
        onnx::MatMul_9290:0:
          dtype: bf16
          shape: [768, 1280]
          location: [1142151112, 1966080]
        onnx::MatMul_9296:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1144117192, 3276800]
        up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1147393992, 2560]
        up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1147396552, 5120]
        up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1147401672, 5120]
        onnx::MatMul_9297:0:
          dtype: bf16
          shape: [1280, 10240]
          location: [1147406792, 26214400]
        up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [10240]
          location: [1173621192, 20480]
        onnx::MatMul_9298:0:
          dtype: bf16
          shape: [5120, 1280]
          location: [1173641672, 13107200]
        up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1186748872, 2560]
        up_blocks.1.attentions.0.proj_out.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [1186751432, 3276800]
        up_blocks.1.attentions.0.proj_out.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1190028232, 2560]
        onnx::Mul_9299:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [1190030792, 10240]
        onnx::Add_9300:0:
          dtype: fp32
          shape: [2560, 1, 1]
          location: [1190041032, 10240]
        up_blocks.1.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [1280, 2560, 3, 3]
          location: [1190051272, 58982400]
        up_blocks.1.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1249033672, 2560]
        up_blocks.1.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1249036232, 3276800]
        up_blocks.1.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1252313032, 2560]
        onnx::Mul_9301:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1252315592, 5120]
        onnx::Add_9302:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1252320712, 5120]
        up_blocks.1.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [1252325832, 29491200]
        up_blocks.1.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1281817032, 2560]
        up_blocks.1.resnets.1.conv_shortcut.weight:0:
          dtype: bf16
          shape: [1280, 2560, 1, 1]
          location: [1281819592, 6553600]
        up_blocks.1.resnets.1.conv_shortcut.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1288373192, 2560]
        /up_blocks.1/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1288375752, 4]
        onnx::Mul_9303:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1288375756, 5120]
        onnx::Add_9304:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1288380876, 5120]
        up_blocks.1.attentions.1.proj_in.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [1288385996, 3276800]
        up_blocks.1.attentions.1.proj_in.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1291662796, 2560]
        up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1291665356, 5120]
        up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1291670476, 5120]
        onnx::MatMul_9305:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1291675596, 3276800]
        onnx::MatMul_9307:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1294952396, 3276800]
        onnx::MatMul_9308:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1298229196, 3276800]
        onnx::MatMul_9314:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1301505996, 3276800]
        up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1304782796, 2560]
        up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1304785356, 5120]
        up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1304790476, 5120]
        onnx::MatMul_9315:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1304795596, 3276800]
        onnx::MatMul_9317:0:
          dtype: bf16
          shape: [768, 1280]
          location: [1308072396, 1966080]
        onnx::MatMul_9318:0:
          dtype: bf16
          shape: [768, 1280]
          location: [1310038476, 1966080]
        onnx::MatMul_9324:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1312004556, 3276800]
        up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1315281356, 2560]
        up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1315283916, 5120]
        up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1315289036, 5120]
        onnx::MatMul_9325:0:
          dtype: bf16
          shape: [1280, 10240]
          location: [1315294156, 26214400]
        up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [10240]
          location: [1341508556, 20480]
        onnx::MatMul_9326:0:
          dtype: bf16
          shape: [5120, 1280]
          location: [1341529036, 13107200]
        up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1354636236, 2560]
        up_blocks.1.attentions.1.proj_out.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [1354638796, 3276800]
        up_blocks.1.attentions.1.proj_out.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1357915596, 2560]
        onnx::Mul_9327:0:
          dtype: fp32
          shape: [1920, 1, 1]
          location: [1357918156, 7680]
        onnx::Add_9328:0:
          dtype: fp32
          shape: [1920, 1, 1]
          location: [1357925836, 7680]
        up_blocks.1.resnets.2.conv1.weight:0:
          dtype: bf16
          shape: [1280, 1920, 3, 3]
          location: [1357933516, 44236800]
        up_blocks.1.resnets.2.conv1.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1402170316, 2560]
        up_blocks.1.resnets.2.time_emb_proj.weight:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1402172876, 3276800]
        up_blocks.1.resnets.2.time_emb_proj.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1405449676, 2560]
        onnx::Mul_9329:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1405452236, 5120]
        onnx::Add_9330:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1405457356, 5120]
        up_blocks.1.resnets.2.conv2.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [1405462476, 29491200]
        up_blocks.1.resnets.2.conv2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1434953676, 2560]
        up_blocks.1.resnets.2.conv_shortcut.weight:0:
          dtype: bf16
          shape: [1280, 1920, 1, 1]
          location: [1434956236, 4915200]
        up_blocks.1.resnets.2.conv_shortcut.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1439871436, 2560]
        /up_blocks.1/resnets.2/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1439873996, 4]
        onnx::Mul_9331:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1439874000, 5120]
        onnx::Add_9332:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1439879120, 5120]
        up_blocks.1.attentions.2.proj_in.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [1439884240, 3276800]
        up_blocks.1.attentions.2.proj_in.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1443161040, 2560]
        up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1443163600, 5120]
        up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1443168720, 5120]
        onnx::MatMul_9333:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1443173840, 3276800]
        onnx::MatMul_9335:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1446450640, 3276800]
        onnx::MatMul_9336:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1449727440, 3276800]
        onnx::MatMul_9342:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1453004240, 3276800]
        up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1456281040, 2560]
        up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1456283600, 5120]
        up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1456288720, 5120]
        onnx::MatMul_9343:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1456293840, 3276800]
        onnx::MatMul_9345:0:
          dtype: bf16
          shape: [768, 1280]
          location: [1459570640, 1966080]
        onnx::MatMul_9346:0:
          dtype: bf16
          shape: [768, 1280]
          location: [1461536720, 1966080]
        onnx::MatMul_9352:0:
          dtype: bf16
          shape: [1280, 1280]
          location: [1463502800, 3276800]
        up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1466779600, 2560]
        up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [1280]
          location: [1466782160, 5120]
        up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [1280]
          location: [1466787280, 5120]
        onnx::MatMul_9353:0:
          dtype: bf16
          shape: [1280, 10240]
          location: [1466792400, 26214400]
        up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [10240]
          location: [1493006800, 20480]
        onnx::MatMul_9354:0:
          dtype: bf16
          shape: [5120, 1280]
          location: [1493027280, 13107200]
        up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1506134480, 2560]
        up_blocks.1.attentions.2.proj_out.weight:0:
          dtype: bf16
          shape: [1280, 1280, 1, 1]
          location: [1506137040, 3276800]
        up_blocks.1.attentions.2.proj_out.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1509413840, 2560]
        /up_blocks.1/upsamplers.0/Constant_output_0:0:
          dtype: fp32
          shape: [4]
          location: [1509416400, 16]
        up_blocks.1.upsamplers.0.conv.weight:0:
          dtype: bf16
          shape: [1280, 1280, 3, 3]
          location: [1509416416, 29491200]
        up_blocks.1.upsamplers.0.conv.bias:0:
          dtype: bf16
          shape: [1280]
          location: [1538907616, 2560]
        onnx::Mul_9356:0:
          dtype: fp32
          shape: [1920, 1, 1]
          location: [1538910176, 7680]
        onnx::Add_9357:0:
          dtype: fp32
          shape: [1920, 1, 1]
          location: [1538917856, 7680]
        up_blocks.2.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [640, 1920, 3, 3]
          location: [1538925536, 22118400]
        up_blocks.2.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [640]
          location: [1561043936, 1280]
        up_blocks.2.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [640, 1280]
          location: [1561045216, 1638400]
        up_blocks.2.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [640]
          location: [1562683616, 1280]
        onnx::Mul_9358:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1562684896, 2560]
        onnx::Add_9359:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1562687456, 2560]
        up_blocks.2.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [1562690016, 7372800]
        up_blocks.2.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [640]
          location: [1570062816, 1280]
        up_blocks.2.resnets.0.conv_shortcut.weight:0:
          dtype: bf16
          shape: [640, 1920, 1, 1]
          location: [1570064096, 2457600]
        up_blocks.2.resnets.0.conv_shortcut.bias:0:
          dtype: bf16
          shape: [640]
          location: [1572521696, 1280]
        /up_blocks.2/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1572522976, 4]
        onnx::Mul_9360:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1572522980, 2560]
        onnx::Add_9361:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1572525540, 2560]
        up_blocks.2.attentions.0.proj_in.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [1572528100, 819200]
        up_blocks.2.attentions.0.proj_in.bias:0:
          dtype: bf16
          shape: [640]
          location: [1573347300, 1280]
        up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [640]
          location: [1573348580, 2560]
        up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [640]
          location: [1573351140, 2560]
        onnx::MatMul_9362:0:
          dtype: bf16
          shape: [640, 640]
          location: [1573353700, 819200]
        onnx::MatMul_9364:0:
          dtype: bf16
          shape: [640, 640]
          location: [1574172900, 819200]
        onnx::MatMul_9365:0:
          dtype: bf16
          shape: [640, 640]
          location: [1574992100, 819200]
        onnx::MatMul_9371:0:
          dtype: bf16
          shape: [640, 640]
          location: [1575811300, 819200]
        up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [1576630500, 1280]
        up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [640]
          location: [1576631780, 2560]
        up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [640]
          location: [1576634340, 2560]
        onnx::MatMul_9372:0:
          dtype: bf16
          shape: [640, 640]
          location: [1576636900, 819200]
        onnx::MatMul_9374:0:
          dtype: bf16
          shape: [768, 640]
          location: [1577456100, 983040]
        onnx::MatMul_9375:0:
          dtype: bf16
          shape: [768, 640]
          location: [1578439140, 983040]
        onnx::MatMul_9381:0:
          dtype: bf16
          shape: [640, 640]
          location: [1579422180, 819200]
        up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [1580241380, 1280]
        up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [640]
          location: [1580242660, 2560]
        up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [640]
          location: [1580245220, 2560]
        onnx::MatMul_9382:0:
          dtype: bf16
          shape: [640, 5120]
          location: [1580247780, 6553600]
        up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [5120]
          location: [1586801380, 10240]
        onnx::MatMul_9383:0:
          dtype: bf16
          shape: [2560, 640]
          location: [1586811620, 3276800]
        up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [640]
          location: [1590088420, 1280]
        up_blocks.2.attentions.0.proj_out.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [1590089700, 819200]
        up_blocks.2.attentions.0.proj_out.bias:0:
          dtype: bf16
          shape: [640]
          location: [1590908900, 1280]
        onnx::Mul_9384:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1590910180, 5120]
        onnx::Add_9385:0:
          dtype: fp32
          shape: [1280, 1, 1]
          location: [1590915300, 5120]
        up_blocks.2.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [640, 1280, 3, 3]
          location: [1590920420, 14745600]
        up_blocks.2.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [640]
          location: [1605666020, 1280]
        up_blocks.2.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [640, 1280]
          location: [1605667300, 1638400]
        up_blocks.2.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [640]
          location: [1607305700, 1280]
        onnx::Mul_9386:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1607306980, 2560]
        onnx::Add_9387:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1607309540, 2560]
        up_blocks.2.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [1607312100, 7372800]
        up_blocks.2.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [640]
          location: [1614684900, 1280]
        up_blocks.2.resnets.1.conv_shortcut.weight:0:
          dtype: bf16
          shape: [640, 1280, 1, 1]
          location: [1614686180, 1638400]
        up_blocks.2.resnets.1.conv_shortcut.bias:0:
          dtype: bf16
          shape: [640]
          location: [1616324580, 1280]
        /up_blocks.2/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1616325860, 4]
        onnx::Mul_9388:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1616325864, 2560]
        onnx::Add_9389:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1616328424, 2560]
        up_blocks.2.attentions.1.proj_in.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [1616330984, 819200]
        up_blocks.2.attentions.1.proj_in.bias:0:
          dtype: bf16
          shape: [640]
          location: [1617150184, 1280]
        up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [640]
          location: [1617151464, 2560]
        up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [640]
          location: [1617154024, 2560]
        onnx::MatMul_9390:0:
          dtype: bf16
          shape: [640, 640]
          location: [1617156584, 819200]
        onnx::MatMul_9392:0:
          dtype: bf16
          shape: [640, 640]
          location: [1617975784, 819200]
        onnx::MatMul_9393:0:
          dtype: bf16
          shape: [640, 640]
          location: [1618794984, 819200]
        onnx::MatMul_9399:0:
          dtype: bf16
          shape: [640, 640]
          location: [1619614184, 819200]
        up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [1620433384, 1280]
        up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [640]
          location: [1620434664, 2560]
        up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [640]
          location: [1620437224, 2560]
        onnx::MatMul_9400:0:
          dtype: bf16
          shape: [640, 640]
          location: [1620439784, 819200]
        onnx::MatMul_9402:0:
          dtype: bf16
          shape: [768, 640]
          location: [1621258984, 983040]
        onnx::MatMul_9403:0:
          dtype: bf16
          shape: [768, 640]
          location: [1622242024, 983040]
        onnx::MatMul_9409:0:
          dtype: bf16
          shape: [640, 640]
          location: [1623225064, 819200]
        up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [1624044264, 1280]
        up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [640]
          location: [1624045544, 2560]
        up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [640]
          location: [1624048104, 2560]
        onnx::MatMul_9410:0:
          dtype: bf16
          shape: [640, 5120]
          location: [1624050664, 6553600]
        up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [5120]
          location: [1630604264, 10240]
        onnx::MatMul_9411:0:
          dtype: bf16
          shape: [2560, 640]
          location: [1630614504, 3276800]
        up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [640]
          location: [1633891304, 1280]
        up_blocks.2.attentions.1.proj_out.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [1633892584, 819200]
        up_blocks.2.attentions.1.proj_out.bias:0:
          dtype: bf16
          shape: [640]
          location: [1634711784, 1280]
        onnx::Mul_9412:0:
          dtype: fp32
          shape: [960, 1, 1]
          location: [1634713064, 3840]
        onnx::Add_9413:0:
          dtype: fp32
          shape: [960, 1, 1]
          location: [1634716904, 3840]
        up_blocks.2.resnets.2.conv1.weight:0:
          dtype: bf16
          shape: [640, 960, 3, 3]
          location: [1634720744, 11059200]
        up_blocks.2.resnets.2.conv1.bias:0:
          dtype: bf16
          shape: [640]
          location: [1645779944, 1280]
        up_blocks.2.resnets.2.time_emb_proj.weight:0:
          dtype: bf16
          shape: [640, 1280]
          location: [1645781224, 1638400]
        up_blocks.2.resnets.2.time_emb_proj.bias:0:
          dtype: bf16
          shape: [640]
          location: [1647419624, 1280]
        onnx::Mul_9414:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1647420904, 2560]
        onnx::Add_9415:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1647423464, 2560]
        up_blocks.2.resnets.2.conv2.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [1647426024, 7372800]
        up_blocks.2.resnets.2.conv2.bias:0:
          dtype: bf16
          shape: [640]
          location: [1654798824, 1280]
        up_blocks.2.resnets.2.conv_shortcut.weight:0:
          dtype: bf16
          shape: [640, 960, 1, 1]
          location: [1654800104, 1228800]
        up_blocks.2.resnets.2.conv_shortcut.bias:0:
          dtype: bf16
          shape: [640]
          location: [1656028904, 1280]
        /up_blocks.2/resnets.2/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1656030184, 4]
        onnx::Mul_9416:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1656030188, 2560]
        onnx::Add_9417:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1656032748, 2560]
        up_blocks.2.attentions.2.proj_in.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [1656035308, 819200]
        up_blocks.2.attentions.2.proj_in.bias:0:
          dtype: bf16
          shape: [640]
          location: [1656854508, 1280]
        up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [640]
          location: [1656855788, 2560]
        up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [640]
          location: [1656858348, 2560]
        onnx::MatMul_9418:0:
          dtype: bf16
          shape: [640, 640]
          location: [1656860908, 819200]
        onnx::MatMul_9420:0:
          dtype: bf16
          shape: [640, 640]
          location: [1657680108, 819200]
        onnx::MatMul_9421:0:
          dtype: bf16
          shape: [640, 640]
          location: [1658499308, 819200]
        onnx::MatMul_9427:0:
          dtype: bf16
          shape: [640, 640]
          location: [1659318508, 819200]
        up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [1660137708, 1280]
        up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [640]
          location: [1660138988, 2560]
        up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [640]
          location: [1660141548, 2560]
        onnx::MatMul_9428:0:
          dtype: bf16
          shape: [640, 640]
          location: [1660144108, 819200]
        onnx::MatMul_9430:0:
          dtype: bf16
          shape: [768, 640]
          location: [1660963308, 983040]
        onnx::MatMul_9431:0:
          dtype: bf16
          shape: [768, 640]
          location: [1661946348, 983040]
        onnx::MatMul_9437:0:
          dtype: bf16
          shape: [640, 640]
          location: [1662929388, 819200]
        up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [640]
          location: [1663748588, 1280]
        up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [640]
          location: [1663749868, 2560]
        up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [640]
          location: [1663752428, 2560]
        onnx::MatMul_9438:0:
          dtype: bf16
          shape: [640, 5120]
          location: [1663754988, 6553600]
        up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [5120]
          location: [1670308588, 10240]
        onnx::MatMul_9439:0:
          dtype: bf16
          shape: [2560, 640]
          location: [1670318828, 3276800]
        up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [640]
          location: [1673595628, 1280]
        up_blocks.2.attentions.2.proj_out.weight:0:
          dtype: bf16
          shape: [640, 640, 1, 1]
          location: [1673596908, 819200]
        up_blocks.2.attentions.2.proj_out.bias:0:
          dtype: bf16
          shape: [640]
          location: [1674416108, 1280]
        /up_blocks.2/upsamplers.0/Constant_output_0:0:
          dtype: fp32
          shape: [4]
          location: [1674417388, 16]
        up_blocks.2.upsamplers.0.conv.weight:0:
          dtype: bf16
          shape: [640, 640, 3, 3]
          location: [1674417404, 7372800]
        up_blocks.2.upsamplers.0.conv.bias:0:
          dtype: bf16
          shape: [640]
          location: [1681790204, 1280]
        onnx::Mul_9441:0:
          dtype: fp32
          shape: [960, 1, 1]
          location: [1681791484, 3840]
        onnx::Add_9442:0:
          dtype: fp32
          shape: [960, 1, 1]
          location: [1681795324, 3840]
        up_blocks.3.resnets.0.conv1.weight:0:
          dtype: bf16
          shape: [320, 960, 3, 3]
          location: [1681799164, 5529600]
        up_blocks.3.resnets.0.conv1.bias:0:
          dtype: bf16
          shape: [320]
          location: [1687328764, 640]
        up_blocks.3.resnets.0.time_emb_proj.weight:0:
          dtype: bf16
          shape: [320, 1280]
          location: [1687329404, 819200]
        up_blocks.3.resnets.0.time_emb_proj.bias:0:
          dtype: bf16
          shape: [320]
          location: [1688148604, 640]
        onnx::Mul_9443:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1688149244, 1280]
        onnx::Add_9444:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1688150524, 1280]
        up_blocks.3.resnets.0.conv2.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [1688151804, 1843200]
        up_blocks.3.resnets.0.conv2.bias:0:
          dtype: bf16
          shape: [320]
          location: [1689995004, 640]
        up_blocks.3.resnets.0.conv_shortcut.weight:0:
          dtype: bf16
          shape: [320, 960, 1, 1]
          location: [1689995644, 614400]
        up_blocks.3.resnets.0.conv_shortcut.bias:0:
          dtype: bf16
          shape: [320]
          location: [1690610044, 640]
        /up_blocks.3/resnets.0/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1690610684, 4]
        onnx::Mul_9445:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1690610688, 1280]
        onnx::Add_9446:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1690611968, 1280]
        up_blocks.3.attentions.0.proj_in.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [1690613248, 204800]
        up_blocks.3.attentions.0.proj_in.bias:0:
          dtype: bf16
          shape: [320]
          location: [1690818048, 640]
        up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [320]
          location: [1690818688, 1280]
        up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [320]
          location: [1690819968, 1280]
        onnx::MatMul_9447:0:
          dtype: bf16
          shape: [320, 320]
          location: [1690821248, 204800]
        onnx::MatMul_9449:0:
          dtype: bf16
          shape: [320, 320]
          location: [1691026048, 204800]
        onnx::MatMul_9450:0:
          dtype: bf16
          shape: [320, 320]
          location: [1691230848, 204800]
        onnx::MatMul_9456:0:
          dtype: bf16
          shape: [320, 320]
          location: [1691435648, 204800]
        up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [1691640448, 640]
        up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [320]
          location: [1691641088, 1280]
        up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [320]
          location: [1691642368, 1280]
        onnx::MatMul_9457:0:
          dtype: bf16
          shape: [320, 320]
          location: [1691643648, 204800]
        onnx::MatMul_9459:0:
          dtype: bf16
          shape: [768, 320]
          location: [1691848448, 491520]
        onnx::MatMul_9460:0:
          dtype: bf16
          shape: [768, 320]
          location: [1692339968, 491520]
        onnx::MatMul_9466:0:
          dtype: bf16
          shape: [320, 320]
          location: [1692831488, 204800]
        up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [1693036288, 640]
        up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [320]
          location: [1693036928, 1280]
        up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [320]
          location: [1693038208, 1280]
        onnx::MatMul_9467:0:
          dtype: bf16
          shape: [320, 2560]
          location: [1693039488, 1638400]
        up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [2560]
          location: [1694677888, 5120]
        onnx::MatMul_9468:0:
          dtype: bf16
          shape: [1280, 320]
          location: [1694683008, 819200]
        up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [320]
          location: [1695502208, 640]
        up_blocks.3.attentions.0.proj_out.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [1695502848, 204800]
        up_blocks.3.attentions.0.proj_out.bias:0:
          dtype: bf16
          shape: [320]
          location: [1695707648, 640]
        onnx::Mul_9469:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1695708288, 2560]
        onnx::Add_9470:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1695710848, 2560]
        up_blocks.3.resnets.1.conv1.weight:0:
          dtype: bf16
          shape: [320, 640, 3, 3]
          location: [1695713408, 3686400]
        up_blocks.3.resnets.1.conv1.bias:0:
          dtype: bf16
          shape: [320]
          location: [1699399808, 640]
        up_blocks.3.resnets.1.time_emb_proj.weight:0:
          dtype: bf16
          shape: [320, 1280]
          location: [1699400448, 819200]
        up_blocks.3.resnets.1.time_emb_proj.bias:0:
          dtype: bf16
          shape: [320]
          location: [1700219648, 640]
        onnx::Mul_9471:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1700220288, 1280]
        onnx::Add_9472:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1700221568, 1280]
        up_blocks.3.resnets.1.conv2.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [1700222848, 1843200]
        up_blocks.3.resnets.1.conv2.bias:0:
          dtype: bf16
          shape: [320]
          location: [1702066048, 640]
        up_blocks.3.resnets.1.conv_shortcut.weight:0:
          dtype: bf16
          shape: [320, 640, 1, 1]
          location: [1702066688, 409600]
        up_blocks.3.resnets.1.conv_shortcut.bias:0:
          dtype: bf16
          shape: [320]
          location: [1702476288, 640]
        /up_blocks.3/resnets.1/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1702476928, 4]
        onnx::Mul_9473:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1702476932, 1280]
        onnx::Add_9474:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1702478212, 1280]
        up_blocks.3.attentions.1.proj_in.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [1702479492, 204800]
        up_blocks.3.attentions.1.proj_in.bias:0:
          dtype: bf16
          shape: [320]
          location: [1702684292, 640]
        up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [320]
          location: [1702684932, 1280]
        up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [320]
          location: [1702686212, 1280]
        onnx::MatMul_9475:0:
          dtype: bf16
          shape: [320, 320]
          location: [1702687492, 204800]
        onnx::MatMul_9477:0:
          dtype: bf16
          shape: [320, 320]
          location: [1702892292, 204800]
        onnx::MatMul_9478:0:
          dtype: bf16
          shape: [320, 320]
          location: [1703097092, 204800]
        onnx::MatMul_9484:0:
          dtype: bf16
          shape: [320, 320]
          location: [1703301892, 204800]
        up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [1703506692, 640]
        up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [320]
          location: [1703507332, 1280]
        up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [320]
          location: [1703508612, 1280]
        onnx::MatMul_9485:0:
          dtype: bf16
          shape: [320, 320]
          location: [1703509892, 204800]
        onnx::MatMul_9487:0:
          dtype: bf16
          shape: [768, 320]
          location: [1703714692, 491520]
        onnx::MatMul_9488:0:
          dtype: bf16
          shape: [768, 320]
          location: [1704206212, 491520]
        onnx::MatMul_9494:0:
          dtype: bf16
          shape: [320, 320]
          location: [1704697732, 204800]
        up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [1704902532, 640]
        up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [320]
          location: [1704903172, 1280]
        up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [320]
          location: [1704904452, 1280]
        onnx::MatMul_9495:0:
          dtype: bf16
          shape: [320, 2560]
          location: [1704905732, 1638400]
        up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [2560]
          location: [1706544132, 5120]
        onnx::MatMul_9496:0:
          dtype: bf16
          shape: [1280, 320]
          location: [1706549252, 819200]
        up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [320]
          location: [1707368452, 640]
        up_blocks.3.attentions.1.proj_out.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [1707369092, 204800]
        up_blocks.3.attentions.1.proj_out.bias:0:
          dtype: bf16
          shape: [320]
          location: [1707573892, 640]
        onnx::Mul_9497:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1707574532, 2560]
        onnx::Add_9498:0:
          dtype: fp32
          shape: [640, 1, 1]
          location: [1707577092, 2560]
        up_blocks.3.resnets.2.conv1.weight:0:
          dtype: bf16
          shape: [320, 640, 3, 3]
          location: [1707579652, 3686400]
        up_blocks.3.resnets.2.conv1.bias:0:
          dtype: bf16
          shape: [320]
          location: [1711266052, 640]
        up_blocks.3.resnets.2.time_emb_proj.weight:0:
          dtype: bf16
          shape: [320, 1280]
          location: [1711266692, 819200]
        up_blocks.3.resnets.2.time_emb_proj.bias:0:
          dtype: bf16
          shape: [320]
          location: [1712085892, 640]
        onnx::Mul_9499:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1712086532, 1280]
        onnx::Add_9500:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1712087812, 1280]
        up_blocks.3.resnets.2.conv2.weight:0:
          dtype: bf16
          shape: [320, 320, 3, 3]
          location: [1712089092, 1843200]
        up_blocks.3.resnets.2.conv2.bias:0:
          dtype: bf16
          shape: [320]
          location: [1713932292, 640]
        up_blocks.3.resnets.2.conv_shortcut.weight:0:
          dtype: bf16
          shape: [320, 640, 1, 1]
          location: [1713932932, 409600]
        up_blocks.3.resnets.2.conv_shortcut.bias:0:
          dtype: bf16
          shape: [320]
          location: [1714342532, 640]
        /up_blocks.3/resnets.2/Constant_2_output_0:0:
          dtype: fp32
          shape: [1]
          location: [1714343172, 4]
        onnx::Mul_9501:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1714343176, 1280]
        onnx::Add_9502:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1714344456, 1280]
        up_blocks.3.attentions.2.proj_in.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [1714345736, 204800]
        up_blocks.3.attentions.2.proj_in.bias:0:
          dtype: bf16
          shape: [320]
          location: [1714550536, 640]
        up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight:0:
          dtype: fp32
          shape: [320]
          location: [1714551176, 1280]
        up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias:0:
          dtype: fp32
          shape: [320]
          location: [1714552456, 1280]
        onnx::MatMul_9503:0:
          dtype: bf16
          shape: [320, 320]
          location: [1714553736, 204800]
        onnx::MatMul_9505:0:
          dtype: bf16
          shape: [320, 320]
          location: [1714758536, 204800]
        onnx::MatMul_9506:0:
          dtype: bf16
          shape: [320, 320]
          location: [1714963336, 204800]
        onnx::MatMul_9512:0:
          dtype: bf16
          shape: [320, 320]
          location: [1715168136, 204800]
        up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [1715372936, 640]
        up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight:0:
          dtype: fp32
          shape: [320]
          location: [1715373576, 1280]
        up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias:0:
          dtype: fp32
          shape: [320]
          location: [1715374856, 1280]
        onnx::MatMul_9513:0:
          dtype: bf16
          shape: [320, 320]
          location: [1715376136, 204800]
        onnx::MatMul_9515:0:
          dtype: bf16
          shape: [768, 320]
          location: [1715580936, 491520]
        onnx::MatMul_9516:0:
          dtype: bf16
          shape: [768, 320]
          location: [1716072456, 491520]
        onnx::MatMul_9522:0:
          dtype: bf16
          shape: [320, 320]
          location: [1716563976, 204800]
        up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias:0:
          dtype: bf16
          shape: [320]
          location: [1716768776, 640]
        up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight:0:
          dtype: fp32
          shape: [320]
          location: [1716769416, 1280]
        up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias:0:
          dtype: fp32
          shape: [320]
          location: [1716770696, 1280]
        onnx::MatMul_9523:0:
          dtype: bf16
          shape: [320, 2560]
          location: [1716771976, 1638400]
        up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias:0:
          dtype: bf16
          shape: [2560]
          location: [1718410376, 5120]
        onnx::MatMul_9524:0:
          dtype: bf16
          shape: [1280, 320]
          location: [1718415496, 819200]
        up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias:0:
          dtype: bf16
          shape: [320]
          location: [1719234696, 640]
        up_blocks.3.attentions.2.proj_out.weight:0:
          dtype: bf16
          shape: [320, 320, 1, 1]
          location: [1719235336, 204800]
        up_blocks.3.attentions.2.proj_out.bias:0:
          dtype: bf16
          shape: [320]
          location: [1719440136, 640]
        onnx::Mul_9525:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1719440776, 1280]
        onnx::Add_9526:0:
          dtype: fp32
          shape: [320, 1, 1]
          location: [1719442056, 1280]
        conv_out.weight:0:
          dtype: bf16
          shape: [4, 320, 3, 3]
          location: [1719443336, 23040]
        conv_out.bias:0:
          dtype: bf16
          shape: [4]
          location: [1719466376, 8]
    timestep/reshape:
      type: Reshape
      input:
        timestep:0: {}
      output:
        timestep/reshape:0: {}
      attr:
        dst_shape: -1
    /Expand:
      type: Concat
      input:
        timestep:0: {}
        timestep/reshape:0: {}
      output:
        /Expand_output_0:0: {}
      attr:
        axis: 0
    /time_proj/Unsqueeze:
      type: Unsqueeze
      input:
        /Expand_output_0:0: {}
      output:
        /time_proj/Cast_output_0:0: {}
      attr:
        axes: 1
    /time_proj/Mul:
      type: BinaryOp
      input:
        /time_proj/Cast_output_0:0: {}
        /time_proj/Constant_1_output_0:0: {}
      output:
        /time_proj/Mul_output_0:0: {}
      attr:
        algorithm: mul
    /time_proj/Sin:
      type: CosSin
      input:
        /time_proj/Mul_output_0:0: {}
      output:
        /time_proj/Sin_output_0:0: {}
      attr:
        algorithm: sin
    /time_proj/Cos:
      type: CosSin
      input:
        /time_proj/Mul_output_0:0: {}
      output:
        /time_proj/Cos_output_0:0: {}
      attr:
        algorithm: cos
    /time_proj/Concat:
      type: Concat
      input:
        /time_proj/Sin_output_0:0: {}
        /time_proj/Cos_output_0:0: {}
      output:
        /time_proj/Concat_output_0:0: {}
      attr:
        axis: 1
    /time_proj/Slice:
      type: Slice
      input:
        /time_proj/Concat_output_0:0: {}
      output:
        /time_proj/Slice_output_0:0: {}
      attr:
        starts: '160'
        ends: '320'
        axes: '1'
        steps: '1'
    /time_proj/Slice_1:
      type: Slice
      input:
        /time_proj/Concat_output_0:0: {}
      output:
        /time_proj/Slice_1_output_0:0: {}
      attr:
        starts: '0'
        ends: '160'
        axes: '1'
        steps: '1'
    /time_proj/Concat_1:
      type: Concat
      input:
        /time_proj/Slice_output_0:0: {}
        /time_proj/Slice_1_output_0:0: {}
      output:
        /time_proj/Concat_1_output_0:0: {}
      attr:
        axis: 1
    /time_embedding/act/Mul_quant:
      type: Quantize
      input:
        /time_proj/Concat_1_output_0:0: {}
      output:
        /time_proj/Concat_1_output_0:0_quant: {}
      attr:
        output_dtype: bf16
    /time_embedding/act/Mul:
      type: InnerProduct
      input:
        /time_proj/Concat_1_output_0:0_quant: {}
        time_embedding.linear_1.weight:0: {}
        time_embedding.linear_1.bias:0: {}
      output:
        /time_embedding/act/Mul_output_0:0_quant: {}
      attr:
        src1_perm: 0,1
        append_op: swish
        output_dtype: bf16
    /conv_in/Conv_quant:
      type: Quantize
      input:
        sample:0: {}
      output:
        sample:0_quant: {}
      attr:
        output_dtype: bf16
    reorder_pre_for_conv_0:
      type: Reorder
      input:
        sample:0_quant: {}
      output:
        reorder_pre_for_conv_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /conv_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_0:0: {}
        conv_in.weight:0: {}
        conv_in.bias:0: {}
      output:
        /conv_in/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_0:
      type: Reorder
      input:
        /conv_in/Conv:0: {}
      output:
        /conv_in/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.0/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /conv_in/Conv_output_0:0: {}
        onnx::Mul_9050:0: {}
        onnx::Add_9051:0: {}
      output:
        /down_blocks.0/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_1:
      type: Reorder
      input:
        /down_blocks.0/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_1:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.0/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_1:0: {}
        down_blocks.0.resnets.0.conv1.weight:0: {}
        down_blocks.0.resnets.0.conv1.bias:0: {}
      output:
        /down_blocks.0/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_1:
      type: Reorder
      input:
        /down_blocks.0/resnets.0/conv1/Conv:0: {}
      output:
        /down_blocks.0/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.0/resnets.0/nonlinearity_1/Mul:
      type: InnerProduct
      input:
        /time_embedding/act/Mul_output_0:0_quant: {}
        time_embedding.linear_2.weight:0: {}
        time_embedding.linear_2.bias:0: {}
      output:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        src1_perm: 0,1
        append_op: swish
        output_dtype: bf16
    /down_blocks.0/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.0.resnets.0.time_emb_proj.weight:0: {}
        down_blocks.0.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,320,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.0/resnets.0/Add:
      type: BinaryAdd
      input:
        /down_blocks.0/resnets.0/conv1/Conv_output_0:0: {}
        /down_blocks.0/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.0/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.0/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.0/resnets.0/Add_output_0:0: {}
        onnx::Mul_9052:0: {}
        onnx::Add_9053:0: {}
      output:
        /down_blocks.0/resnets.0/nonlinearity_2/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_2:
      type: Reorder
      input:
        /down_blocks.0/resnets.0/nonlinearity_2/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_2:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.0/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_2:0: {}
        down_blocks.0.resnets.0.conv2.weight:0: {}
        down_blocks.0.resnets.0.conv2.bias:0: {}
      output:
        /down_blocks.0/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_2:
      type: Reorder
      input:
        /down_blocks.0/resnets.0/conv2/Conv:0: {}
      output:
        /down_blocks.0/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.0/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /conv_in/Conv_output_0:0: {}
        /down_blocks.0/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.0/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.0/resnets.0/Div:
      type: BinaryOp
      input:
        /down_blocks.0/resnets.0/Add_1_output_0:0: {}
        /down_blocks.0/resnets.0/Constant_2_output_0:0: {}
      output:
        /down_blocks.0/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /down_blocks.0/attentions.0/norm/Add:
      type: GroupNorm
      input:
        /down_blocks.0/resnets.0/Div_output_0:0: {}
        onnx::Mul_9054:0: {}
        onnx::Add_9055:0: {}
      output:
        /down_blocks.0/attentions.0/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_3:
      type: Reorder
      input:
        /down_blocks.0/attentions.0/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_3:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.0/attentions.0/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_3:0: {}
        down_blocks.0.attentions.0.proj_in.weight:0: {}
        down_blocks.0.attentions.0.proj_in.bias:0: {}
      output:
        /down_blocks.0/attentions.0/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /down_blocks.0/attentions.0/Reshape:
      type: Reshape
      input:
        /down_blocks.0/attentions.0/proj_in/Conv_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,320
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /down_blocks.0/attentions.0/Reshape_output_0:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9056:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9058:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9059:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9065:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /down_blocks.0/attentions.0/Reshape_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_output_0:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9066:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    encoder_hidden_states/reshape_2d:
      type: Reshape
      input:
        encoder_hidden_states:0: {}
      output:
        encoder_hidden_states:0_2d: {}
      attr:
        dst_shape: -1,768
    /down_blocks.0/attentions.0/transformer_blocks.0/attn2/to_k/MatMul_quant:
      type: Quantize
      input:
        encoder_hidden_states:0_2d: {}
      output:
        encoder_hidden_states:0_2d_quant: {}
      attr:
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9068:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9069:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9075:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9076:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 1280
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 1280
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /down_blocks.0/attentions.0/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9077:0: {}
        down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias:0: {}
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.0/attentions.0/Reshape_1:
      type: Reshape
      input:
        /down_blocks.0/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
        /down_blocks.0/resnets.0/Div_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /down_blocks.0/attentions.0/proj_out/Conv:
      type: Convolution
      input:
        /down_blocks.0/attentions.0/Transpose_1_output_0:0_quant: {}
        down_blocks.0.attentions.0.proj_out.weight:0: {}
        down_blocks.0.attentions.0.proj_out.bias:0: {}
      output:
        /down_blocks.0/attentions.0/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_4:
      type: Reorder
      input:
        /down_blocks.0/attentions.0/proj_out/Conv:0: {}
      output:
        /down_blocks.0/attentions.0/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.0/attentions.0/Add:
      type: BinaryAdd
      input:
        /down_blocks.0/attentions.0/proj_out/Conv_output_0:0: {}
        /down_blocks.0/resnets.0/Div_output_0:0: {}
      output:
        /down_blocks.0/attentions.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.0/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.0/attentions.0/Add_output_0:0: {}
        onnx::Mul_9078:0: {}
        onnx::Add_9079:0: {}
      output:
        /down_blocks.0/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_5:
      type: Reorder
      input:
        /down_blocks.0/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_5:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.0/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_5:0: {}
        down_blocks.0.resnets.1.conv1.weight:0: {}
        down_blocks.0.resnets.1.conv1.bias:0: {}
      output:
        /down_blocks.0/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_5:
      type: Reorder
      input:
        /down_blocks.0/resnets.1/conv1/Conv:0: {}
      output:
        /down_blocks.0/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.0/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.0.resnets.1.time_emb_proj.weight:0: {}
        down_blocks.0.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,320,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.0/resnets.1/Add:
      type: BinaryAdd
      input:
        /down_blocks.0/resnets.1/conv1/Conv_output_0:0: {}
        /down_blocks.0/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.0/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.0/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.0/resnets.1/Add_output_0:0: {}
        onnx::Mul_9080:0: {}
        onnx::Add_9081:0: {}
      output:
        /down_blocks.0/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_6:
      type: Reorder
      input:
        /down_blocks.0/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_6:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.0/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_6:0: {}
        down_blocks.0.resnets.1.conv2.weight:0: {}
        down_blocks.0.resnets.1.conv2.bias:0: {}
      output:
        /down_blocks.0/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_6:
      type: Reorder
      input:
        /down_blocks.0/resnets.1/conv2/Conv:0: {}
      output:
        /down_blocks.0/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.0/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.0/attentions.0/Add_output_0:0: {}
        /down_blocks.0/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.0/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.0/resnets.1/Div:
      type: BinaryOp
      input:
        /down_blocks.0/resnets.1/Add_1_output_0:0: {}
        /down_blocks.0/resnets.1/Constant_2_output_0:0: {}
      output:
        /down_blocks.0/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /down_blocks.0/attentions.1/norm/Add:
      type: GroupNorm
      input:
        /down_blocks.0/resnets.1/Div_output_0:0: {}
        onnx::Mul_9082:0: {}
        onnx::Add_9083:0: {}
      output:
        /down_blocks.0/attentions.1/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_7:
      type: Reorder
      input:
        /down_blocks.0/attentions.1/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_7:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.0/attentions.1/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_7:0: {}
        down_blocks.0.attentions.1.proj_in.weight:0: {}
        down_blocks.0.attentions.1.proj_in.bias:0: {}
      output:
        /down_blocks.0/attentions.1/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /down_blocks.0/attentions.1/Reshape:
      type: Reshape
      input:
        /down_blocks.0/attentions.1/proj_in/Conv_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,320
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /down_blocks.0/attentions.1/Reshape_output_0:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9084:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9086:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9087:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9093:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /down_blocks.0/attentions.1/Reshape_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_output_0:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9094:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9096:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9097:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9103:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9104:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 1280
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 1280
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /down_blocks.0/attentions.1/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9105:0: {}
        down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias:0: {}
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.0/attentions.1/Reshape_1:
      type: Reshape
      input:
        /down_blocks.0/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
        /down_blocks.0/resnets.1/Div_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /down_blocks.0/attentions.1/proj_out/Conv:
      type: Convolution
      input:
        /down_blocks.0/attentions.1/Transpose_1_output_0:0_quant: {}
        down_blocks.0.attentions.1.proj_out.weight:0: {}
        down_blocks.0.attentions.1.proj_out.bias:0: {}
      output:
        /down_blocks.0/attentions.1/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_8:
      type: Reorder
      input:
        /down_blocks.0/attentions.1/proj_out/Conv:0: {}
      output:
        /down_blocks.0/attentions.1/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.0/attentions.1/Add:
      type: BinaryAdd
      input:
        /down_blocks.0/attentions.1/proj_out/Conv_output_0:0: {}
        /down_blocks.0/resnets.1/Div_output_0:0: {}
      output:
        /down_blocks.0/attentions.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    reorder_pre_for_conv_9:
      type: Reorder
      input:
        /down_blocks.0/attentions.1/Add_output_0:0: {}
      output:
        reorder_pre_for_conv_9:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.0/downsamplers.0/conv/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_9:0: {}
        down_blocks.0.downsamplers.0.conv.weight:0: {}
        down_blocks.0.downsamplers.0.conv.bias:0: {}
      output:
        /down_blocks.0/downsamplers.0/conv/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 2,2
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_9:
      type: Reorder
      input:
        /down_blocks.0/downsamplers.0/conv/Conv:0: {}
      output:
        /down_blocks.0/downsamplers.0/conv/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.1/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.0/downsamplers.0/conv/Conv_output_0:0: {}
        onnx::Mul_9106:0: {}
        onnx::Add_9107:0: {}
      output:
        /down_blocks.1/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_10:
      type: Reorder
      input:
        /down_blocks.1/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_10:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_10:0: {}
        down_blocks.1.resnets.0.conv1.weight:0: {}
        down_blocks.1.resnets.0.conv1.bias:0: {}
      output:
        /down_blocks.1/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_10:
      type: Reorder
      input:
        /down_blocks.1/resnets.0/conv1/Conv:0: {}
      output:
        /down_blocks.1/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.1/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.1.resnets.0.time_emb_proj.weight:0: {}
        down_blocks.1.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,640,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.1/resnets.0/Add:
      type: BinaryAdd
      input:
        /down_blocks.1/resnets.0/conv1/Conv_output_0:0: {}
        /down_blocks.1/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.1/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.1/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.1/resnets.0/Add_output_0:0: {}
        onnx::Mul_9108:0: {}
        onnx::Add_9109:0: {}
      output:
        /down_blocks.1/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_11:
      type: Reorder
      input:
        /down_blocks.1/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_11:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_11:0: {}
        down_blocks.1.resnets.0.conv2.weight:0: {}
        down_blocks.1.resnets.0.conv2.bias:0: {}
      output:
        /down_blocks.1/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_11:
      type: Reorder
      input:
        /down_blocks.1/resnets.0/conv2/Conv:0: {}
      output:
        /down_blocks.1/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_12:
      type: Reorder
      input:
        /down_blocks.0/downsamplers.0/conv/Conv_output_0:0: {}
      output:
        reorder_pre_for_conv_12:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/resnets.0/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_12:0: {}
        down_blocks.1.resnets.0.conv_shortcut.weight:0: {}
        down_blocks.1.resnets.0.conv_shortcut.bias:0: {}
      output:
        /down_blocks.1/resnets.0/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_12:
      type: Reorder
      input:
        /down_blocks.1/resnets.0/conv_shortcut/Conv:0: {}
      output:
        /down_blocks.1/resnets.0/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.1/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.1/resnets.0/conv_shortcut/Conv_output_0:0: {}
        /down_blocks.1/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.1/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.1/resnets.0/Div:
      type: BinaryOp
      input:
        /down_blocks.1/resnets.0/Add_1_output_0:0: {}
        /down_blocks.1/resnets.0/Constant_2_output_0:0: {}
      output:
        /down_blocks.1/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /down_blocks.1/attentions.0/norm/Add:
      type: GroupNorm
      input:
        /down_blocks.1/resnets.0/Div_output_0:0: {}
        onnx::Mul_9110:0: {}
        onnx::Add_9111:0: {}
      output:
        /down_blocks.1/attentions.0/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_13:
      type: Reorder
      input:
        /down_blocks.1/attentions.0/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_13:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/attentions.0/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_13:0: {}
        down_blocks.1.attentions.0.proj_in.weight:0: {}
        down_blocks.1.attentions.0.proj_in.bias:0: {}
      output:
        /down_blocks.1/attentions.0/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /down_blocks.1/attentions.0/Reshape:
      type: Reshape
      input:
        /down_blocks.1/attentions.0/proj_in/Conv_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,640
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /down_blocks.1/attentions.0/Reshape_output_0:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9112:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9114:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9115:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9121:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /down_blocks.1/attentions.0/Reshape_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_output_0:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9122:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9124:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9125:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9131:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9132:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 2560
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /down_blocks.1/attentions.0/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9133:0: {}
        down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias:0: {}
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.1/attentions.0/Reshape_1:
      type: Reshape
      input:
        /down_blocks.1/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
        /down_blocks.1/resnets.0/Div_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /down_blocks.1/attentions.0/proj_out/Conv:
      type: Convolution
      input:
        /down_blocks.1/attentions.0/Transpose_1_output_0:0_quant: {}
        down_blocks.1.attentions.0.proj_out.weight:0: {}
        down_blocks.1.attentions.0.proj_out.bias:0: {}
      output:
        /down_blocks.1/attentions.0/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_14:
      type: Reorder
      input:
        /down_blocks.1/attentions.0/proj_out/Conv:0: {}
      output:
        /down_blocks.1/attentions.0/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.1/attentions.0/Add:
      type: BinaryAdd
      input:
        /down_blocks.1/attentions.0/proj_out/Conv_output_0:0: {}
        /down_blocks.1/resnets.0/Div_output_0:0: {}
      output:
        /down_blocks.1/attentions.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.1/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.1/attentions.0/Add_output_0:0: {}
        onnx::Mul_9134:0: {}
        onnx::Add_9135:0: {}
      output:
        /down_blocks.1/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_15:
      type: Reorder
      input:
        /down_blocks.1/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_15:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_15:0: {}
        down_blocks.1.resnets.1.conv1.weight:0: {}
        down_blocks.1.resnets.1.conv1.bias:0: {}
      output:
        /down_blocks.1/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_15:
      type: Reorder
      input:
        /down_blocks.1/resnets.1/conv1/Conv:0: {}
      output:
        /down_blocks.1/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.1/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.1.resnets.1.time_emb_proj.weight:0: {}
        down_blocks.1.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,640,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.1/resnets.1/Add:
      type: BinaryAdd
      input:
        /down_blocks.1/resnets.1/conv1/Conv_output_0:0: {}
        /down_blocks.1/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.1/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.1/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.1/resnets.1/Add_output_0:0: {}
        onnx::Mul_9136:0: {}
        onnx::Add_9137:0: {}
      output:
        /down_blocks.1/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_16:
      type: Reorder
      input:
        /down_blocks.1/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_16:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_16:0: {}
        down_blocks.1.resnets.1.conv2.weight:0: {}
        down_blocks.1.resnets.1.conv2.bias:0: {}
      output:
        /down_blocks.1/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_16:
      type: Reorder
      input:
        /down_blocks.1/resnets.1/conv2/Conv:0: {}
      output:
        /down_blocks.1/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.1/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.1/attentions.0/Add_output_0:0: {}
        /down_blocks.1/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.1/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.1/resnets.1/Div:
      type: BinaryOp
      input:
        /down_blocks.1/resnets.1/Add_1_output_0:0: {}
        /down_blocks.1/resnets.1/Constant_2_output_0:0: {}
      output:
        /down_blocks.1/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /down_blocks.1/attentions.1/norm/Add:
      type: GroupNorm
      input:
        /down_blocks.1/resnets.1/Div_output_0:0: {}
        onnx::Mul_9138:0: {}
        onnx::Add_9139:0: {}
      output:
        /down_blocks.1/attentions.1/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_17:
      type: Reorder
      input:
        /down_blocks.1/attentions.1/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_17:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/attentions.1/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_17:0: {}
        down_blocks.1.attentions.1.proj_in.weight:0: {}
        down_blocks.1.attentions.1.proj_in.bias:0: {}
      output:
        /down_blocks.1/attentions.1/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /down_blocks.1/attentions.1/Reshape:
      type: Reshape
      input:
        /down_blocks.1/attentions.1/proj_in/Conv_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,640
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /down_blocks.1/attentions.1/Reshape_output_0:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9140:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9142:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9143:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9149:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /down_blocks.1/attentions.1/Reshape_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_output_0:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9150:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9152:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9153:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9159:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9160:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 2560
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /down_blocks.1/attentions.1/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9161:0: {}
        down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias:0: {}
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.1/attentions.1/Reshape_1:
      type: Reshape
      input:
        /down_blocks.1/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
        /down_blocks.1/resnets.1/Div_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /down_blocks.1/attentions.1/proj_out/Conv:
      type: Convolution
      input:
        /down_blocks.1/attentions.1/Transpose_1_output_0:0_quant: {}
        down_blocks.1.attentions.1.proj_out.weight:0: {}
        down_blocks.1.attentions.1.proj_out.bias:0: {}
      output:
        /down_blocks.1/attentions.1/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_18:
      type: Reorder
      input:
        /down_blocks.1/attentions.1/proj_out/Conv:0: {}
      output:
        /down_blocks.1/attentions.1/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.1/attentions.1/Add:
      type: BinaryAdd
      input:
        /down_blocks.1/attentions.1/proj_out/Conv_output_0:0: {}
        /down_blocks.1/resnets.1/Div_output_0:0: {}
      output:
        /down_blocks.1/attentions.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    reorder_pre_for_conv_19:
      type: Reorder
      input:
        /down_blocks.1/attentions.1/Add_output_0:0: {}
      output:
        reorder_pre_for_conv_19:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.1/downsamplers.0/conv/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_19:0: {}
        down_blocks.1.downsamplers.0.conv.weight:0: {}
        down_blocks.1.downsamplers.0.conv.bias:0: {}
      output:
        /down_blocks.1/downsamplers.0/conv/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 2,2
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_19:
      type: Reorder
      input:
        /down_blocks.1/downsamplers.0/conv/Conv:0: {}
      output:
        /down_blocks.1/downsamplers.0/conv/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.2/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.1/downsamplers.0/conv/Conv_output_0:0: {}
        onnx::Mul_9162:0: {}
        onnx::Add_9163:0: {}
      output:
        /down_blocks.2/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_20:
      type: Reorder
      input:
        /down_blocks.2/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_20:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_20:0: {}
        down_blocks.2.resnets.0.conv1.weight:0: {}
        down_blocks.2.resnets.0.conv1.bias:0: {}
      output:
        /down_blocks.2/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_20:
      type: Reorder
      input:
        /down_blocks.2/resnets.0/conv1/Conv:0: {}
      output:
        /down_blocks.2/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.2/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.2.resnets.0.time_emb_proj.weight:0: {}
        down_blocks.2.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.2/resnets.0/Add:
      type: BinaryAdd
      input:
        /down_blocks.2/resnets.0/conv1/Conv_output_0:0: {}
        /down_blocks.2/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.2/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.2/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.2/resnets.0/Add_output_0:0: {}
        onnx::Mul_9164:0: {}
        onnx::Add_9165:0: {}
      output:
        /down_blocks.2/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_21:
      type: Reorder
      input:
        /down_blocks.2/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_21:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_21:0: {}
        down_blocks.2.resnets.0.conv2.weight:0: {}
        down_blocks.2.resnets.0.conv2.bias:0: {}
      output:
        /down_blocks.2/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_21:
      type: Reorder
      input:
        /down_blocks.2/resnets.0/conv2/Conv:0: {}
      output:
        /down_blocks.2/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_22:
      type: Reorder
      input:
        /down_blocks.1/downsamplers.0/conv/Conv_output_0:0: {}
      output:
        reorder_pre_for_conv_22:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/resnets.0/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_22:0: {}
        down_blocks.2.resnets.0.conv_shortcut.weight:0: {}
        down_blocks.2.resnets.0.conv_shortcut.bias:0: {}
      output:
        /down_blocks.2/resnets.0/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_22:
      type: Reorder
      input:
        /down_blocks.2/resnets.0/conv_shortcut/Conv:0: {}
      output:
        /down_blocks.2/resnets.0/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.2/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.2/resnets.0/conv_shortcut/Conv_output_0:0: {}
        /down_blocks.2/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.2/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.2/resnets.0/Div:
      type: BinaryOp
      input:
        /down_blocks.2/resnets.0/Add_1_output_0:0: {}
        /down_blocks.2/resnets.0/Constant_2_output_0:0: {}
      output:
        /down_blocks.2/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /down_blocks.2/attentions.0/norm/Add:
      type: GroupNorm
      input:
        /down_blocks.2/resnets.0/Div_output_0:0: {}
        onnx::Mul_9166:0: {}
        onnx::Add_9167:0: {}
      output:
        /down_blocks.2/attentions.0/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_23:
      type: Reorder
      input:
        /down_blocks.2/attentions.0/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_23:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/attentions.0/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_23:0: {}
        down_blocks.2.attentions.0.proj_in.weight:0: {}
        down_blocks.2.attentions.0.proj_in.bias:0: {}
      output:
        /down_blocks.2/attentions.0/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /down_blocks.2/attentions.0/Reshape:
      type: Reshape
      input:
        /down_blocks.2/attentions.0/proj_in/Conv_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,1280
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /down_blocks.2/attentions.0/Reshape_output_0:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9168:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9170:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9171:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9177:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /down_blocks.2/attentions.0/Reshape_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_output_0:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9178:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9180:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9181:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9187:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9188:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 5120
        ends: 10240
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /down_blocks.2/attentions.0/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9189:0: {}
        down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias:0: {}
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.2/attentions.0/Reshape_1:
      type: Reshape
      input:
        /down_blocks.2/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
        /down_blocks.2/resnets.0/Div_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /down_blocks.2/attentions.0/proj_out/Conv:
      type: Convolution
      input:
        /down_blocks.2/attentions.0/Transpose_1_output_0:0_quant: {}
        down_blocks.2.attentions.0.proj_out.weight:0: {}
        down_blocks.2.attentions.0.proj_out.bias:0: {}
      output:
        /down_blocks.2/attentions.0/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_24:
      type: Reorder
      input:
        /down_blocks.2/attentions.0/proj_out/Conv:0: {}
      output:
        /down_blocks.2/attentions.0/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.2/attentions.0/Add:
      type: BinaryAdd
      input:
        /down_blocks.2/attentions.0/proj_out/Conv_output_0:0: {}
        /down_blocks.2/resnets.0/Div_output_0:0: {}
      output:
        /down_blocks.2/attentions.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.2/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.2/attentions.0/Add_output_0:0: {}
        onnx::Mul_9190:0: {}
        onnx::Add_9191:0: {}
      output:
        /down_blocks.2/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_25:
      type: Reorder
      input:
        /down_blocks.2/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_25:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_25:0: {}
        down_blocks.2.resnets.1.conv1.weight:0: {}
        down_blocks.2.resnets.1.conv1.bias:0: {}
      output:
        /down_blocks.2/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_25:
      type: Reorder
      input:
        /down_blocks.2/resnets.1/conv1/Conv:0: {}
      output:
        /down_blocks.2/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.2/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.2.resnets.1.time_emb_proj.weight:0: {}
        down_blocks.2.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.2/resnets.1/Add:
      type: BinaryAdd
      input:
        /down_blocks.2/resnets.1/conv1/Conv_output_0:0: {}
        /down_blocks.2/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.2/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.2/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.2/resnets.1/Add_output_0:0: {}
        onnx::Mul_9192:0: {}
        onnx::Add_9193:0: {}
      output:
        /down_blocks.2/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_26:
      type: Reorder
      input:
        /down_blocks.2/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_26:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_26:0: {}
        down_blocks.2.resnets.1.conv2.weight:0: {}
        down_blocks.2.resnets.1.conv2.bias:0: {}
      output:
        /down_blocks.2/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_26:
      type: Reorder
      input:
        /down_blocks.2/resnets.1/conv2/Conv:0: {}
      output:
        /down_blocks.2/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.2/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.2/attentions.0/Add_output_0:0: {}
        /down_blocks.2/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.2/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.2/resnets.1/Div:
      type: BinaryOp
      input:
        /down_blocks.2/resnets.1/Add_1_output_0:0: {}
        /down_blocks.2/resnets.1/Constant_2_output_0:0: {}
      output:
        /down_blocks.2/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /down_blocks.2/attentions.1/norm/Add:
      type: GroupNorm
      input:
        /down_blocks.2/resnets.1/Div_output_0:0: {}
        onnx::Mul_9194:0: {}
        onnx::Add_9195:0: {}
      output:
        /down_blocks.2/attentions.1/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_27:
      type: Reorder
      input:
        /down_blocks.2/attentions.1/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_27:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/attentions.1/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_27:0: {}
        down_blocks.2.attentions.1.proj_in.weight:0: {}
        down_blocks.2.attentions.1.proj_in.bias:0: {}
      output:
        /down_blocks.2/attentions.1/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /down_blocks.2/attentions.1/Reshape:
      type: Reshape
      input:
        /down_blocks.2/attentions.1/proj_in/Conv_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,1280
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /down_blocks.2/attentions.1/Reshape_output_0:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9196:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9198:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9199:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9205:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /down_blocks.2/attentions.1/Reshape_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_output_0:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9206:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9208:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9209:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9215:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9216:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 5120
        ends: 10240
        axes: 1
        steps: 1
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /down_blocks.2/attentions.1/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9217:0: {}
        down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias:0: {}
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /down_blocks.2/attentions.1/Reshape_1:
      type: Reshape
      input:
        /down_blocks.2/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
        /down_blocks.2/resnets.1/Div_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /down_blocks.2/attentions.1/proj_out/Conv:
      type: Convolution
      input:
        /down_blocks.2/attentions.1/Transpose_1_output_0:0_quant: {}
        down_blocks.2.attentions.1.proj_out.weight:0: {}
        down_blocks.2.attentions.1.proj_out.bias:0: {}
      output:
        /down_blocks.2/attentions.1/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_28:
      type: Reorder
      input:
        /down_blocks.2/attentions.1/proj_out/Conv:0: {}
      output:
        /down_blocks.2/attentions.1/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.2/attentions.1/Add:
      type: BinaryAdd
      input:
        /down_blocks.2/attentions.1/proj_out/Conv_output_0:0: {}
        /down_blocks.2/resnets.1/Div_output_0:0: {}
      output:
        /down_blocks.2/attentions.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    reorder_pre_for_conv_29:
      type: Reorder
      input:
        /down_blocks.2/attentions.1/Add_output_0:0: {}
      output:
        reorder_pre_for_conv_29:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.2/downsamplers.0/conv/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_29:0: {}
        down_blocks.2.downsamplers.0.conv.weight:0: {}
        down_blocks.2.downsamplers.0.conv.bias:0: {}
      output:
        /down_blocks.2/downsamplers.0/conv/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 2,2
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_29:
      type: Reorder
      input:
        /down_blocks.2/downsamplers.0/conv/Conv:0: {}
      output:
        /down_blocks.2/downsamplers.0/conv/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.3/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.2/downsamplers.0/conv/Conv_output_0:0: {}
        onnx::Mul_9218:0: {}
        onnx::Add_9219:0: {}
      output:
        /down_blocks.3/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_30:
      type: Reorder
      input:
        /down_blocks.3/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_30:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.3/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_30:0: {}
        down_blocks.3.resnets.0.conv1.weight:0: {}
        down_blocks.3.resnets.0.conv1.bias:0: {}
      output:
        /down_blocks.3/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_30:
      type: Reorder
      input:
        /down_blocks.3/resnets.0/conv1/Conv:0: {}
      output:
        /down_blocks.3/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.3/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.3.resnets.0.time_emb_proj.weight:0: {}
        down_blocks.3.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.3/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.3/resnets.0/Add:
      type: BinaryAdd
      input:
        /down_blocks.3/resnets.0/conv1/Conv_output_0:0: {}
        /down_blocks.3/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.3/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.3/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.3/resnets.0/Add_output_0:0: {}
        onnx::Mul_9220:0: {}
        onnx::Add_9221:0: {}
      output:
        /down_blocks.3/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_31:
      type: Reorder
      input:
        /down_blocks.3/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_31:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.3/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_31:0: {}
        down_blocks.3.resnets.0.conv2.weight:0: {}
        down_blocks.3.resnets.0.conv2.bias:0: {}
      output:
        /down_blocks.3/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_31:
      type: Reorder
      input:
        /down_blocks.3/resnets.0/conv2/Conv:0: {}
      output:
        /down_blocks.3/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.3/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.2/downsamplers.0/conv/Conv_output_0:0: {}
        /down_blocks.3/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.3/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.3/resnets.0/Div:
      type: BinaryOp
      input:
        /down_blocks.3/resnets.0/Add_1_output_0:0: {}
        /down_blocks.3/resnets.0/Constant_2_output_0:0: {}
      output:
        /down_blocks.3/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /down_blocks.3/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.3/resnets.0/Div_output_0:0: {}
        onnx::Mul_9222:0: {}
        onnx::Add_9223:0: {}
      output:
        /down_blocks.3/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_32:
      type: Reorder
      input:
        /down_blocks.3/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_32:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.3/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_32:0: {}
        down_blocks.3.resnets.1.conv1.weight:0: {}
        down_blocks.3.resnets.1.conv1.bias:0: {}
      output:
        /down_blocks.3/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_32:
      type: Reorder
      input:
        /down_blocks.3/resnets.1/conv1/Conv:0: {}
      output:
        /down_blocks.3/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.3/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        down_blocks.3.resnets.1.time_emb_proj.weight:0: {}
        down_blocks.3.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /down_blocks.3/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /down_blocks.3/resnets.1/Add:
      type: BinaryAdd
      input:
        /down_blocks.3/resnets.1/conv1/Conv_output_0:0: {}
        /down_blocks.3/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /down_blocks.3/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.3/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /down_blocks.3/resnets.1/Add_output_0:0: {}
        onnx::Mul_9224:0: {}
        onnx::Add_9225:0: {}
      output:
        /down_blocks.3/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_33:
      type: Reorder
      input:
        /down_blocks.3/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_33:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /down_blocks.3/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_33:0: {}
        down_blocks.3.resnets.1.conv2.weight:0: {}
        down_blocks.3.resnets.1.conv2.bias:0: {}
      output:
        /down_blocks.3/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_33:
      type: Reorder
      input:
        /down_blocks.3/resnets.1/conv2/Conv:0: {}
      output:
        /down_blocks.3/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /down_blocks.3/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.3/resnets.0/Div_output_0:0: {}
        /down_blocks.3/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /down_blocks.3/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /down_blocks.3/resnets.1/Div:
      type: BinaryOp
      input:
        /down_blocks.3/resnets.1/Add_1_output_0:0: {}
        /down_blocks.3/resnets.1/Constant_2_output_0:0: {}
      output:
        /down_blocks.3/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /mid_block/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /down_blocks.3/resnets.1/Div_output_0:0: {}
        onnx::Mul_9226:0: {}
        onnx::Add_9227:0: {}
      output:
        /mid_block/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_34:
      type: Reorder
      input:
        /mid_block/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_34:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /mid_block/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_34:0: {}
        mid_block.resnets.0.conv1.weight:0: {}
        mid_block.resnets.0.conv1.bias:0: {}
      output:
        /mid_block/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_34:
      type: Reorder
      input:
        /mid_block/resnets.0/conv1/Conv:0: {}
      output:
        /mid_block/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /mid_block/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        mid_block.resnets.0.time_emb_proj.weight:0: {}
        mid_block.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /mid_block/resnets.0/Add:
      type: BinaryAdd
      input:
        /mid_block/resnets.0/conv1/Conv_output_0:0: {}
        /mid_block/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /mid_block/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /mid_block/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /mid_block/resnets.0/Add_output_0:0: {}
        onnx::Mul_9228:0: {}
        onnx::Add_9229:0: {}
      output:
        /mid_block/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_35:
      type: Reorder
      input:
        /mid_block/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_35:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /mid_block/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_35:0: {}
        mid_block.resnets.0.conv2.weight:0: {}
        mid_block.resnets.0.conv2.bias:0: {}
      output:
        /mid_block/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_35:
      type: Reorder
      input:
        /mid_block/resnets.0/conv2/Conv:0: {}
      output:
        /mid_block/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /mid_block/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /down_blocks.3/resnets.1/Div_output_0:0: {}
        /mid_block/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /mid_block/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /mid_block/resnets.0/Div:
      type: BinaryOp
      input:
        /mid_block/resnets.0/Add_1_output_0:0: {}
        /mid_block/resnets.0/Constant_2_output_0:0: {}
      output:
        /mid_block/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /mid_block/attentions.0/norm/Add:
      type: GroupNorm
      input:
        /mid_block/resnets.0/Div_output_0:0: {}
        onnx::Mul_9230:0: {}
        onnx::Add_9231:0: {}
      output:
        /mid_block/attentions.0/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_36:
      type: Reorder
      input:
        /mid_block/attentions.0/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_36:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /mid_block/attentions.0/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_36:0: {}
        mid_block.attentions.0.proj_in.weight:0: {}
        mid_block.attentions.0.proj_in.bias:0: {}
      output:
        /mid_block/attentions.0/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /mid_block/attentions.0/Reshape:
      type: Reshape
      input:
        /mid_block/attentions.0/proj_in/Conv_output_0:0: {}
      output:
        /mid_block/attentions.0/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,1280
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /mid_block/attentions.0/Reshape_output_0:0: {}
        mid_block.attentions.0.transformer_blocks.0.norm1.weight:0: {}
        mid_block.attentions.0.transformer_blocks.0.norm1.bias:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9232:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9234:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9235:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9241:0: {}
        mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /mid_block/attentions.0/Reshape_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /mid_block/attentions.0/transformer_blocks.0/Add_output_0:0: {}
        mid_block.attentions.0.transformer_blocks.0.norm2.weight:0: {}
        mid_block.attentions.0.transformer_blocks.0.norm2.bias:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9242:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9244:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9245:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9251:0: {}
        mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /mid_block/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /mid_block/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
        mid_block.attentions.0.transformer_blocks.0.norm3.weight:0: {}
        mid_block.attentions.0.transformer_blocks.0.norm3.bias:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9252:0: {}
        mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 5120
        ends: 10240
        axes: 1
        steps: 1
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /mid_block/attentions.0/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /mid_block/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9253:0: {}
        mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias:0: {}
        /mid_block/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /mid_block/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /mid_block/attentions.0/Reshape_1:
      type: Reshape
      input:
        /mid_block/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
        /mid_block/resnets.0/Div_output_0:0: {}
      output:
        /mid_block/attentions.0/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /mid_block/attentions.0/proj_out/Conv:
      type: Convolution
      input:
        /mid_block/attentions.0/Transpose_1_output_0:0_quant: {}
        mid_block.attentions.0.proj_out.weight:0: {}
        mid_block.attentions.0.proj_out.bias:0: {}
      output:
        /mid_block/attentions.0/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_37:
      type: Reorder
      input:
        /mid_block/attentions.0/proj_out/Conv:0: {}
      output:
        /mid_block/attentions.0/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /mid_block/attentions.0/Add:
      type: BinaryAdd
      input:
        /mid_block/attentions.0/proj_out/Conv_output_0:0: {}
        /mid_block/resnets.0/Div_output_0:0: {}
      output:
        /mid_block/attentions.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /mid_block/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /mid_block/attentions.0/Add_output_0:0: {}
        onnx::Mul_9254:0: {}
        onnx::Add_9255:0: {}
      output:
        /mid_block/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_38:
      type: Reorder
      input:
        /mid_block/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_38:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /mid_block/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_38:0: {}
        mid_block.resnets.1.conv1.weight:0: {}
        mid_block.resnets.1.conv1.bias:0: {}
      output:
        /mid_block/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_38:
      type: Reorder
      input:
        /mid_block/resnets.1/conv1/Conv:0: {}
      output:
        /mid_block/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /mid_block/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        mid_block.resnets.1.time_emb_proj.weight:0: {}
        mid_block.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /mid_block/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /mid_block/resnets.1/Add:
      type: BinaryAdd
      input:
        /mid_block/resnets.1/conv1/Conv_output_0:0: {}
        /mid_block/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /mid_block/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /mid_block/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /mid_block/resnets.1/Add_output_0:0: {}
        onnx::Mul_9256:0: {}
        onnx::Add_9257:0: {}
      output:
        /mid_block/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_39:
      type: Reorder
      input:
        /mid_block/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_39:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /mid_block/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_39:0: {}
        mid_block.resnets.1.conv2.weight:0: {}
        mid_block.resnets.1.conv2.bias:0: {}
      output:
        /mid_block/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_39:
      type: Reorder
      input:
        /mid_block/resnets.1/conv2/Conv:0: {}
      output:
        /mid_block/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /mid_block/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /mid_block/attentions.0/Add_output_0:0: {}
        /mid_block/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /mid_block/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /mid_block/resnets.1/Div:
      type: BinaryOp
      input:
        /mid_block/resnets.1/Add_1_output_0:0: {}
        /mid_block/resnets.1/Constant_2_output_0:0: {}
      output:
        /mid_block/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.0/Concat:
      type: Concat
      input:
        /mid_block/resnets.1/Div_output_0:0: {}
        /down_blocks.3/resnets.1/Div_output_0:0: {}
      output:
        /up_blocks.0/Concat_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.0/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.0/Concat_output_0:0: {}
        onnx::Mul_9258:0: {}
        onnx::Add_9259:0: {}
      output:
        /up_blocks.0/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 2560
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_40:
      type: Reorder
      input:
        /up_blocks.0/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_40:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_40:0: {}
        up_blocks.0.resnets.0.conv1.weight:0: {}
        up_blocks.0.resnets.0.conv1.bias:0: {}
      output:
        /up_blocks.0/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_40:
      type: Reorder
      input:
        /up_blocks.0/resnets.0/conv1/Conv:0: {}
      output:
        /up_blocks.0/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.0/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.0.resnets.0.time_emb_proj.weight:0: {}
        up_blocks.0.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.0/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.0/resnets.0/Add:
      type: BinaryAdd
      input:
        /up_blocks.0/resnets.0/conv1/Conv_output_0:0: {}
        /up_blocks.0/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.0/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.0/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.0/resnets.0/Add_output_0:0: {}
        onnx::Mul_9260:0: {}
        onnx::Add_9261:0: {}
      output:
        /up_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_41:
      type: Reorder
      input:
        /up_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_41:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_41:0: {}
        up_blocks.0.resnets.0.conv2.weight:0: {}
        up_blocks.0.resnets.0.conv2.bias:0: {}
      output:
        /up_blocks.0/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_41:
      type: Reorder
      input:
        /up_blocks.0/resnets.0/conv2/Conv:0: {}
      output:
        /up_blocks.0/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_42:
      type: Reorder
      input:
        /up_blocks.0/Concat_output_0:0: {}
      output:
        reorder_pre_for_conv_42:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.0/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_42:0: {}
        up_blocks.0.resnets.0.conv_shortcut.weight:0: {}
        up_blocks.0.resnets.0.conv_shortcut.bias:0: {}
      output:
        /up_blocks.0/resnets.0/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_42:
      type: Reorder
      input:
        /up_blocks.0/resnets.0/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.0/resnets.0/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.0/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.0/resnets.0/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.0/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.0/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.0/resnets.0/Div:
      type: BinaryOp
      input:
        /up_blocks.0/resnets.0/Add_1_output_0:0: {}
        /up_blocks.0/resnets.0/Constant_2_output_0:0: {}
      output:
        /up_blocks.0/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.0/Concat_1:
      type: Concat
      input:
        /up_blocks.0/resnets.0/Div_output_0:0: {}
        /down_blocks.3/resnets.0/Div_output_0:0: {}
      output:
        /up_blocks.0/Concat_1_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.0/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.0/Concat_1_output_0:0: {}
        onnx::Mul_9262:0: {}
        onnx::Add_9263:0: {}
      output:
        /up_blocks.0/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 2560
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_43:
      type: Reorder
      input:
        /up_blocks.0/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_43:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_43:0: {}
        up_blocks.0.resnets.1.conv1.weight:0: {}
        up_blocks.0.resnets.1.conv1.bias:0: {}
      output:
        /up_blocks.0/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_43:
      type: Reorder
      input:
        /up_blocks.0/resnets.1/conv1/Conv:0: {}
      output:
        /up_blocks.0/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.0/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.0.resnets.1.time_emb_proj.weight:0: {}
        up_blocks.0.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.0/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.0/resnets.1/Add:
      type: BinaryAdd
      input:
        /up_blocks.0/resnets.1/conv1/Conv_output_0:0: {}
        /up_blocks.0/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.0/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.0/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.0/resnets.1/Add_output_0:0: {}
        onnx::Mul_9264:0: {}
        onnx::Add_9265:0: {}
      output:
        /up_blocks.0/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_44:
      type: Reorder
      input:
        /up_blocks.0/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_44:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_44:0: {}
        up_blocks.0.resnets.1.conv2.weight:0: {}
        up_blocks.0.resnets.1.conv2.bias:0: {}
      output:
        /up_blocks.0/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_44:
      type: Reorder
      input:
        /up_blocks.0/resnets.1/conv2/Conv:0: {}
      output:
        /up_blocks.0/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_45:
      type: Reorder
      input:
        /up_blocks.0/Concat_1_output_0:0: {}
      output:
        reorder_pre_for_conv_45:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.1/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_45:0: {}
        up_blocks.0.resnets.1.conv_shortcut.weight:0: {}
        up_blocks.0.resnets.1.conv_shortcut.bias:0: {}
      output:
        /up_blocks.0/resnets.1/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_45:
      type: Reorder
      input:
        /up_blocks.0/resnets.1/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.0/resnets.1/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.0/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.0/resnets.1/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.0/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.0/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.0/resnets.1/Div:
      type: BinaryOp
      input:
        /up_blocks.0/resnets.1/Add_1_output_0:0: {}
        /up_blocks.0/resnets.1/Constant_2_output_0:0: {}
      output:
        /up_blocks.0/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.0/Concat_2:
      type: Concat
      input:
        /up_blocks.0/resnets.1/Div_output_0:0: {}
        /down_blocks.2/downsamplers.0/conv/Conv_output_0:0: {}
      output:
        /up_blocks.0/Concat_2_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.0/resnets.2/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.0/Concat_2_output_0:0: {}
        onnx::Mul_9266:0: {}
        onnx::Add_9267:0: {}
      output:
        /up_blocks.0/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 2560
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_46:
      type: Reorder
      input:
        /up_blocks.0/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_46:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.2/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_46:0: {}
        up_blocks.0.resnets.2.conv1.weight:0: {}
        up_blocks.0.resnets.2.conv1.bias:0: {}
      output:
        /up_blocks.0/resnets.2/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_46:
      type: Reorder
      input:
        /up_blocks.0/resnets.2/conv1/Conv:0: {}
      output:
        /up_blocks.0/resnets.2/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.0/resnets.2/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.0.resnets.2.time_emb_proj.weight:0: {}
        up_blocks.0.resnets.2.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.0/resnets.2/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.0/resnets.2/Add:
      type: BinaryAdd
      input:
        /up_blocks.0/resnets.2/conv1/Conv_output_0:0: {}
        /up_blocks.0/resnets.2/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.0/resnets.2/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.0/resnets.2/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.0/resnets.2/Add_output_0:0: {}
        onnx::Mul_9268:0: {}
        onnx::Add_9269:0: {}
      output:
        /up_blocks.0/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_47:
      type: Reorder
      input:
        /up_blocks.0/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_47:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.2/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_47:0: {}
        up_blocks.0.resnets.2.conv2.weight:0: {}
        up_blocks.0.resnets.2.conv2.bias:0: {}
      output:
        /up_blocks.0/resnets.2/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_47:
      type: Reorder
      input:
        /up_blocks.0/resnets.2/conv2/Conv:0: {}
      output:
        /up_blocks.0/resnets.2/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_48:
      type: Reorder
      input:
        /up_blocks.0/Concat_2_output_0:0: {}
      output:
        reorder_pre_for_conv_48:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/resnets.2/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_48:0: {}
        up_blocks.0.resnets.2.conv_shortcut.weight:0: {}
        up_blocks.0.resnets.2.conv_shortcut.bias:0: {}
      output:
        /up_blocks.0/resnets.2/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_48:
      type: Reorder
      input:
        /up_blocks.0/resnets.2/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.0/resnets.2/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.0/resnets.2/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.0/resnets.2/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.0/resnets.2/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.0/resnets.2/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.0/resnets.2/Div:
      type: BinaryOp
      input:
        /up_blocks.0/resnets.2/Add_1_output_0:0: {}
        /up_blocks.0/resnets.2/Constant_2_output_0:0: {}
      output:
        /up_blocks.0/resnets.2/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.0/upsamplers.0/Resize:
      type: Resampling
      input:
        /up_blocks.0/resnets.2/Div_output_0:0: {}
        /up_blocks.0/upsamplers.0/Constant_output_0:0: {}
      output:
        /up_blocks.0/upsamplers.0/Resize_output_0:0_quant: {}
      attr:
        scales: 1,1,2,2
        output_dtype: bf16
    reorder_pre_for_conv_49:
      type: Reorder
      input:
        /up_blocks.0/upsamplers.0/Resize_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_49:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.0/upsamplers.0/conv/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_49:0: {}
        up_blocks.0.upsamplers.0.conv.weight:0: {}
        up_blocks.0.upsamplers.0.conv.bias:0: {}
      output:
        /up_blocks.0/upsamplers.0/conv/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_49:
      type: Reorder
      input:
        /up_blocks.0/upsamplers.0/conv/Conv:0: {}
      output:
        /up_blocks.0/upsamplers.0/conv/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/Concat:
      type: Concat
      input:
        /up_blocks.0/upsamplers.0/conv/Conv_output_0:0: {}
        /down_blocks.2/attentions.1/Add_output_0:0: {}
      output:
        /up_blocks.1/Concat_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.1/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.1/Concat_output_0:0: {}
        onnx::Mul_9271:0: {}
        onnx::Add_9272:0: {}
      output:
        /up_blocks.1/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 2560
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_50:
      type: Reorder
      input:
        /up_blocks.1/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_50:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_50:0: {}
        up_blocks.1.resnets.0.conv1.weight:0: {}
        up_blocks.1.resnets.0.conv1.bias:0: {}
      output:
        /up_blocks.1/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_50:
      type: Reorder
      input:
        /up_blocks.1/resnets.0/conv1/Conv:0: {}
      output:
        /up_blocks.1/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.1.resnets.0.time_emb_proj.weight:0: {}
        up_blocks.1.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.1/resnets.0/Add:
      type: BinaryAdd
      input:
        /up_blocks.1/resnets.0/conv1/Conv_output_0:0: {}
        /up_blocks.1/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.1/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.1/resnets.0/Add_output_0:0: {}
        onnx::Mul_9273:0: {}
        onnx::Add_9274:0: {}
      output:
        /up_blocks.1/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_51:
      type: Reorder
      input:
        /up_blocks.1/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_51:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_51:0: {}
        up_blocks.1.resnets.0.conv2.weight:0: {}
        up_blocks.1.resnets.0.conv2.bias:0: {}
      output:
        /up_blocks.1/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_51:
      type: Reorder
      input:
        /up_blocks.1/resnets.0/conv2/Conv:0: {}
      output:
        /up_blocks.1/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_52:
      type: Reorder
      input:
        /up_blocks.1/Concat_output_0:0: {}
      output:
        reorder_pre_for_conv_52:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.0/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_52:0: {}
        up_blocks.1.resnets.0.conv_shortcut.weight:0: {}
        up_blocks.1.resnets.0.conv_shortcut.bias:0: {}
      output:
        /up_blocks.1/resnets.0/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_52:
      type: Reorder
      input:
        /up_blocks.1/resnets.0/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.1/resnets.0/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.1/resnets.0/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.1/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.1/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/resnets.0/Div:
      type: BinaryOp
      input:
        /up_blocks.1/resnets.0/Add_1_output_0:0: {}
        /up_blocks.1/resnets.0/Constant_2_output_0:0: {}
      output:
        /up_blocks.1/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.1/attentions.0/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.1/resnets.0/Div_output_0:0: {}
        onnx::Mul_9275:0: {}
        onnx::Add_9276:0: {}
      output:
        /up_blocks.1/attentions.0/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_53:
      type: Reorder
      input:
        /up_blocks.1/attentions.0/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_53:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/attentions.0/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_53:0: {}
        up_blocks.1.attentions.0.proj_in.weight:0: {}
        up_blocks.1.attentions.0.proj_in.bias:0: {}
      output:
        /up_blocks.1/attentions.0/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.1/attentions.0/Reshape:
      type: Reshape
      input:
        /up_blocks.1/attentions.0/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.0/Reshape_output_0:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9277:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9279:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9280:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9286:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.1/attentions.0/Reshape_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9287:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9289:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9290:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9296:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9297:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 5120
        ends: 10240
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.1/attentions.0/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9298:0: {}
        up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.0/Reshape_1:
      type: Reshape
      input:
        /up_blocks.1/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.1/resnets.0/Div_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.1/attentions.0/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.1/attentions.0/Transpose_1_output_0:0_quant: {}
        up_blocks.1.attentions.0.proj_out.weight:0: {}
        up_blocks.1.attentions.0.proj_out.bias:0: {}
      output:
        /up_blocks.1/attentions.0/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_54:
      type: Reorder
      input:
        /up_blocks.1/attentions.0/proj_out/Conv:0: {}
      output:
        /up_blocks.1/attentions.0/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/attentions.0/Add:
      type: BinaryAdd
      input:
        /up_blocks.1/attentions.0/proj_out/Conv_output_0:0: {}
        /up_blocks.1/resnets.0/Div_output_0:0: {}
      output:
        /up_blocks.1/attentions.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/Concat_1:
      type: Concat
      input:
        /up_blocks.1/attentions.0/Add_output_0:0: {}
        /down_blocks.2/attentions.0/Add_output_0:0: {}
      output:
        /up_blocks.1/Concat_1_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.1/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.1/Concat_1_output_0:0: {}
        onnx::Mul_9299:0: {}
        onnx::Add_9300:0: {}
      output:
        /up_blocks.1/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 2560
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_55:
      type: Reorder
      input:
        /up_blocks.1/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_55:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_55:0: {}
        up_blocks.1.resnets.1.conv1.weight:0: {}
        up_blocks.1.resnets.1.conv1.bias:0: {}
      output:
        /up_blocks.1/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_55:
      type: Reorder
      input:
        /up_blocks.1/resnets.1/conv1/Conv:0: {}
      output:
        /up_blocks.1/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.1.resnets.1.time_emb_proj.weight:0: {}
        up_blocks.1.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.1/resnets.1/Add:
      type: BinaryAdd
      input:
        /up_blocks.1/resnets.1/conv1/Conv_output_0:0: {}
        /up_blocks.1/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.1/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.1/resnets.1/Add_output_0:0: {}
        onnx::Mul_9301:0: {}
        onnx::Add_9302:0: {}
      output:
        /up_blocks.1/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_56:
      type: Reorder
      input:
        /up_blocks.1/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_56:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_56:0: {}
        up_blocks.1.resnets.1.conv2.weight:0: {}
        up_blocks.1.resnets.1.conv2.bias:0: {}
      output:
        /up_blocks.1/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_56:
      type: Reorder
      input:
        /up_blocks.1/resnets.1/conv2/Conv:0: {}
      output:
        /up_blocks.1/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_57:
      type: Reorder
      input:
        /up_blocks.1/Concat_1_output_0:0: {}
      output:
        reorder_pre_for_conv_57:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.1/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_57:0: {}
        up_blocks.1.resnets.1.conv_shortcut.weight:0: {}
        up_blocks.1.resnets.1.conv_shortcut.bias:0: {}
      output:
        /up_blocks.1/resnets.1/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_57:
      type: Reorder
      input:
        /up_blocks.1/resnets.1/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.1/resnets.1/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.1/resnets.1/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.1/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.1/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/resnets.1/Div:
      type: BinaryOp
      input:
        /up_blocks.1/resnets.1/Add_1_output_0:0: {}
        /up_blocks.1/resnets.1/Constant_2_output_0:0: {}
      output:
        /up_blocks.1/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.1/attentions.1/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.1/resnets.1/Div_output_0:0: {}
        onnx::Mul_9303:0: {}
        onnx::Add_9304:0: {}
      output:
        /up_blocks.1/attentions.1/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_58:
      type: Reorder
      input:
        /up_blocks.1/attentions.1/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_58:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/attentions.1/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_58:0: {}
        up_blocks.1.attentions.1.proj_in.weight:0: {}
        up_blocks.1.attentions.1.proj_in.bias:0: {}
      output:
        /up_blocks.1/attentions.1/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.1/attentions.1/Reshape:
      type: Reshape
      input:
        /up_blocks.1/attentions.1/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.1/Reshape_output_0:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9305:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9307:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9308:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9314:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.1/attentions.1/Reshape_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9315:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9317:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9318:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9324:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9325:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 5120
        ends: 10240
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.1/attentions.1/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9326:0: {}
        up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.1/Reshape_1:
      type: Reshape
      input:
        /up_blocks.1/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.1/resnets.1/Div_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.1/attentions.1/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.1/attentions.1/Transpose_1_output_0:0_quant: {}
        up_blocks.1.attentions.1.proj_out.weight:0: {}
        up_blocks.1.attentions.1.proj_out.bias:0: {}
      output:
        /up_blocks.1/attentions.1/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_59:
      type: Reorder
      input:
        /up_blocks.1/attentions.1/proj_out/Conv:0: {}
      output:
        /up_blocks.1/attentions.1/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/attentions.1/Add:
      type: BinaryAdd
      input:
        /up_blocks.1/attentions.1/proj_out/Conv_output_0:0: {}
        /up_blocks.1/resnets.1/Div_output_0:0: {}
      output:
        /up_blocks.1/attentions.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/Concat_2:
      type: Concat
      input:
        /up_blocks.1/attentions.1/Add_output_0:0: {}
        /down_blocks.1/downsamplers.0/conv/Conv_output_0:0: {}
      output:
        /up_blocks.1/Concat_2_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.1/resnets.2/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.1/Concat_2_output_0:0: {}
        onnx::Mul_9327:0: {}
        onnx::Add_9328:0: {}
      output:
        /up_blocks.1/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1920
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_60:
      type: Reorder
      input:
        /up_blocks.1/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_60:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.2/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_60:0: {}
        up_blocks.1.resnets.2.conv1.weight:0: {}
        up_blocks.1.resnets.2.conv1.bias:0: {}
      output:
        /up_blocks.1/resnets.2/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_60:
      type: Reorder
      input:
        /up_blocks.1/resnets.2/conv1/Conv:0: {}
      output:
        /up_blocks.1/resnets.2/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/resnets.2/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.1.resnets.2.time_emb_proj.weight:0: {}
        up_blocks.1.resnets.2.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/resnets.2/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,1280,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.1/resnets.2/Add:
      type: BinaryAdd
      input:
        /up_blocks.1/resnets.2/conv1/Conv_output_0:0: {}
        /up_blocks.1/resnets.2/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.1/resnets.2/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/resnets.2/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.1/resnets.2/Add_output_0:0: {}
        onnx::Mul_9329:0: {}
        onnx::Add_9330:0: {}
      output:
        /up_blocks.1/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_61:
      type: Reorder
      input:
        /up_blocks.1/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_61:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.2/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_61:0: {}
        up_blocks.1.resnets.2.conv2.weight:0: {}
        up_blocks.1.resnets.2.conv2.bias:0: {}
      output:
        /up_blocks.1/resnets.2/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_61:
      type: Reorder
      input:
        /up_blocks.1/resnets.2/conv2/Conv:0: {}
      output:
        /up_blocks.1/resnets.2/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_62:
      type: Reorder
      input:
        /up_blocks.1/Concat_2_output_0:0: {}
      output:
        reorder_pre_for_conv_62:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/resnets.2/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_62:0: {}
        up_blocks.1.resnets.2.conv_shortcut.weight:0: {}
        up_blocks.1.resnets.2.conv_shortcut.bias:0: {}
      output:
        /up_blocks.1/resnets.2/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_62:
      type: Reorder
      input:
        /up_blocks.1/resnets.2/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.1/resnets.2/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/resnets.2/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.1/resnets.2/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.1/resnets.2/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.1/resnets.2/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/resnets.2/Div:
      type: BinaryOp
      input:
        /up_blocks.1/resnets.2/Add_1_output_0:0: {}
        /up_blocks.1/resnets.2/Constant_2_output_0:0: {}
      output:
        /up_blocks.1/resnets.2/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.1/attentions.2/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.1/resnets.2/Div_output_0:0: {}
        onnx::Mul_9331:0: {}
        onnx::Add_9332:0: {}
      output:
        /up_blocks.1/attentions.2/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_63:
      type: Reorder
      input:
        /up_blocks.1/attentions.2/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_63:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/attentions.2/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_63:0: {}
        up_blocks.1.attentions.2.proj_in.weight:0: {}
        up_blocks.1.attentions.2.proj_in.bias:0: {}
      output:
        /up_blocks.1/attentions.2/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.1/attentions.2/Reshape:
      type: Reshape
      input:
        /up_blocks.1/attentions.2/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.2/Reshape_output_0:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9333:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9335:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9336:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9342:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.1/attentions.2/Reshape_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9343:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9345:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9346:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,160
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.07905694097280502
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,1280
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9352:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9353:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 5120
        ends: 10240
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.1/attentions.2/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9354:0: {}
        up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.1/attentions.2/Reshape_1:
      type: Reshape
      input:
        /up_blocks.1/attentions.2/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.1/resnets.2/Div_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.1/attentions.2/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.1/attentions.2/Transpose_1_output_0:0_quant: {}
        up_blocks.1.attentions.2.proj_out.weight:0: {}
        up_blocks.1.attentions.2.proj_out.bias:0: {}
      output:
        /up_blocks.1/attentions.2/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_64:
      type: Reorder
      input:
        /up_blocks.1/attentions.2/proj_out/Conv:0: {}
      output:
        /up_blocks.1/attentions.2/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.1/attentions.2/Add:
      type: BinaryAdd
      input:
        /up_blocks.1/attentions.2/proj_out/Conv_output_0:0: {}
        /up_blocks.1/resnets.2/Div_output_0:0: {}
      output:
        /up_blocks.1/attentions.2/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.1/upsamplers.0/Resize:
      type: Resampling
      input:
        /up_blocks.1/attentions.2/Add_output_0:0: {}
        /up_blocks.1/upsamplers.0/Constant_output_0:0: {}
      output:
        /up_blocks.1/upsamplers.0/Resize_output_0:0_quant: {}
      attr:
        scales: 1,1,2,2
        output_dtype: bf16
    reorder_pre_for_conv_65:
      type: Reorder
      input:
        /up_blocks.1/upsamplers.0/Resize_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_65:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.1/upsamplers.0/conv/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_65:0: {}
        up_blocks.1.upsamplers.0.conv.weight:0: {}
        up_blocks.1.upsamplers.0.conv.bias:0: {}
      output:
        /up_blocks.1/upsamplers.0/conv/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_65:
      type: Reorder
      input:
        /up_blocks.1/upsamplers.0/conv/Conv:0: {}
      output:
        /up_blocks.1/upsamplers.0/conv/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/Concat:
      type: Concat
      input:
        /up_blocks.1/upsamplers.0/conv/Conv_output_0:0: {}
        /down_blocks.1/attentions.1/Add_output_0:0: {}
      output:
        /up_blocks.2/Concat_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.2/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.2/Concat_output_0:0: {}
        onnx::Mul_9356:0: {}
        onnx::Add_9357:0: {}
      output:
        /up_blocks.2/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1920
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_66:
      type: Reorder
      input:
        /up_blocks.2/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_66:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_66:0: {}
        up_blocks.2.resnets.0.conv1.weight:0: {}
        up_blocks.2.resnets.0.conv1.bias:0: {}
      output:
        /up_blocks.2/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_66:
      type: Reorder
      input:
        /up_blocks.2/resnets.0/conv1/Conv:0: {}
      output:
        /up_blocks.2/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.2.resnets.0.time_emb_proj.weight:0: {}
        up_blocks.2.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,640,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.2/resnets.0/Add:
      type: BinaryAdd
      input:
        /up_blocks.2/resnets.0/conv1/Conv_output_0:0: {}
        /up_blocks.2/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.2/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.2/resnets.0/Add_output_0:0: {}
        onnx::Mul_9358:0: {}
        onnx::Add_9359:0: {}
      output:
        /up_blocks.2/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_67:
      type: Reorder
      input:
        /up_blocks.2/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_67:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_67:0: {}
        up_blocks.2.resnets.0.conv2.weight:0: {}
        up_blocks.2.resnets.0.conv2.bias:0: {}
      output:
        /up_blocks.2/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_67:
      type: Reorder
      input:
        /up_blocks.2/resnets.0/conv2/Conv:0: {}
      output:
        /up_blocks.2/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_68:
      type: Reorder
      input:
        /up_blocks.2/Concat_output_0:0: {}
      output:
        reorder_pre_for_conv_68:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.0/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_68:0: {}
        up_blocks.2.resnets.0.conv_shortcut.weight:0: {}
        up_blocks.2.resnets.0.conv_shortcut.bias:0: {}
      output:
        /up_blocks.2/resnets.0/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_68:
      type: Reorder
      input:
        /up_blocks.2/resnets.0/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.2/resnets.0/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.2/resnets.0/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.2/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.2/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/resnets.0/Div:
      type: BinaryOp
      input:
        /up_blocks.2/resnets.0/Add_1_output_0:0: {}
        /up_blocks.2/resnets.0/Constant_2_output_0:0: {}
      output:
        /up_blocks.2/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.2/attentions.0/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.2/resnets.0/Div_output_0:0: {}
        onnx::Mul_9360:0: {}
        onnx::Add_9361:0: {}
      output:
        /up_blocks.2/attentions.0/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_69:
      type: Reorder
      input:
        /up_blocks.2/attentions.0/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_69:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/attentions.0/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_69:0: {}
        up_blocks.2.attentions.0.proj_in.weight:0: {}
        up_blocks.2.attentions.0.proj_in.bias:0: {}
      output:
        /up_blocks.2/attentions.0/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.2/attentions.0/Reshape:
      type: Reshape
      input:
        /up_blocks.2/attentions.0/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.0/Reshape_output_0:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9362:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9364:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9365:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9371:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.2/attentions.0/Reshape_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9372:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9374:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9375:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9381:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9382:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 2560
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.2/attentions.0/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9383:0: {}
        up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.0/Reshape_1:
      type: Reshape
      input:
        /up_blocks.2/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.2/resnets.0/Div_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.2/attentions.0/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.2/attentions.0/Transpose_1_output_0:0_quant: {}
        up_blocks.2.attentions.0.proj_out.weight:0: {}
        up_blocks.2.attentions.0.proj_out.bias:0: {}
      output:
        /up_blocks.2/attentions.0/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_70:
      type: Reorder
      input:
        /up_blocks.2/attentions.0/proj_out/Conv:0: {}
      output:
        /up_blocks.2/attentions.0/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/attentions.0/Add:
      type: BinaryAdd
      input:
        /up_blocks.2/attentions.0/proj_out/Conv_output_0:0: {}
        /up_blocks.2/resnets.0/Div_output_0:0: {}
      output:
        /up_blocks.2/attentions.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/Concat_1:
      type: Concat
      input:
        /up_blocks.2/attentions.0/Add_output_0:0: {}
        /down_blocks.1/attentions.0/Add_output_0:0: {}
      output:
        /up_blocks.2/Concat_1_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.2/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.2/Concat_1_output_0:0: {}
        onnx::Mul_9384:0: {}
        onnx::Add_9385:0: {}
      output:
        /up_blocks.2/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 1280
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_71:
      type: Reorder
      input:
        /up_blocks.2/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_71:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_71:0: {}
        up_blocks.2.resnets.1.conv1.weight:0: {}
        up_blocks.2.resnets.1.conv1.bias:0: {}
      output:
        /up_blocks.2/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_71:
      type: Reorder
      input:
        /up_blocks.2/resnets.1/conv1/Conv:0: {}
      output:
        /up_blocks.2/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.2.resnets.1.time_emb_proj.weight:0: {}
        up_blocks.2.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,640,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.2/resnets.1/Add:
      type: BinaryAdd
      input:
        /up_blocks.2/resnets.1/conv1/Conv_output_0:0: {}
        /up_blocks.2/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.2/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.2/resnets.1/Add_output_0:0: {}
        onnx::Mul_9386:0: {}
        onnx::Add_9387:0: {}
      output:
        /up_blocks.2/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_72:
      type: Reorder
      input:
        /up_blocks.2/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_72:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_72:0: {}
        up_blocks.2.resnets.1.conv2.weight:0: {}
        up_blocks.2.resnets.1.conv2.bias:0: {}
      output:
        /up_blocks.2/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_72:
      type: Reorder
      input:
        /up_blocks.2/resnets.1/conv2/Conv:0: {}
      output:
        /up_blocks.2/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_73:
      type: Reorder
      input:
        /up_blocks.2/Concat_1_output_0:0: {}
      output:
        reorder_pre_for_conv_73:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.1/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_73:0: {}
        up_blocks.2.resnets.1.conv_shortcut.weight:0: {}
        up_blocks.2.resnets.1.conv_shortcut.bias:0: {}
      output:
        /up_blocks.2/resnets.1/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_73:
      type: Reorder
      input:
        /up_blocks.2/resnets.1/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.2/resnets.1/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.2/resnets.1/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.2/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.2/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/resnets.1/Div:
      type: BinaryOp
      input:
        /up_blocks.2/resnets.1/Add_1_output_0:0: {}
        /up_blocks.2/resnets.1/Constant_2_output_0:0: {}
      output:
        /up_blocks.2/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.2/attentions.1/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.2/resnets.1/Div_output_0:0: {}
        onnx::Mul_9388:0: {}
        onnx::Add_9389:0: {}
      output:
        /up_blocks.2/attentions.1/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_74:
      type: Reorder
      input:
        /up_blocks.2/attentions.1/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_74:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/attentions.1/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_74:0: {}
        up_blocks.2.attentions.1.proj_in.weight:0: {}
        up_blocks.2.attentions.1.proj_in.bias:0: {}
      output:
        /up_blocks.2/attentions.1/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.2/attentions.1/Reshape:
      type: Reshape
      input:
        /up_blocks.2/attentions.1/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.1/Reshape_output_0:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9390:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9392:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9393:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9399:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.2/attentions.1/Reshape_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9400:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9402:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9403:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9409:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9410:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 2560
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.2/attentions.1/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9411:0: {}
        up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.1/Reshape_1:
      type: Reshape
      input:
        /up_blocks.2/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.2/resnets.1/Div_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.2/attentions.1/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.2/attentions.1/Transpose_1_output_0:0_quant: {}
        up_blocks.2.attentions.1.proj_out.weight:0: {}
        up_blocks.2.attentions.1.proj_out.bias:0: {}
      output:
        /up_blocks.2/attentions.1/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_75:
      type: Reorder
      input:
        /up_blocks.2/attentions.1/proj_out/Conv:0: {}
      output:
        /up_blocks.2/attentions.1/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/attentions.1/Add:
      type: BinaryAdd
      input:
        /up_blocks.2/attentions.1/proj_out/Conv_output_0:0: {}
        /up_blocks.2/resnets.1/Div_output_0:0: {}
      output:
        /up_blocks.2/attentions.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/Concat_2:
      type: Concat
      input:
        /up_blocks.2/attentions.1/Add_output_0:0: {}
        /down_blocks.0/downsamplers.0/conv/Conv_output_0:0: {}
      output:
        /up_blocks.2/Concat_2_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.2/resnets.2/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.2/Concat_2_output_0:0: {}
        onnx::Mul_9412:0: {}
        onnx::Add_9413:0: {}
      output:
        /up_blocks.2/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 960
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_76:
      type: Reorder
      input:
        /up_blocks.2/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_76:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.2/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_76:0: {}
        up_blocks.2.resnets.2.conv1.weight:0: {}
        up_blocks.2.resnets.2.conv1.bias:0: {}
      output:
        /up_blocks.2/resnets.2/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_76:
      type: Reorder
      input:
        /up_blocks.2/resnets.2/conv1/Conv:0: {}
      output:
        /up_blocks.2/resnets.2/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/resnets.2/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.2.resnets.2.time_emb_proj.weight:0: {}
        up_blocks.2.resnets.2.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/resnets.2/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,640,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.2/resnets.2/Add:
      type: BinaryAdd
      input:
        /up_blocks.2/resnets.2/conv1/Conv_output_0:0: {}
        /up_blocks.2/resnets.2/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.2/resnets.2/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/resnets.2/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.2/resnets.2/Add_output_0:0: {}
        onnx::Mul_9414:0: {}
        onnx::Add_9415:0: {}
      output:
        /up_blocks.2/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_77:
      type: Reorder
      input:
        /up_blocks.2/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_77:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.2/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_77:0: {}
        up_blocks.2.resnets.2.conv2.weight:0: {}
        up_blocks.2.resnets.2.conv2.bias:0: {}
      output:
        /up_blocks.2/resnets.2/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_77:
      type: Reorder
      input:
        /up_blocks.2/resnets.2/conv2/Conv:0: {}
      output:
        /up_blocks.2/resnets.2/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_78:
      type: Reorder
      input:
        /up_blocks.2/Concat_2_output_0:0: {}
      output:
        reorder_pre_for_conv_78:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/resnets.2/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_78:0: {}
        up_blocks.2.resnets.2.conv_shortcut.weight:0: {}
        up_blocks.2.resnets.2.conv_shortcut.bias:0: {}
      output:
        /up_blocks.2/resnets.2/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_78:
      type: Reorder
      input:
        /up_blocks.2/resnets.2/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.2/resnets.2/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/resnets.2/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.2/resnets.2/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.2/resnets.2/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.2/resnets.2/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/resnets.2/Div:
      type: BinaryOp
      input:
        /up_blocks.2/resnets.2/Add_1_output_0:0: {}
        /up_blocks.2/resnets.2/Constant_2_output_0:0: {}
      output:
        /up_blocks.2/resnets.2/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.2/attentions.2/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.2/resnets.2/Div_output_0:0: {}
        onnx::Mul_9416:0: {}
        onnx::Add_9417:0: {}
      output:
        /up_blocks.2/attentions.2/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_79:
      type: Reorder
      input:
        /up_blocks.2/attentions.2/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_79:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/attentions.2/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_79:0: {}
        up_blocks.2.attentions.2.proj_in.weight:0: {}
        up_blocks.2.attentions.2.proj_in.bias:0: {}
      output:
        /up_blocks.2/attentions.2/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.2/attentions.2/Reshape:
      type: Reshape
      input:
        /up_blocks.2/attentions.2/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.2/Reshape_output_0:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9418:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9420:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9421:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9427:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.2/attentions.2/Reshape_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9428:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9430:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9431:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,80
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.11180339753627777
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,640
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9437:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9438:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 2560
        ends: 5120
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.2/attentions.2/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9439:0: {}
        up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.2/attentions.2/Reshape_1:
      type: Reshape
      input:
        /up_blocks.2/attentions.2/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.2/resnets.2/Div_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.2/attentions.2/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.2/attentions.2/Transpose_1_output_0:0_quant: {}
        up_blocks.2.attentions.2.proj_out.weight:0: {}
        up_blocks.2.attentions.2.proj_out.bias:0: {}
      output:
        /up_blocks.2/attentions.2/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_80:
      type: Reorder
      input:
        /up_blocks.2/attentions.2/proj_out/Conv:0: {}
      output:
        /up_blocks.2/attentions.2/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.2/attentions.2/Add:
      type: BinaryAdd
      input:
        /up_blocks.2/attentions.2/proj_out/Conv_output_0:0: {}
        /up_blocks.2/resnets.2/Div_output_0:0: {}
      output:
        /up_blocks.2/attentions.2/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.2/upsamplers.0/Resize:
      type: Resampling
      input:
        /up_blocks.2/attentions.2/Add_output_0:0: {}
        /up_blocks.2/upsamplers.0/Constant_output_0:0: {}
      output:
        /up_blocks.2/upsamplers.0/Resize_output_0:0_quant: {}
      attr:
        scales: 1,1,2,2
        output_dtype: bf16
    reorder_pre_for_conv_81:
      type: Reorder
      input:
        /up_blocks.2/upsamplers.0/Resize_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_81:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.2/upsamplers.0/conv/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_81:0: {}
        up_blocks.2.upsamplers.0.conv.weight:0: {}
        up_blocks.2.upsamplers.0.conv.bias:0: {}
      output:
        /up_blocks.2/upsamplers.0/conv/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_81:
      type: Reorder
      input:
        /up_blocks.2/upsamplers.0/conv/Conv:0: {}
      output:
        /up_blocks.2/upsamplers.0/conv/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/Concat:
      type: Concat
      input:
        /up_blocks.2/upsamplers.0/conv/Conv_output_0:0: {}
        /down_blocks.0/attentions.1/Add_output_0:0: {}
      output:
        /up_blocks.3/Concat_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.3/resnets.0/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.3/Concat_output_0:0: {}
        onnx::Mul_9441:0: {}
        onnx::Add_9442:0: {}
      output:
        /up_blocks.3/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 960
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_82:
      type: Reorder
      input:
        /up_blocks.3/resnets.0/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_82:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.0/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_82:0: {}
        up_blocks.3.resnets.0.conv1.weight:0: {}
        up_blocks.3.resnets.0.conv1.bias:0: {}
      output:
        /up_blocks.3/resnets.0/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_82:
      type: Reorder
      input:
        /up_blocks.3/resnets.0/conv1/Conv:0: {}
      output:
        /up_blocks.3/resnets.0/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/resnets.0/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.3.resnets.0.time_emb_proj.weight:0: {}
        up_blocks.3.resnets.0.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/resnets.0/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,320,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.3/resnets.0/Add:
      type: BinaryAdd
      input:
        /up_blocks.3/resnets.0/conv1/Conv_output_0:0: {}
        /up_blocks.3/resnets.0/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.3/resnets.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/resnets.0/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.3/resnets.0/Add_output_0:0: {}
        onnx::Mul_9443:0: {}
        onnx::Add_9444:0: {}
      output:
        /up_blocks.3/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_83:
      type: Reorder
      input:
        /up_blocks.3/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_83:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.0/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_83:0: {}
        up_blocks.3.resnets.0.conv2.weight:0: {}
        up_blocks.3.resnets.0.conv2.bias:0: {}
      output:
        /up_blocks.3/resnets.0/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_83:
      type: Reorder
      input:
        /up_blocks.3/resnets.0/conv2/Conv:0: {}
      output:
        /up_blocks.3/resnets.0/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_84:
      type: Reorder
      input:
        /up_blocks.3/Concat_output_0:0: {}
      output:
        reorder_pre_for_conv_84:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.0/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_84:0: {}
        up_blocks.3.resnets.0.conv_shortcut.weight:0: {}
        up_blocks.3.resnets.0.conv_shortcut.bias:0: {}
      output:
        /up_blocks.3/resnets.0/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_84:
      type: Reorder
      input:
        /up_blocks.3/resnets.0/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.3/resnets.0/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/resnets.0/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.3/resnets.0/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.3/resnets.0/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.3/resnets.0/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/resnets.0/Div:
      type: BinaryOp
      input:
        /up_blocks.3/resnets.0/Add_1_output_0:0: {}
        /up_blocks.3/resnets.0/Constant_2_output_0:0: {}
      output:
        /up_blocks.3/resnets.0/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.3/attentions.0/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.3/resnets.0/Div_output_0:0: {}
        onnx::Mul_9445:0: {}
        onnx::Add_9446:0: {}
      output:
        /up_blocks.3/attentions.0/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_85:
      type: Reorder
      input:
        /up_blocks.3/attentions.0/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_85:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/attentions.0/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_85:0: {}
        up_blocks.3.attentions.0.proj_in.weight:0: {}
        up_blocks.3.attentions.0.proj_in.bias:0: {}
      output:
        /up_blocks.3/attentions.0/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.3/attentions.0/Reshape:
      type: Reshape
      input:
        /up_blocks.3/attentions.0/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.0/Reshape_output_0:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9447:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9449:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9450:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9456:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.3/attentions.0/Reshape_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9457:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9459:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9460:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9466:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9467:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 1280
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 1280
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.3/attentions.0/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9468:0: {}
        up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.0/Reshape_1:
      type: Reshape
      input:
        /up_blocks.3/attentions.0/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.3/resnets.0/Div_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.3/attentions.0/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.3/attentions.0/Transpose_1_output_0:0_quant: {}
        up_blocks.3.attentions.0.proj_out.weight:0: {}
        up_blocks.3.attentions.0.proj_out.bias:0: {}
      output:
        /up_blocks.3/attentions.0/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_86:
      type: Reorder
      input:
        /up_blocks.3/attentions.0/proj_out/Conv:0: {}
      output:
        /up_blocks.3/attentions.0/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/attentions.0/Add:
      type: BinaryAdd
      input:
        /up_blocks.3/attentions.0/proj_out/Conv_output_0:0: {}
        /up_blocks.3/resnets.0/Div_output_0:0: {}
      output:
        /up_blocks.3/attentions.0/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/Concat_1:
      type: Concat
      input:
        /up_blocks.3/attentions.0/Add_output_0:0: {}
        /down_blocks.0/attentions.0/Add_output_0:0: {}
      output:
        /up_blocks.3/Concat_1_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.3/resnets.1/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.3/Concat_1_output_0:0: {}
        onnx::Mul_9469:0: {}
        onnx::Add_9470:0: {}
      output:
        /up_blocks.3/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_87:
      type: Reorder
      input:
        /up_blocks.3/resnets.1/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_87:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.1/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_87:0: {}
        up_blocks.3.resnets.1.conv1.weight:0: {}
        up_blocks.3.resnets.1.conv1.bias:0: {}
      output:
        /up_blocks.3/resnets.1/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_87:
      type: Reorder
      input:
        /up_blocks.3/resnets.1/conv1/Conv:0: {}
      output:
        /up_blocks.3/resnets.1/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/resnets.1/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.3.resnets.1.time_emb_proj.weight:0: {}
        up_blocks.3.resnets.1.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/resnets.1/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,320,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.3/resnets.1/Add:
      type: BinaryAdd
      input:
        /up_blocks.3/resnets.1/conv1/Conv_output_0:0: {}
        /up_blocks.3/resnets.1/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.3/resnets.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/resnets.1/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.3/resnets.1/Add_output_0:0: {}
        onnx::Mul_9471:0: {}
        onnx::Add_9472:0: {}
      output:
        /up_blocks.3/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_88:
      type: Reorder
      input:
        /up_blocks.3/resnets.1/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_88:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.1/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_88:0: {}
        up_blocks.3.resnets.1.conv2.weight:0: {}
        up_blocks.3.resnets.1.conv2.bias:0: {}
      output:
        /up_blocks.3/resnets.1/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_88:
      type: Reorder
      input:
        /up_blocks.3/resnets.1/conv2/Conv:0: {}
      output:
        /up_blocks.3/resnets.1/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_89:
      type: Reorder
      input:
        /up_blocks.3/Concat_1_output_0:0: {}
      output:
        reorder_pre_for_conv_89:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.1/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_89:0: {}
        up_blocks.3.resnets.1.conv_shortcut.weight:0: {}
        up_blocks.3.resnets.1.conv_shortcut.bias:0: {}
      output:
        /up_blocks.3/resnets.1/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_89:
      type: Reorder
      input:
        /up_blocks.3/resnets.1/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.3/resnets.1/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/resnets.1/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.3/resnets.1/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.3/resnets.1/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.3/resnets.1/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/resnets.1/Div:
      type: BinaryOp
      input:
        /up_blocks.3/resnets.1/Add_1_output_0:0: {}
        /up_blocks.3/resnets.1/Constant_2_output_0:0: {}
      output:
        /up_blocks.3/resnets.1/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.3/attentions.1/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.3/resnets.1/Div_output_0:0: {}
        onnx::Mul_9473:0: {}
        onnx::Add_9474:0: {}
      output:
        /up_blocks.3/attentions.1/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_90:
      type: Reorder
      input:
        /up_blocks.3/attentions.1/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_90:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/attentions.1/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_90:0: {}
        up_blocks.3.attentions.1.proj_in.weight:0: {}
        up_blocks.3.attentions.1.proj_in.bias:0: {}
      output:
        /up_blocks.3/attentions.1/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.3/attentions.1/Reshape:
      type: Reshape
      input:
        /up_blocks.3/attentions.1/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.1/Reshape_output_0:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9475:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9477:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9478:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9484:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.3/attentions.1/Reshape_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9485:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9487:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9488:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9494:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9495:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 1280
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 1280
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.3/attentions.1/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9496:0: {}
        up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.1/Reshape_1:
      type: Reshape
      input:
        /up_blocks.3/attentions.1/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.3/resnets.1/Div_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.3/attentions.1/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.3/attentions.1/Transpose_1_output_0:0_quant: {}
        up_blocks.3.attentions.1.proj_out.weight:0: {}
        up_blocks.3.attentions.1.proj_out.bias:0: {}
      output:
        /up_blocks.3/attentions.1/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_91:
      type: Reorder
      input:
        /up_blocks.3/attentions.1/proj_out/Conv:0: {}
      output:
        /up_blocks.3/attentions.1/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/attentions.1/Add:
      type: BinaryAdd
      input:
        /up_blocks.3/attentions.1/proj_out/Conv_output_0:0: {}
        /up_blocks.3/resnets.1/Div_output_0:0: {}
      output:
        /up_blocks.3/attentions.1/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/Concat_2:
      type: Concat
      input:
        /up_blocks.3/attentions.1/Add_output_0:0: {}
        /conv_in/Conv_output_0:0: {}
      output:
        /up_blocks.3/Concat_2_output_0:0: {}
      attr:
        axis: 1
        output_dtype: bf16
    /up_blocks.3/resnets.2/norm1/Add:
      type: GroupNorm
      input:
        /up_blocks.3/Concat_2_output_0:0: {}
        onnx::Mul_9497:0: {}
        onnx::Add_9498:0: {}
      output:
        /up_blocks.3/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 640
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_92:
      type: Reorder
      input:
        /up_blocks.3/resnets.2/nonlinearity/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_92:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.2/conv1/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_92:0: {}
        up_blocks.3.resnets.2.conv1.weight:0: {}
        up_blocks.3.resnets.2.conv1.bias:0: {}
      output:
        /up_blocks.3/resnets.2/conv1/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_92:
      type: Reorder
      input:
        /up_blocks.3/resnets.2/conv1/Conv:0: {}
      output:
        /up_blocks.3/resnets.2/conv1/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/resnets.2/time_emb_proj/Gemm:
      type: InnerProduct
      input:
        /down_blocks.0/resnets.0/nonlinearity_1/Mul_output_0:0_quant: {}
        up_blocks.3.resnets.2.time_emb_proj.weight:0: {}
        up_blocks.3.resnets.2.time_emb_proj.bias:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/resnets.2/Unsqueeze_1_output_0:0: {}
      attr:
        src1_perm: 0,1
        reshape: -1,320,1,1
        reshape_dims: 0
        output_dtype: bf16
    /up_blocks.3/resnets.2/Add:
      type: BinaryAdd
      input:
        /up_blocks.3/resnets.2/conv1/Conv_output_0:0: {}
        /up_blocks.3/resnets.2/Unsqueeze_1_output_0:0: {}
      output:
        /up_blocks.3/resnets.2/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/resnets.2/norm2/Add:
      type: GroupNorm
      input:
        /up_blocks.3/resnets.2/Add_output_0:0: {}
        onnx::Mul_9499:0: {}
        onnx::Add_9500:0: {}
      output:
        /up_blocks.3/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_93:
      type: Reorder
      input:
        /up_blocks.3/resnets.2/nonlinearity_1/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_93:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.2/conv2/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_93:0: {}
        up_blocks.3.resnets.2.conv2.weight:0: {}
        up_blocks.3.resnets.2.conv2.bias:0: {}
      output:
        /up_blocks.3/resnets.2/conv2/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_93:
      type: Reorder
      input:
        /up_blocks.3/resnets.2/conv2/Conv:0: {}
      output:
        /up_blocks.3/resnets.2/conv2/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    reorder_pre_for_conv_94:
      type: Reorder
      input:
        /up_blocks.3/Concat_2_output_0:0: {}
      output:
        reorder_pre_for_conv_94:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/resnets.2/conv_shortcut/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_94:0: {}
        up_blocks.3.resnets.2.conv_shortcut.weight:0: {}
        up_blocks.3.resnets.2.conv_shortcut.bias:0: {}
      output:
        /up_blocks.3/resnets.2/conv_shortcut/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_94:
      type: Reorder
      input:
        /up_blocks.3/resnets.2/conv_shortcut/Conv:0: {}
      output:
        /up_blocks.3/resnets.2/conv_shortcut/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/resnets.2/Add_1:
      type: BinaryAdd
      input:
        /up_blocks.3/resnets.2/conv_shortcut/Conv_output_0:0: {}
        /up_blocks.3/resnets.2/conv2/Conv_output_0:0: {}
      output:
        /up_blocks.3/resnets.2/Add_1_output_0:0: {}
      attr:
        output_dtype: bf16
    /up_blocks.3/resnets.2/Div:
      type: BinaryOp
      input:
        /up_blocks.3/resnets.2/Add_1_output_0:0: {}
        /up_blocks.3/resnets.2/Constant_2_output_0:0: {}
      output:
        /up_blocks.3/resnets.2/Div_output_0:0: {}
      attr:
        algorithm: div
        output_dtype: bf16
    /up_blocks.3/attentions.2/norm/Add:
      type: GroupNorm
      input:
        /up_blocks.3/resnets.2/Div_output_0:0: {}
        onnx::Mul_9501:0: {}
        onnx::Add_9502:0: {}
      output:
        /up_blocks.3/attentions.2/norm/Add_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        output_dtype: bf16
    reorder_pre_for_conv_95:
      type: Reorder
      input:
        /up_blocks.3/attentions.2/norm/Add_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_95:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /up_blocks.3/attentions.2/proj_in/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_95:0: {}
        up_blocks.3.attentions.2.proj_in.weight:0: {}
        up_blocks.3.attentions.2.proj_in.bias:0: {}
      output:
        /up_blocks.3/attentions.2/proj_in/Conv_output_0:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    /up_blocks.3/attentions.2/Reshape:
      type: Reshape
      input:
        /up_blocks.3/attentions.2/proj_in/Conv_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/Reshape_output_0:0: {}
      attr:
        dst_shape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/norm1/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.2/Reshape_output_0:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn1/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9503:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn1/to_k/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9505:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn1/to_v/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_9506:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn1/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_output_0:0: {}
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_2_output_0:0: {}
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_4_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/Add:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn1/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9512:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias:0: {}
        /up_blocks.3/attentions.2/Reshape_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/norm2/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_output_0:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn2/to_q/MatMul:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_9513:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn2/to_k/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9515:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn2/to_v/MatMul:
      type: InnerProduct
      input:
        encoder_hidden_states:0_2d_quant: {}
        onnx::MatMul_9516:0: {}
        encoder_hidden_states:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        src1_perm: 1,0
        reshape: -1,-1,8,40
        reshape_dims: '0'
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/attn2/MatMul_1:
      type: MultiHeadAttention
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_output_0:0: {}
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_2_output_0:0: {}
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_4_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
      attr:
        Q_perm: 0,2,1,3
        K_perm: 0,2,3,1
        output_scale: 0.15811388194561005
        V_perm: 0,2,1,3
        dst_perm: 0,2,1,3
        reshape: -1,320
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/Add_1:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/attn2/Reshape_7_output_0:0_quant: {}
        onnx::MatMul_9522:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias:0: {}
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/norm3/Add_1:
      type: LayerNorm
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/proj/Add:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/norm3/Add_1_output_0:0_quant: {}
        onnx::MatMul_9523:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Slice:
      type: Slice
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
      attr:
        starts: 0
        ends: 1280
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Slice_1:
      type: Slice
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/proj/Add_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      attr:
        starts: 1280
        ends: 2560
        axes: 1
        steps: 1
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Mul_3:
      type: Gelu
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Slice_1_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      attr:
        algorithm: gelu_tanh
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Mul_4:
      type: BinaryOp
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Slice_output_0:0: {}
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Mul_3_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /up_blocks.3/attentions.2/transformer_blocks.0/Add_2:
      type: InnerProduct
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/ff/net.0/Mul_4_output_0:0_quant: {}
        onnx::MatMul_9524:0: {}
        up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias:0: {}
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_1_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_2_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /up_blocks.3/attentions.2/Reshape_1:
      type: Reshape
      input:
        /up_blocks.3/attentions.2/transformer_blocks.0/Add_2_output_0:0: {}
        /up_blocks.3/resnets.2/Div_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/Transpose_1_output_0:0_quant: {}
      attr:
        dst_shape: -1,-1,-1,-1
        dims: 0, 2, 3
        output_dtype: bf16
    /up_blocks.3/attentions.2/proj_out/Conv:
      type: Convolution
      input:
        /up_blocks.3/attentions.2/Transpose_1_output_0:0_quant: {}
        up_blocks.3.attentions.2.proj_out.weight:0: {}
        up_blocks.3.attentions.2.proj_out.bias:0: {}
      output:
        /up_blocks.3/attentions.2/proj_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 1,1
        pads: 0,0,0,0
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_96:
      type: Reorder
      input:
        /up_blocks.3/attentions.2/proj_out/Conv:0: {}
      output:
        /up_blocks.3/attentions.2/proj_out/Conv_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: bf16
    /up_blocks.3/attentions.2/Add:
      type: BinaryAdd
      input:
        /up_blocks.3/attentions.2/proj_out/Conv_output_0:0: {}
        /up_blocks.3/resnets.2/Div_output_0:0: {}
      output:
        /up_blocks.3/attentions.2/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /conv_norm_out/Add:
      type: GroupNorm
      input:
        /up_blocks.3/attentions.2/Add_output_0:0: {}
        onnx::Mul_9525:0: {}
        onnx::Add_9526:0: {}
      output:
        /conv_act/Mul_output_0:0_quant: {}
      attr:
        group: 32
        channels: 320
        epsilon: 9.999999960041972e-13
        append_op: swish
        swish_beta: 1
        output_dtype: bf16
    reorder_pre_for_conv_97:
      type: Reorder
      input:
        /conv_act/Mul_output_0:0_quant: {}
      output:
        reorder_pre_for_conv_97:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,3,1
        output_dtype: bf16
    /conv_out/Conv:
      type: Convolution
      input:
        reorder_pre_for_conv_97:0: {}
        conv_out.weight:0: {}
        conv_out.bias:0: {}
      output:
        /conv_out/Conv:0: {}
      attr:
        dilations: 1,1
        group: 1
        kernel_shape: 3,3
        pads: 1,1,1,1
        strides: 1,1
        output_dtype: bf16
        src_perm: 0,3,1,2
        dst_perm: 0,2,3,1
    reorder_post_for_conv_97:
      type: Reorder
      input:
        /conv_out/Conv:0: {}
      output:
        out_sample:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,3,1,2
        output_dtype: fp32
    output_data:
      type: Output
      input:
        out_sample:0: {}
