model:
  name: model
  operator:
    input_data:
      type: Input
      output:
        input_ids:0:
          dtype: s32
          shape: [-1, -1]
        text_model.embeddings.position_embedding.weight:0:
          dtype: fp32
          shape: [77, 768]
          location: [0, 236544]
        text_model.embeddings.token_embedding.weight:0:
          dtype: fp32
          shape: [49408, 768]
          location: [236544, 151781376]
        text_model.encoder.layers.0.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [152017920, 3072]
        text_model.encoder.layers.0.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [152020992, 3072]
        onnx::MatMul_2215:0:
          dtype: bf16
          shape: [768, 768]
          location: [152024064, 1179648]
        text_model.encoder.layers.0.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [153203712, 1536]
        /text_model/encoder/layers.0/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [153205248, 4]
        onnx::MatMul_2216:0:
          dtype: bf16
          shape: [768, 768]
          location: [153205252, 1179648]
        text_model.encoder.layers.0.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [154384900, 1536]
        onnx::MatMul_2223:0:
          dtype: bf16
          shape: [768, 768]
          location: [154386436, 1179648]
        text_model.encoder.layers.0.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [155566084, 1536]
        onnx::MatMul_2235:0:
          dtype: bf16
          shape: [768, 768]
          location: [155567620, 1179648]
        text_model.encoder.layers.0.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [156747268, 1536]
        text_model.encoder.layers.0.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [156748804, 3072]
        text_model.encoder.layers.0.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [156751876, 3072]
        onnx::MatMul_2236:0:
          dtype: bf16
          shape: [768, 3072]
          location: [156754948, 4718592]
        text_model.encoder.layers.0.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [161473540, 6144]
        /text_model/encoder/layers.0/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [161479684, 4]
        onnx::MatMul_2237:0:
          dtype: bf16
          shape: [3072, 768]
          location: [161479688, 4718592]
        text_model.encoder.layers.0.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [166198280, 1536]
        text_model.encoder.layers.1.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [166199816, 3072]
        text_model.encoder.layers.1.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [166202888, 3072]
        onnx::MatMul_2238:0:
          dtype: bf16
          shape: [768, 768]
          location: [166205960, 1179648]
        text_model.encoder.layers.1.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [167385608, 1536]
        /text_model/encoder/layers.1/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [167387144, 4]
        onnx::MatMul_2239:0:
          dtype: bf16
          shape: [768, 768]
          location: [167387148, 1179648]
        text_model.encoder.layers.1.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [168566796, 1536]
        onnx::MatMul_2246:0:
          dtype: bf16
          shape: [768, 768]
          location: [168568332, 1179648]
        text_model.encoder.layers.1.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [169747980, 1536]
        onnx::MatMul_2258:0:
          dtype: bf16
          shape: [768, 768]
          location: [169749516, 1179648]
        text_model.encoder.layers.1.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [170929164, 1536]
        text_model.encoder.layers.1.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [170930700, 3072]
        text_model.encoder.layers.1.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [170933772, 3072]
        onnx::MatMul_2259:0:
          dtype: bf16
          shape: [768, 3072]
          location: [170936844, 4718592]
        text_model.encoder.layers.1.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [175655436, 6144]
        /text_model/encoder/layers.1/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [175661580, 4]
        onnx::MatMul_2260:0:
          dtype: bf16
          shape: [3072, 768]
          location: [175661584, 4718592]
        text_model.encoder.layers.1.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [180380176, 1536]
        text_model.encoder.layers.2.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [180381712, 3072]
        text_model.encoder.layers.2.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [180384784, 3072]
        onnx::MatMul_2261:0:
          dtype: bf16
          shape: [768, 768]
          location: [180387856, 1179648]
        text_model.encoder.layers.2.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [181567504, 1536]
        /text_model/encoder/layers.2/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [181569040, 4]
        onnx::MatMul_2262:0:
          dtype: bf16
          shape: [768, 768]
          location: [181569044, 1179648]
        text_model.encoder.layers.2.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [182748692, 1536]
        onnx::MatMul_2269:0:
          dtype: bf16
          shape: [768, 768]
          location: [182750228, 1179648]
        text_model.encoder.layers.2.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [183929876, 1536]
        onnx::MatMul_2281:0:
          dtype: bf16
          shape: [768, 768]
          location: [183931412, 1179648]
        text_model.encoder.layers.2.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [185111060, 1536]
        text_model.encoder.layers.2.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [185112596, 3072]
        text_model.encoder.layers.2.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [185115668, 3072]
        onnx::MatMul_2282:0:
          dtype: bf16
          shape: [768, 3072]
          location: [185118740, 4718592]
        text_model.encoder.layers.2.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [189837332, 6144]
        /text_model/encoder/layers.2/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [189843476, 4]
        onnx::MatMul_2283:0:
          dtype: bf16
          shape: [3072, 768]
          location: [189843480, 4718592]
        text_model.encoder.layers.2.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [194562072, 1536]
        text_model.encoder.layers.3.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [194563608, 3072]
        text_model.encoder.layers.3.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [194566680, 3072]
        onnx::MatMul_2284:0:
          dtype: bf16
          shape: [768, 768]
          location: [194569752, 1179648]
        text_model.encoder.layers.3.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [195749400, 1536]
        /text_model/encoder/layers.3/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [195750936, 4]
        onnx::MatMul_2285:0:
          dtype: bf16
          shape: [768, 768]
          location: [195750940, 1179648]
        text_model.encoder.layers.3.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [196930588, 1536]
        onnx::MatMul_2292:0:
          dtype: bf16
          shape: [768, 768]
          location: [196932124, 1179648]
        text_model.encoder.layers.3.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [198111772, 1536]
        onnx::MatMul_2304:0:
          dtype: bf16
          shape: [768, 768]
          location: [198113308, 1179648]
        text_model.encoder.layers.3.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [199292956, 1536]
        text_model.encoder.layers.3.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [199294492, 3072]
        text_model.encoder.layers.3.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [199297564, 3072]
        onnx::MatMul_2305:0:
          dtype: bf16
          shape: [768, 3072]
          location: [199300636, 4718592]
        text_model.encoder.layers.3.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [204019228, 6144]
        /text_model/encoder/layers.3/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [204025372, 4]
        onnx::MatMul_2306:0:
          dtype: bf16
          shape: [3072, 768]
          location: [204025376, 4718592]
        text_model.encoder.layers.3.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [208743968, 1536]
        text_model.encoder.layers.4.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [208745504, 3072]
        text_model.encoder.layers.4.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [208748576, 3072]
        onnx::MatMul_2307:0:
          dtype: bf16
          shape: [768, 768]
          location: [208751648, 1179648]
        text_model.encoder.layers.4.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [209931296, 1536]
        /text_model/encoder/layers.4/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [209932832, 4]
        onnx::MatMul_2308:0:
          dtype: bf16
          shape: [768, 768]
          location: [209932836, 1179648]
        text_model.encoder.layers.4.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [211112484, 1536]
        onnx::MatMul_2315:0:
          dtype: bf16
          shape: [768, 768]
          location: [211114020, 1179648]
        text_model.encoder.layers.4.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [212293668, 1536]
        onnx::MatMul_2327:0:
          dtype: bf16
          shape: [768, 768]
          location: [212295204, 1179648]
        text_model.encoder.layers.4.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [213474852, 1536]
        text_model.encoder.layers.4.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [213476388, 3072]
        text_model.encoder.layers.4.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [213479460, 3072]
        onnx::MatMul_2328:0:
          dtype: bf16
          shape: [768, 3072]
          location: [213482532, 4718592]
        text_model.encoder.layers.4.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [218201124, 6144]
        /text_model/encoder/layers.4/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [218207268, 4]
        onnx::MatMul_2329:0:
          dtype: bf16
          shape: [3072, 768]
          location: [218207272, 4718592]
        text_model.encoder.layers.4.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [222925864, 1536]
        text_model.encoder.layers.5.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [222927400, 3072]
        text_model.encoder.layers.5.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [222930472, 3072]
        onnx::MatMul_2330:0:
          dtype: bf16
          shape: [768, 768]
          location: [222933544, 1179648]
        text_model.encoder.layers.5.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [224113192, 1536]
        /text_model/encoder/layers.5/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [224114728, 4]
        onnx::MatMul_2331:0:
          dtype: bf16
          shape: [768, 768]
          location: [224114732, 1179648]
        text_model.encoder.layers.5.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [225294380, 1536]
        onnx::MatMul_2338:0:
          dtype: bf16
          shape: [768, 768]
          location: [225295916, 1179648]
        text_model.encoder.layers.5.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [226475564, 1536]
        onnx::MatMul_2350:0:
          dtype: bf16
          shape: [768, 768]
          location: [226477100, 1179648]
        text_model.encoder.layers.5.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [227656748, 1536]
        text_model.encoder.layers.5.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [227658284, 3072]
        text_model.encoder.layers.5.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [227661356, 3072]
        onnx::MatMul_2351:0:
          dtype: bf16
          shape: [768, 3072]
          location: [227664428, 4718592]
        text_model.encoder.layers.5.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [232383020, 6144]
        /text_model/encoder/layers.5/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [232389164, 4]
        onnx::MatMul_2352:0:
          dtype: bf16
          shape: [3072, 768]
          location: [232389168, 4718592]
        text_model.encoder.layers.5.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [237107760, 1536]
        text_model.encoder.layers.6.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [237109296, 3072]
        text_model.encoder.layers.6.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [237112368, 3072]
        onnx::MatMul_2353:0:
          dtype: bf16
          shape: [768, 768]
          location: [237115440, 1179648]
        text_model.encoder.layers.6.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [238295088, 1536]
        /text_model/encoder/layers.6/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [238296624, 4]
        onnx::MatMul_2354:0:
          dtype: bf16
          shape: [768, 768]
          location: [238296628, 1179648]
        text_model.encoder.layers.6.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [239476276, 1536]
        onnx::MatMul_2361:0:
          dtype: bf16
          shape: [768, 768]
          location: [239477812, 1179648]
        text_model.encoder.layers.6.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [240657460, 1536]
        onnx::MatMul_2373:0:
          dtype: bf16
          shape: [768, 768]
          location: [240658996, 1179648]
        text_model.encoder.layers.6.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [241838644, 1536]
        text_model.encoder.layers.6.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [241840180, 3072]
        text_model.encoder.layers.6.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [241843252, 3072]
        onnx::MatMul_2374:0:
          dtype: bf16
          shape: [768, 3072]
          location: [241846324, 4718592]
        text_model.encoder.layers.6.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [246564916, 6144]
        /text_model/encoder/layers.6/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [246571060, 4]
        onnx::MatMul_2375:0:
          dtype: bf16
          shape: [3072, 768]
          location: [246571064, 4718592]
        text_model.encoder.layers.6.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [251289656, 1536]
        text_model.encoder.layers.7.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [251291192, 3072]
        text_model.encoder.layers.7.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [251294264, 3072]
        onnx::MatMul_2376:0:
          dtype: bf16
          shape: [768, 768]
          location: [251297336, 1179648]
        text_model.encoder.layers.7.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [252476984, 1536]
        /text_model/encoder/layers.7/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [252478520, 4]
        onnx::MatMul_2377:0:
          dtype: bf16
          shape: [768, 768]
          location: [252478524, 1179648]
        text_model.encoder.layers.7.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [253658172, 1536]
        onnx::MatMul_2384:0:
          dtype: bf16
          shape: [768, 768]
          location: [253659708, 1179648]
        text_model.encoder.layers.7.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [254839356, 1536]
        onnx::MatMul_2396:0:
          dtype: bf16
          shape: [768, 768]
          location: [254840892, 1179648]
        text_model.encoder.layers.7.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [256020540, 1536]
        text_model.encoder.layers.7.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [256022076, 3072]
        text_model.encoder.layers.7.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [256025148, 3072]
        onnx::MatMul_2397:0:
          dtype: bf16
          shape: [768, 3072]
          location: [256028220, 4718592]
        text_model.encoder.layers.7.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [260746812, 6144]
        /text_model/encoder/layers.7/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [260752956, 4]
        onnx::MatMul_2398:0:
          dtype: bf16
          shape: [3072, 768]
          location: [260752960, 4718592]
        text_model.encoder.layers.7.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [265471552, 1536]
        text_model.encoder.layers.8.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [265473088, 3072]
        text_model.encoder.layers.8.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [265476160, 3072]
        onnx::MatMul_2399:0:
          dtype: bf16
          shape: [768, 768]
          location: [265479232, 1179648]
        text_model.encoder.layers.8.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [266658880, 1536]
        /text_model/encoder/layers.8/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [266660416, 4]
        onnx::MatMul_2400:0:
          dtype: bf16
          shape: [768, 768]
          location: [266660420, 1179648]
        text_model.encoder.layers.8.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [267840068, 1536]
        onnx::MatMul_2407:0:
          dtype: bf16
          shape: [768, 768]
          location: [267841604, 1179648]
        text_model.encoder.layers.8.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [269021252, 1536]
        onnx::MatMul_2419:0:
          dtype: bf16
          shape: [768, 768]
          location: [269022788, 1179648]
        text_model.encoder.layers.8.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [270202436, 1536]
        text_model.encoder.layers.8.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [270203972, 3072]
        text_model.encoder.layers.8.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [270207044, 3072]
        onnx::MatMul_2420:0:
          dtype: bf16
          shape: [768, 3072]
          location: [270210116, 4718592]
        text_model.encoder.layers.8.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [274928708, 6144]
        /text_model/encoder/layers.8/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [274934852, 4]
        onnx::MatMul_2421:0:
          dtype: bf16
          shape: [3072, 768]
          location: [274934856, 4718592]
        text_model.encoder.layers.8.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [279653448, 1536]
        text_model.encoder.layers.9.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [279654984, 3072]
        text_model.encoder.layers.9.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [279658056, 3072]
        onnx::MatMul_2422:0:
          dtype: bf16
          shape: [768, 768]
          location: [279661128, 1179648]
        text_model.encoder.layers.9.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [280840776, 1536]
        /text_model/encoder/layers.9/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [280842312, 4]
        onnx::MatMul_2423:0:
          dtype: bf16
          shape: [768, 768]
          location: [280842316, 1179648]
        text_model.encoder.layers.9.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [282021964, 1536]
        onnx::MatMul_2430:0:
          dtype: bf16
          shape: [768, 768]
          location: [282023500, 1179648]
        text_model.encoder.layers.9.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [283203148, 1536]
        onnx::MatMul_2442:0:
          dtype: bf16
          shape: [768, 768]
          location: [283204684, 1179648]
        text_model.encoder.layers.9.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [284384332, 1536]
        text_model.encoder.layers.9.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [284385868, 3072]
        text_model.encoder.layers.9.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [284388940, 3072]
        onnx::MatMul_2443:0:
          dtype: bf16
          shape: [768, 3072]
          location: [284392012, 4718592]
        text_model.encoder.layers.9.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [289110604, 6144]
        /text_model/encoder/layers.9/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [289116748, 4]
        onnx::MatMul_2444:0:
          dtype: bf16
          shape: [3072, 768]
          location: [289116752, 4718592]
        text_model.encoder.layers.9.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [293835344, 1536]
        text_model.encoder.layers.10.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [293836880, 3072]
        text_model.encoder.layers.10.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [293839952, 3072]
        onnx::MatMul_2445:0:
          dtype: bf16
          shape: [768, 768]
          location: [293843024, 1179648]
        text_model.encoder.layers.10.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [295022672, 1536]
        /text_model/encoder/layers.10/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [295024208, 4]
        onnx::MatMul_2446:0:
          dtype: bf16
          shape: [768, 768]
          location: [295024212, 1179648]
        text_model.encoder.layers.10.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [296203860, 1536]
        onnx::MatMul_2453:0:
          dtype: bf16
          shape: [768, 768]
          location: [296205396, 1179648]
        text_model.encoder.layers.10.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [297385044, 1536]
        onnx::MatMul_2465:0:
          dtype: bf16
          shape: [768, 768]
          location: [297386580, 1179648]
        text_model.encoder.layers.10.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [298566228, 1536]
        text_model.encoder.layers.10.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [298567764, 3072]
        text_model.encoder.layers.10.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [298570836, 3072]
        onnx::MatMul_2466:0:
          dtype: bf16
          shape: [768, 3072]
          location: [298573908, 4718592]
        text_model.encoder.layers.10.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [303292500, 6144]
        /text_model/encoder/layers.10/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [303298644, 4]
        onnx::MatMul_2467:0:
          dtype: bf16
          shape: [3072, 768]
          location: [303298648, 4718592]
        text_model.encoder.layers.10.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [308017240, 1536]
        text_model.encoder.layers.11.layer_norm1.weight:0:
          dtype: fp32
          shape: [768]
          location: [308018776, 3072]
        text_model.encoder.layers.11.layer_norm1.bias:0:
          dtype: fp32
          shape: [768]
          location: [308021848, 3072]
        onnx::MatMul_2468:0:
          dtype: bf16
          shape: [768, 768]
          location: [308024920, 1179648]
        text_model.encoder.layers.11.self_attn.q_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [309204568, 1536]
        /text_model/encoder/layers.11/self_attn/Constant_3_output_0:0:
          dtype: fp32
          shape: [1]
          location: [309206104, 4]
        onnx::MatMul_2469:0:
          dtype: bf16
          shape: [768, 768]
          location: [309206108, 1179648]
        text_model.encoder.layers.11.self_attn.k_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [310385756, 1536]
        onnx::MatMul_2476:0:
          dtype: bf16
          shape: [768, 768]
          location: [310387292, 1179648]
        text_model.encoder.layers.11.self_attn.v_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [311566940, 1536]
        onnx::MatMul_2488:0:
          dtype: bf16
          shape: [768, 768]
          location: [311568476, 1179648]
        text_model.encoder.layers.11.self_attn.out_proj.bias:0:
          dtype: bf16
          shape: [768]
          location: [312748124, 1536]
        text_model.encoder.layers.11.layer_norm2.weight:0:
          dtype: fp32
          shape: [768]
          location: [312749660, 3072]
        text_model.encoder.layers.11.layer_norm2.bias:0:
          dtype: fp32
          shape: [768]
          location: [312752732, 3072]
        onnx::MatMul_2489:0:
          dtype: bf16
          shape: [768, 3072]
          location: [312755804, 4718592]
        text_model.encoder.layers.11.mlp.fc1.bias:0:
          dtype: bf16
          shape: [3072]
          location: [317474396, 6144]
        /text_model/encoder/layers.11/mlp/activation_fn/Constant_output_0:0:
          dtype: fp32
          shape: [1]
          location: [317480540, 4]
        onnx::MatMul_2490:0:
          dtype: bf16
          shape: [3072, 768]
          location: [317480544, 4718592]
        text_model.encoder.layers.11.mlp.fc2.bias:0:
          dtype: bf16
          shape: [768]
          location: [322199136, 1536]
        text_model.final_layer_norm.weight:0:
          dtype: fp32
          shape: [768]
          location: [322200672, 3072]
        text_model.final_layer_norm.bias:0:
          dtype: fp32
          shape: [768]
          location: [322203744, 3072]
    position_embeddings/after/reshape:
      type: Reshape
      input:
        text_model.embeddings.position_embedding.weight:0: {}
        input_ids:0: {}
      output:
        position_embeddings/after/reshape:0: {}
      attr:
        dst_shape: 1,-1,768
        dims: 1
    /text_model/embeddings/position_embedding/Gather:
      type: Reshape
      input:
        position_embeddings/after/reshape:0: {}
      output:
        /text_model/embeddings/position_embedding/Gather_output_0:0: {}
      attr:
        dst_shape: 1,-1
    /text_model/Reshape:
      type: Reshape
      input:
        input_ids:0: {}
      output:
        /text_model/Reshape_output_0:0: {}
      attr:
        dst_shape: 1,-1
    textEncoder_word_embeddings/reshape:
      type: Reshape
      input:
        /text_model/Reshape_output_0:0: {}
      output:
        textEncoder_word_embeddings/reshape:0: {}
      attr:
        dst_shape: -1
    diffusion_casualAttentionMask/input/reshape:
      type: Reshape
      input:
        input_ids:0: {}
      output:
        diffusion_casualAttentionMask/input/reshape:0: {}
      attr:
        dst_shape: 1,-1
    diffusion_casualAttentionMask/input/reshape3D:
      type: Reshape
      input:
        diffusion_casualAttentionMask/input/reshape:0: {}
        input_ids:0: {}
      output:
        /text_model/Shape_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1, 1
    /text_model/ConstantOfShape_1:
      type: ConstantOfShape
      input:
        /text_model/Shape_output_0:0: {}
      output:
        /text_model/ConstantOfShape_1_output_0:0: {}
      attr:
        trilu: 1
        value: -10000
        tensor: 1
    /text_model/Unsqueeze_4:
      type: Unsqueeze
      input:
        /text_model/ConstantOfShape_1_output_0:0: {}
      output:
        /text_model/Cast_output_0:0: {}
      attr:
        axes: 1
    /text_model/embeddings/token_embedding/Gather:
      type: Gather
      input:
        textEncoder_word_embeddings/reshape:0: {}
        text_model.embeddings.token_embedding.weight:0: {}
        /text_model/embeddings/position_embedding/Gather_output_0:0: {}
        input_ids:0: {}
      output:
        embeddings_add/reshape_2d:0_before_quant: {}
      attr:
        axis: 0
        batch_dims: 0
        append_op: binary_add
        reshape: -1,-1,768
        reshape_dims: 0,1
        mul: 1,2
    /text_model/embeddings/token_embedding/Gather_quant:
      type: Quantize
      input:
        embeddings_add/reshape_2d:0_before_quant: {}
      output:
        embeddings_add/reshape_2d:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.0/layer_norm1/Add_1:
      type: LayerNorm
      input:
        embeddings_add/reshape_2d:0: {}
        text_model.encoder.layers.0.layer_norm1.weight:0: {}
        text_model.encoder.layers.0.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.0/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.0/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2215:0: {}
        text_model.encoder.layers.0.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.0/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.0/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.0/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2216:0: {}
        text_model.encoder.layers.0.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.0/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2223:0: {}
        text_model.encoder.layers.0.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.0/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.0/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.0/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.0/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.0/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.0/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.0/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.0/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.0/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.0/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.0/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.0/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_0:
      type: Reshape
      input:
        /text_model/encoder/layers.0/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_0:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.0/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_0:0_quant: {}
        onnx::MatMul_2235:0: {}
        text_model.encoder.layers.0.self_attn.out_proj.bias:0: {}
        embeddings_add/reshape_2d:0: {}
      output:
        /text_model/encoder/layers.0/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.0/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.0/Add_output_0:0: {}
        text_model.encoder.layers.0.layer_norm2.weight:0: {}
        text_model.encoder.layers.0.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.0/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.0/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.0/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2236:0: {}
        text_model.encoder.layers.0.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.0/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.0/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.0/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.0/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.0/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.0/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.0/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.0/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.0/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.0/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.0/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.0/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.0/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.0/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2237:0: {}
        text_model.encoder.layers.0.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.0/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.0/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.1/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.0/Add_1_output_0:0: {}
        text_model.encoder.layers.1.layer_norm1.weight:0: {}
        text_model.encoder.layers.1.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.1/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.1/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2238:0: {}
        text_model.encoder.layers.1.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.1/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.1/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.1/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2239:0: {}
        text_model.encoder.layers.1.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.1/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2246:0: {}
        text_model.encoder.layers.1.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.1/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.1/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.1/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.1/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.1/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.1/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.1/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.1/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.1/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.1/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.1/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.1/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_1:
      type: Reshape
      input:
        /text_model/encoder/layers.1/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_1:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.1/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_1:0_quant: {}
        onnx::MatMul_2258:0: {}
        text_model.encoder.layers.1.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.0/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.1/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.1/Add_output_0:0: {}
        text_model.encoder.layers.1.layer_norm2.weight:0: {}
        text_model.encoder.layers.1.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.1/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.1/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.1/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2259:0: {}
        text_model.encoder.layers.1.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.1/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.1/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.1/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.1/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.1/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.1/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.1/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.1/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.1/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.1/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.1/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.1/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.1/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.1/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2260:0: {}
        text_model.encoder.layers.1.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.1/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.1/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.2/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.1/Add_1_output_0:0: {}
        text_model.encoder.layers.2.layer_norm1.weight:0: {}
        text_model.encoder.layers.2.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.2/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.2/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2261:0: {}
        text_model.encoder.layers.2.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.2/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.2/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.2/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2262:0: {}
        text_model.encoder.layers.2.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.2/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2269:0: {}
        text_model.encoder.layers.2.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.2/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.2/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.2/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.2/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.2/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.2/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.2/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.2/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.2/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.2/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.2/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.2/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_2:
      type: Reshape
      input:
        /text_model/encoder/layers.2/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_2:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.2/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_2:0_quant: {}
        onnx::MatMul_2281:0: {}
        text_model.encoder.layers.2.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.1/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.2/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.2/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.2/Add_output_0:0: {}
        text_model.encoder.layers.2.layer_norm2.weight:0: {}
        text_model.encoder.layers.2.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.2/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.2/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.2/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2282:0: {}
        text_model.encoder.layers.2.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.2/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.2/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.2/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.2/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.2/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.2/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.2/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.2/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.2/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.2/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.2/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.2/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.2/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.2/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2283:0: {}
        text_model.encoder.layers.2.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.2/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.2/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.3/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.2/Add_1_output_0:0: {}
        text_model.encoder.layers.3.layer_norm1.weight:0: {}
        text_model.encoder.layers.3.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.3/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.3/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2284:0: {}
        text_model.encoder.layers.3.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.3/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.3/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.3/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2285:0: {}
        text_model.encoder.layers.3.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.3/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2292:0: {}
        text_model.encoder.layers.3.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.3/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.3/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.3/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.3/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.3/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.3/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.3/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.3/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.3/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.3/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.3/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.3/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_3:
      type: Reshape
      input:
        /text_model/encoder/layers.3/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_3:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.3/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_3:0_quant: {}
        onnx::MatMul_2304:0: {}
        text_model.encoder.layers.3.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.2/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.3/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.3/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.3/Add_output_0:0: {}
        text_model.encoder.layers.3.layer_norm2.weight:0: {}
        text_model.encoder.layers.3.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.3/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.3/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.3/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2305:0: {}
        text_model.encoder.layers.3.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.3/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.3/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.3/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.3/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.3/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.3/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.3/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.3/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.3/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.3/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.3/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.3/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.3/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.3/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2306:0: {}
        text_model.encoder.layers.3.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.3/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.3/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.4/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.3/Add_1_output_0:0: {}
        text_model.encoder.layers.4.layer_norm1.weight:0: {}
        text_model.encoder.layers.4.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.4/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.4/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2307:0: {}
        text_model.encoder.layers.4.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.4/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.4/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.4/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2308:0: {}
        text_model.encoder.layers.4.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.4/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2315:0: {}
        text_model.encoder.layers.4.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.4/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.4/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.4/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.4/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.4/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.4/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.4/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.4/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.4/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.4/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.4/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.4/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_4:
      type: Reshape
      input:
        /text_model/encoder/layers.4/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_4:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.4/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_4:0_quant: {}
        onnx::MatMul_2327:0: {}
        text_model.encoder.layers.4.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.3/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.4/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.4/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.4/Add_output_0:0: {}
        text_model.encoder.layers.4.layer_norm2.weight:0: {}
        text_model.encoder.layers.4.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.4/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.4/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.4/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2328:0: {}
        text_model.encoder.layers.4.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.4/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.4/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.4/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.4/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.4/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.4/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.4/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.4/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.4/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.4/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.4/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.4/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.4/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.4/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2329:0: {}
        text_model.encoder.layers.4.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.4/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.4/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.5/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.4/Add_1_output_0:0: {}
        text_model.encoder.layers.5.layer_norm1.weight:0: {}
        text_model.encoder.layers.5.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.5/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.5/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2330:0: {}
        text_model.encoder.layers.5.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.5/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.5/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.5/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2331:0: {}
        text_model.encoder.layers.5.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.5/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2338:0: {}
        text_model.encoder.layers.5.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.5/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.5/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.5/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.5/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.5/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.5/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.5/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.5/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.5/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.5/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.5/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.5/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_5:
      type: Reshape
      input:
        /text_model/encoder/layers.5/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_5:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.5/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_5:0_quant: {}
        onnx::MatMul_2350:0: {}
        text_model.encoder.layers.5.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.4/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.5/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.5/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.5/Add_output_0:0: {}
        text_model.encoder.layers.5.layer_norm2.weight:0: {}
        text_model.encoder.layers.5.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.5/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.5/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.5/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2351:0: {}
        text_model.encoder.layers.5.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.5/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.5/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.5/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.5/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.5/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.5/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.5/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.5/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.5/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.5/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.5/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.5/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.5/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.5/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2352:0: {}
        text_model.encoder.layers.5.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.5/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.5/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.6/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.5/Add_1_output_0:0: {}
        text_model.encoder.layers.6.layer_norm1.weight:0: {}
        text_model.encoder.layers.6.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.6/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.6/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2353:0: {}
        text_model.encoder.layers.6.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.6/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.6/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.6/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2354:0: {}
        text_model.encoder.layers.6.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.6/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2361:0: {}
        text_model.encoder.layers.6.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.6/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.6/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.6/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.6/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.6/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.6/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.6/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.6/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.6/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.6/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.6/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.6/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_6:
      type: Reshape
      input:
        /text_model/encoder/layers.6/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_6:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.6/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_6:0_quant: {}
        onnx::MatMul_2373:0: {}
        text_model.encoder.layers.6.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.5/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.6/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.6/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.6/Add_output_0:0: {}
        text_model.encoder.layers.6.layer_norm2.weight:0: {}
        text_model.encoder.layers.6.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.6/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.6/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.6/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2374:0: {}
        text_model.encoder.layers.6.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.6/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.6/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.6/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.6/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.6/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.6/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.6/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.6/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.6/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.6/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.6/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.6/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.6/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.6/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2375:0: {}
        text_model.encoder.layers.6.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.6/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.6/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.7/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.6/Add_1_output_0:0: {}
        text_model.encoder.layers.7.layer_norm1.weight:0: {}
        text_model.encoder.layers.7.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.7/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.7/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2376:0: {}
        text_model.encoder.layers.7.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.7/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.7/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.7/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2377:0: {}
        text_model.encoder.layers.7.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.7/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2384:0: {}
        text_model.encoder.layers.7.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.7/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.7/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.7/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.7/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.7/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.7/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.7/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.7/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.7/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.7/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.7/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.7/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_7:
      type: Reshape
      input:
        /text_model/encoder/layers.7/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_7:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.7/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_7:0_quant: {}
        onnx::MatMul_2396:0: {}
        text_model.encoder.layers.7.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.6/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.7/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.7/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.7/Add_output_0:0: {}
        text_model.encoder.layers.7.layer_norm2.weight:0: {}
        text_model.encoder.layers.7.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.7/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.7/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.7/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2397:0: {}
        text_model.encoder.layers.7.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.7/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.7/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.7/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.7/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.7/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.7/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.7/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.7/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.7/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.7/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.7/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.7/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.7/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.7/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2398:0: {}
        text_model.encoder.layers.7.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.7/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.7/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.8/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.7/Add_1_output_0:0: {}
        text_model.encoder.layers.8.layer_norm1.weight:0: {}
        text_model.encoder.layers.8.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.8/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.8/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2399:0: {}
        text_model.encoder.layers.8.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.8/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.8/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.8/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2400:0: {}
        text_model.encoder.layers.8.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.8/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2407:0: {}
        text_model.encoder.layers.8.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.8/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.8/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.8/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.8/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.8/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.8/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.8/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.8/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.8/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.8/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.8/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.8/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_8:
      type: Reshape
      input:
        /text_model/encoder/layers.8/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_8:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.8/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_8:0_quant: {}
        onnx::MatMul_2419:0: {}
        text_model.encoder.layers.8.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.7/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.8/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.8/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.8/Add_output_0:0: {}
        text_model.encoder.layers.8.layer_norm2.weight:0: {}
        text_model.encoder.layers.8.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.8/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.8/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.8/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2420:0: {}
        text_model.encoder.layers.8.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.8/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.8/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.8/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.8/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.8/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.8/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.8/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.8/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.8/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.8/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.8/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.8/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.8/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.8/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2421:0: {}
        text_model.encoder.layers.8.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.8/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.8/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.9/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.8/Add_1_output_0:0: {}
        text_model.encoder.layers.9.layer_norm1.weight:0: {}
        text_model.encoder.layers.9.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.9/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.9/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2422:0: {}
        text_model.encoder.layers.9.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.9/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.9/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.9/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2423:0: {}
        text_model.encoder.layers.9.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.9/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2430:0: {}
        text_model.encoder.layers.9.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.9/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.9/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.9/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.9/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.9/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.9/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.9/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.9/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.9/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.9/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.9/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.9/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_9:
      type: Reshape
      input:
        /text_model/encoder/layers.9/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_9:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.9/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_9:0_quant: {}
        onnx::MatMul_2442:0: {}
        text_model.encoder.layers.9.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.8/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.9/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.9/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.9/Add_output_0:0: {}
        text_model.encoder.layers.9.layer_norm2.weight:0: {}
        text_model.encoder.layers.9.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.9/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.9/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.9/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2443:0: {}
        text_model.encoder.layers.9.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.9/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.9/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.9/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.9/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.9/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.9/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.9/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.9/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.9/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.9/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.9/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.9/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.9/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.9/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2444:0: {}
        text_model.encoder.layers.9.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.9/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.9/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.10/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.9/Add_1_output_0:0: {}
        text_model.encoder.layers.10.layer_norm1.weight:0: {}
        text_model.encoder.layers.10.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.10/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.10/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2445:0: {}
        text_model.encoder.layers.10.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.10/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.10/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.10/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2446:0: {}
        text_model.encoder.layers.10.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.10/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2453:0: {}
        text_model.encoder.layers.10.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.10/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.10/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.10/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.10/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.10/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.10/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.10/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.10/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.10/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.10/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.10/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.10/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_10:
      type: Reshape
      input:
        /text_model/encoder/layers.10/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_10:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.10/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_10:0_quant: {}
        onnx::MatMul_2465:0: {}
        text_model.encoder.layers.10.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.9/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.10/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.10/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.10/Add_output_0:0: {}
        text_model.encoder.layers.10.layer_norm2.weight:0: {}
        text_model.encoder.layers.10.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.10/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.10/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.10/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2466:0: {}
        text_model.encoder.layers.10.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.10/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.10/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.10/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.10/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.10/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.10/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.10/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.10/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.10/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.10/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.10/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.10/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.10/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.10/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2467:0: {}
        text_model.encoder.layers.10.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.10/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.10/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.11/layer_norm1/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.10/Add_1_output_0:0: {}
        text_model.encoder.layers.11.layer_norm1.weight:0: {}
        text_model.encoder.layers.11.layer_norm1.bias:0: {}
      output:
        /text_model/encoder/layers.11/layer_norm1/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/q_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.11/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2468:0: {}
        text_model.encoder.layers.11.self_attn.q_proj.bias:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/q_proj/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.11/self_attn/q_proj/Add_output_0:0: {}
        /text_model/encoder/layers.11/self_attn/Constant_3_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/k_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.11/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2469:0: {}
        text_model.encoder.layers.11.self_attn.k_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Transpose:
      type: Reorder
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Transpose_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/v_proj/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.11/layer_norm1/Add_1_output_0:0_quant: {}
        onnx::MatMul_2476:0: {}
        text_model.encoder.layers.11.self_attn.v_proj.bias:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        reshape: -1,-1,12,64
        reshape_dims: '0'
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Transpose_1:
      type: Reorder
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_1_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Transpose_1_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Reshape_2:
      type: Reshape
      input:
        /text_model/encoder/layers.11/self_attn/Mul_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_2_output_0:0: {}
      attr:
        dst_shape: -1,-1,12,64
        dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Transpose_2:
      type: Reorder
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_2_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Transpose_2_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Reshape_3:
      type: Reshape
      input:
        /text_model/encoder/layers.11/self_attn/Transpose_2_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_3_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Reshape_5:
      type: Reshape
      input:
        /text_model/encoder/layers.11/self_attn/Transpose_1_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_5_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Reshape_4:
      type: Reshape
      input:
        /text_model/encoder/layers.11/self_attn/Transpose_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_4_output_0:0: {}
      attr:
        dst_shape: 12,-1,64
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/MatMul:
      type: Matmul
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_3_output_0:0: {}
        /text_model/encoder/layers.11/self_attn/Reshape_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_6_output_0:0: {}
      attr:
        src1_perm: 0,2,1
        reshape: -1,12,-1,-1
        reshape_dims: 0,1,1
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Add:
      type: BinaryAdd
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_6_output_0:0: {}
        /text_model/Cast_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Add_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Reshape_7:
      type: Reshape
      input:
        /text_model/encoder/layers.11/self_attn/Add_output_0:0: {}
        /text_model/encoder/layers.11/self_attn/Reshape_4_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_7_output_0:0: {}
      attr:
        dst_shape: 12,-1,-1
        dims: 1,1
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Softmax:
      type: Softmax
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_7_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Softmax_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/MatMul_1:
      type: Matmul
      input:
        /text_model/encoder/layers.11/self_attn/Softmax_output_0:0: {}
        /text_model/encoder/layers.11/self_attn/Reshape_5_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_8_output_0:0: {}
      attr:
        transpose_a: false
        transpose_b: false
        reshape: -1,12,-1,64
        reshape_dims: 0,1
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Transpose_4:
      type: Reorder
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_8_output_0:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Transpose_4_output_0:0: {}
      attr:
        src_perm: 0,1,2,3
        dst_perm: 0,2,1,3
        output_dtype: bf16
    /text_model/encoder/layers.11/self_attn/Reshape_9:
      type: Reshape
      input:
        /text_model/encoder/layers.11/self_attn/Transpose_4_output_0:0: {}
        input_ids:0: {}
      output:
        /text_model/encoder/layers.11/self_attn/Reshape_9_output_0:0: {}
      attr:
        dst_shape: -1,-1,-1
        dims: 0, 1
        output_dtype: bf16
    TextEncoder_AttentionReshape/reshape_to_2D_11:
      type: Reshape
      input:
        /text_model/encoder/layers.11/self_attn/Reshape_9_output_0:0: {}
        input_ids:0: {}
      output:
        TextEncoder_AttentionReshape/reshape_to_2D_11:0_quant: {}
      attr:
        dst_shape: -1,-1
        dims: 1
        output_dtype: bf16
    /text_model/encoder/layers.11/Add:
      type: InnerProduct
      input:
        TextEncoder_AttentionReshape/reshape_to_2D_11:0_quant: {}
        onnx::MatMul_2488:0: {}
        text_model.encoder.layers.11.self_attn.out_proj.bias:0: {}
        /text_model/encoder/layers.10/Add_1_output_0:0: {}
      output:
        /text_model/encoder/layers.11/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/encoder/layers.11/layer_norm2/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.11/Add_output_0:0: {}
        text_model.encoder.layers.11.layer_norm2.weight:0: {}
        text_model.encoder.layers.11.layer_norm2.bias:0: {}
      output:
        /text_model/encoder/layers.11/layer_norm2/Add_1_output_0:0_quant: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    /text_model/encoder/layers.11/mlp/fc1/Add:
      type: InnerProduct
      input:
        /text_model/encoder/layers.11/layer_norm2/Add_1_output_0:0_quant: {}
        onnx::MatMul_2489:0: {}
        text_model.encoder.layers.11.mlp.fc1.bias:0: {}
      output:
        /text_model/encoder/layers.11/mlp/fc1/Add_output_0:0: {}
      attr:
        src1_perm: 1,0
        output_dtype: bf16
    /text_model/encoder/layers.11/mlp/activation_fn/Mul:
      type: BinaryOp
      input:
        /text_model/encoder/layers.11/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.11/mlp/activation_fn/Constant_output_0:0: {}
      output:
        /text_model/encoder/layers.11/mlp/activation_fn/Mul_output_0:0: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.11/mlp/activation_fn/Sigmoid:
      type: Sigmoid
      input:
        /text_model/encoder/layers.11/mlp/activation_fn/Mul_output_0:0: {}
      output:
        /text_model/encoder/layers.11/mlp/activation_fn/Sigmoid_output_0:0: {}
      attr:
        output_dtype: bf16
    /text_model/encoder/layers.11/mlp/activation_fn/Mul_1:
      type: BinaryOp
      input:
        /text_model/encoder/layers.11/mlp/fc1/Add_output_0:0: {}
        /text_model/encoder/layers.11/mlp/activation_fn/Sigmoid_output_0:0: {}
      output:
        /text_model/encoder/layers.11/mlp/activation_fn/Mul_1_output_0:0_quant: {}
      attr:
        algorithm: mul
        output_dtype: bf16
    /text_model/encoder/layers.11/Add_1:
      type: InnerProduct
      input:
        /text_model/encoder/layers.11/mlp/activation_fn/Mul_1_output_0:0_quant: {}
        onnx::MatMul_2490:0: {}
        text_model.encoder.layers.11.mlp.fc2.bias:0: {}
        /text_model/encoder/layers.11/Add_output_0:0: {}
      output:
        /text_model/encoder/layers.11/Add_1_output_0:0: {}
      attr:
        src1_perm: 1,0
        append_op: sum
        output_dtype: bf16
    /text_model/final_layer_norm/Add_1:
      type: LayerNorm
      input:
        /text_model/encoder/layers.11/Add_1_output_0:0: {}
        text_model.final_layer_norm.weight:0: {}
        text_model.final_layer_norm.bias:0: {}
      output:
        last_hidden_state:0: {}
      attr:
        epsilon: 9.999999747378752e-06
        output_dtype: bf16
    output_data:
      type: Output
      input:
        last_hidden_state:0: {}
