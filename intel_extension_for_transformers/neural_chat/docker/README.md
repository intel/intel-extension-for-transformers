# Intel Neural Chat Dockerfile


Welcome to use docker based NeuralChat service across a wide range of platforms. Dive into our detailed guide to discover how to develop chatbots on these various computing platforms.

|Docker|HW|Location|
|:---:|:---:|:---:|
|Neuralchat-CodeGen|CPU/HPU|[code_generation](./code_generation/README.md)|
|Neuralchat-TextGen|CPU/HPU|[text_generation](./text_generation/README.md)|
|Neuralchat-Finetune|CPU/HPU|[finetuning](./finetuning/README.md)|
|Neuralchat-Inference|CPU/HPU|[inference](./inference/README.md)|
|Neuralchat-vllm-serving|GPU|[vllm_serving](./vllm_serving/README.md)|
|Neuralchat-tgi-serving|GPU|[tgi_serving](./tgi_serving/README.md)|
